{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The current Numpy installation ('c:\\\\programs\\\\python38\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9e3324102725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2325\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-102>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3492\u001b[0m         \"\"\"\n\u001b[0;32m   3493\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3494\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0m_win_os_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0m_win_os_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programs\\python38\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m_win_os_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m                    \u001b[1;34m\"See this issue for more information: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                    \"https://tinyurl.com/y3dm3h86\")\n\u001b[1;32m--> 302\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The current Numpy installation ('c:\\\\programs\\\\python38\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Classification of spoken digit recordings\n",
    "=========================================\n",
    "\n",
    "In this example we use the 1D scattering transform to represent spoken digits,\n",
    "which we then classify using a simple classifier. This shows that 1D scattering\n",
    "representations are useful for this type of problem.\n",
    "\n",
    "This dataset is automatically downloaded and preprocessed from\n",
    "https://github.com/Jakobovski/free-spoken-digit-dataset.git\n",
    "\n",
    "Downloading and precomputing scattering coefficients should take about 5 min.\n",
    "Running the gradient descent takes about 1 min.\n",
    "\n",
    "Results:\n",
    "Training accuracy = 99.7%\n",
    "Testing accuracy = 98.0%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminaries\n",
    "-------------\n",
    "\n",
    "Since kymatio handles PyTorch arrays, we first import `torch`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be constructing a logistic regression classifier on top of the\n",
    "scattering coefficients, so we need some of the neural network tools from\n",
    "`torch.nn` and the Adam optimizer from `torch.optim`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, NLLLoss, LogSoftmax, Sequential\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle audio file I/O, we import `os` and `scipy.io.wavfile`. We also need\n",
    "`numpy` for some basic array manipulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our results, we need to form a confusion matrix using\n",
    "scikit-learn and display them using `matplotlib`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we import the `Scattering1D` class from the `scattering` package and\n",
    "the `fetch_fsdd` function from `scattering.datasets`. The `Scattering1D`\n",
    "class is what lets us calculate the scattering transform, while the\n",
    "`fetch_fsdd` function downloads the FSDD, if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio import Scattering1D\n",
    "from kymatio.datasets import fetch_fsdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline setup\n",
    "--------------\n",
    "We start by specifying the dimensions of our processing pipeline along with\n",
    "some other parameters.\n",
    "\n",
    "First, we have signal length. Longer signals are truncated and shorter\n",
    "signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n",
    "little over a second.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2**13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n",
    "and the number of wavelets per octave.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 8\n",
    "Q = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a small constant to add to the scattering coefficients before\n",
    "computing the logarithm. This prevents very large values when the scattering \n",
    "coefficients are very close to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_eps = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a GPU is available, let's use it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility, we fix the seed of the random number generator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "----------------\n",
    "Once the parameter are set, we can start loading the data into a format that\n",
    "can be fed into the scattering transform and then a logistic regression\n",
    "classifier.\n",
    "\n",
    "We first download the dataset. If it's already downloaded, `fetch_fsdd` will\n",
    "simply return the information corresponding to the dataset that's already\n",
    "on disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data = fetch_fsdd()\n",
    "files = info_data['files']\n",
    "path_dataset = info_data['path_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Tensors to hold the audio signals (`x_all`), the labels (`y_all`), and\n",
    "whether the signal is in the train or test set (`subset`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = torch.zeros(len(files), T, dtype=torch.float32)\n",
    "y_all = torch.zeros(len(files), dtype=torch.int64)\n",
    "subset = torch.zeros(len(files), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file in the dataset, we extract its label `y` and its index from the\n",
    "filename. If the index is between 0 and 4, it is placed in the test set, while\n",
    "files with larger indices are used for training. The actual signals are\n",
    "normalized to have maximum amplitude one, and are truncated or zero-padded\n",
    "to the desired length `T`. They are then stored in the `x_all` Tensor while\n",
    "their labels are in `y_all`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, f in enumerate(files):\n",
    "    basename = f.split('.')[0]\n",
    "\n",
    "    # Get label (0-9) of recording.\n",
    "    y = int(basename.split('_')[0])\n",
    "\n",
    "    # Index larger than 5 gets assigned to training set.\n",
    "    if int(basename.split('_')[2]) >= 5:\n",
    "        subset[k] = 0\n",
    "    else:\n",
    "        subset[k] = 1\n",
    "\n",
    "    # Load the audio signal and normalize it.\n",
    "    _, x = wavfile.read(os.path.join(path_dataset, f))\n",
    "    x = np.asarray(x, dtype='float')\n",
    "    x /= np.max(np.abs(x))\n",
    "\n",
    "    # Convert from NumPy array to PyTorch Tensor.\n",
    "    x = torch.from_numpy(x)\n",
    "\n",
    "    # If it's too long, truncate it.\n",
    "    if x.numel() > T:\n",
    "        x = x[:T]\n",
    "\n",
    "    # If it's too short, zero-pad it.\n",
    "    start = (T - x.numel()) // 2\n",
    "\n",
    "    x_all[k,start:start + x.numel()] = x\n",
    "    y_all[k] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-scattering transform\n",
    "------------------------\n",
    "We now create the `Scattering1D` object that will be used to calculate the\n",
    "scattering coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering = Scattering1D(J, T, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using CUDA, the scattering transform object must be transferred to\n",
    "the GPU by calling its `cuda()` method. The data is similarly transferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    scattering.cuda()\n",
    "    x_all = x_all.cuda()\n",
    "    y_all = y_all.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the scattering transform for all signals in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all = scattering.forward(x_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it does not carry useful information, we remove the zeroth-order\n",
    "scattering coefficients, which are always placed in the first channel of\n",
    "the scattering Tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all = Sx_all[:,1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase discriminability, we take the logarithm of the scattering\n",
    "coefficients (after adding a small constant to make sure nothing blows up\n",
    "when scattering coefficients are close to zero).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all = torch.log(torch.abs(Sx_all) + log_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we average along the last dimension (time) to get a time-shift\n",
    "invariant representation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all = torch.mean(Sx_all, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the classifier\n",
    "-----------------------\n",
    "With the log-scattering coefficients in hand, we are ready to train our\n",
    "logistic regression classifier.\n",
    "\n",
    "First, we extract the training data (those for which `subset` equals `0`)\n",
    "and the associated labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_tr, y_tr = Sx_all[subset == 0], y_all[subset == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data to have mean zero and unit variance. Note that we need\n",
    "to apply the same transformation to the test data later, so we save the\n",
    "mean and standard deviation Tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_tr = Sx_tr.mean(dim=0)\n",
    "std_tr = Sx_tr.std(dim=0)\n",
    "Sx_tr = (Sx_tr - mu_tr) / std_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a Logistic Regression model using PyTorch. We train it using\n",
    "Adam with a negative log-likelihood loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Sx_tr.shape[-1]\n",
    "num_classes = y_tr.cpu().unique().numel()\n",
    "model = Sequential(Linear(num_input, num_classes), LogSoftmax(dim=1))\n",
    "optimizer = Adam(model.parameters())\n",
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, if we're on a GPU, transfer the model and the loss function onto\n",
    "the device.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, we set some parameters for the optimization\n",
    "procedure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of signals to use in each gradient descent step (batch).\n",
    "batch_size = 32\n",
    "# Number of epochs.\n",
    "num_epochs = 50\n",
    "# Learning rate for Adam.\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these parameters, we compute the total number of batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = Sx_tr.shape[0]\n",
    "nbatches = nsamples // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train the classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(num_epochs):\n",
    "    # Randomly permute the data. If necessary, transfer the permutation to the\n",
    "    # GPU.\n",
    "    perm = torch.randperm(nsamples)\n",
    "    if use_cuda:\n",
    "        perm = perm.cuda()\n",
    "\n",
    "    # For each batch, calculate the gradient with respect to the loss and take\n",
    "    # one step.\n",
    "    for i in range(nbatches):\n",
    "        idx = perm[i * batch_size : (i+1) * batch_size]\n",
    "        model.zero_grad()\n",
    "        resp = model.forward(Sx_tr[idx])\n",
    "        loss = criterion(resp, y_tr[idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the response of the training data at the end of this epoch and\n",
    "    # the average loss.\n",
    "    resp = model.forward(Sx_tr)\n",
    "    avg_loss = criterion(resp, y_tr)\n",
    "\n",
    "    # Try predicting the classes of the signals in the training set and compute\n",
    "    # the accuracy.\n",
    "    y_hat = resp.argmax(dim=1)\n",
    "    accuracy = (y_tr == y_hat).float().mean()\n",
    "\n",
    "    print('Epoch {}, average loss = {:1.3f}, accuracy = {:1.3f}'.format(\n",
    "        e, avg_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our network is trained, let's test it!\n",
    "\n",
    "First, we extract the test data (those for which `subset` equals `1`) and the\n",
    "associated labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_te, y_te = Sx_all[subset == 1], y_all[subset == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the mean and standard deviation calculated on the training data to \n",
    "standardize the testing data, as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_te = (Sx_te - mu_tr) / std_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the response of the classifier on the test data and the resulting\n",
    "loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = model.forward(Sx_te)\n",
    "avg_loss = criterion(resp, y_te)\n",
    "\n",
    "# Try predicting the labels of the signals in the test data and compute the\n",
    "# accuracy.\n",
    "y_hat = resp.argmax(dim=1)\n",
    "accu = (y_te == y_hat).float().mean()\n",
    "\n",
    "print('TEST, average loss = {:1.3f}, accuracy = {:1.3f}'.format(\n",
    "      avg_loss, accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the classification accuracy as a confusion matrix\n",
    "----------------------------------------------------------\n",
    "Let's see what the very few misclassified sounds get misclassified as. We\n",
    "will plot a confusion matrix which indicates in a 2D histogram how often\n",
    "one sample was mistaken for another (anything on the diagonal is correctly\n",
    "classified, anything off the diagonal is wrong).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories = y_hat.cpu().numpy()\n",
    "actual_categories = y_te.cpu().numpy()\n",
    "\n",
    "confusion = confusion_matrix(actual_categories, predicted_categories)\n",
    "plt.figure()\n",
    "plt.imshow(confusion)\n",
    "tick_locs = np.arange(10)\n",
    "ticks = ['{}'.format(i) for i in range(1, 11)]\n",
    "plt.xticks(tick_locs, ticks)\n",
    "plt.yticks(tick_locs, ticks)\n",
    "plt.ylabel(\"True number\")\n",
    "plt.xlabel(\"Predicted number\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
