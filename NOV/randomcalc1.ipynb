{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Calculus\n",
    "\n",
    "### Introduction\n",
    "In this section we discuss the concept of conditional time dependence component.  In order to model randomness in signals (noise signals), we introduce the notion of random processes.  Note that the tools are deterministic mathematical constructs; randomness only enters when observations are conducted.  We first state the clasic definition of random processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Definition 1.  Random Processes\n",
    "*A random (or stochastic) process $\\{X_t,t\\in T\\}$ is a collection of random variables on the same probability space $(\\Omega, \\mathcal{F},P)$.  The index set T is usually representing time and can be either an interval [t<sub>1</sub>,t<sub>1</sub>] or a discrete set.  Therefore the random process X can be written as a function:*\n",
    "$$ X : \\mathbb{R} \\times \\Omega \\rightarrow \\mathbb{R}, (t,\\omega) \\mapsto X(t,\\omega) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the stochastic interpretation, a sample $\\omega$ is chosen from the sample space $\\Omega$ \"at random\".  This yields the \"stochatic signal\" or \"noise signal\" r(.,$\\omega$) defined on index set T.  This signal is also denoted as sample path, realisation or trajectory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation Remark\n",
    "We introduced random or stochastic processes as functions wth to arguments: t and $\\omega$.  We will, however, omit the argument $\\omega$ for brevity as it is done in most text books: X(t,$\\omega$)=X(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the definition of random processes, we know that the amount of information is increasing with time.  Again, we need the concept of sigma algebras.  We assume that information is not lost with increasing time and therefore the corresponding $\\sigma$-algebras will increase over time as more and more information becomes available. This concept is called filtration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2 Filtration/adapted process\n",
    "A collection $\\{\\mathcal{F}_t\\}_{t\\ge0}$ of a sub $\\sigma$ algebras is called filtration if, for every $s\\le t$ we have $\\mathcal{F}_s\\subseteq\\mathcal{F}_t$.  The random variables $\\{X_t:0\\le t\\le\\infty\\}$ are called adpated to the filtration $\\mathcal{F}_t$ if, for every t, X<sub>t</sub> is meaurable with respect to $\\mathcal{F}_t$.\n",
    "![Figure 1](https://selene.hud.ac.uk/u1273400/images/seg_media/r1.PNG)\n",
    "**Figure 1** Example of a filtration\n",
    "\n",
    "The concept of a filtration is easily understood with a simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1\n",
    "Suppose we have a sample space of four elements: $\\Omega=\\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\}$.  At time zero, we do not have any information about which $\\omega$ has been chosen.  At time T/2 we know whether we have $\\Omega=\\{\\omega_1, \\omega_2\\}$ or $\\{\\omega_3, \\omega_4\\}$. At time T, we have full information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we have the folloing $\\sigma$-algebras:\n",
    "$$ \\mathcal{F}_t=\\left\\{\n",
    "\\begin{aligned}[lcr]\n",
    "\\{0,\\Omega\\}, && t \\in [0, \\frac{T}{2}) \\\\\n",
    "\\{0,\\{\\omega_1,\\omega_2\\},\\{\\omega_3,\\omega_4\\},\\Omega\\}, && t \\in [\\frac{T}{2}, T) \\\\\n",
    "\\mathcal{F}_{max}=2^{\\Omega}, && t=T\n",
    "\\end{aligned} \\right\\} $$\n",
    "\n",
    "Thus $\\mathcal{F}_0$ represents initial information whereas  $\\mathcal{F}_\\infty$ represents full information (all we will ever know).  Therefore, a stochastic process is said to to be defined on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t \\ge 0},P)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into the topics of random processes, stationary random processes, Gaussian random processes, etc. let us first recapitulate two (almost) trivial properties of deterministic functions:\n",
    "\n",
    "Let x(.) be a real, continuously differentiable function defined on the interval [0,T].  Its continuously differentiability implies both a bounded total variation and a vanishing \"sum of squared increments\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Total variation: $$ \\int_0^T\\left|\\frac{dx(t)}{dt}\\right|dt<\\infty$$\n",
    "2. Sum of squares:$$\\lim_{N\\rightarrow\\infty}\\sum_{k=1}^N\\left[x\\left(k\\frac{T}{N}\\right)-x\\left((k-1)\\frac{T}{N}\\right)\\right]^2=0$$\n",
    "\n",
    "Random processes do not have either of these nice smoothness properties in general.  This allows the desired \"wild\" and \"random\" behaviour of the (sample) \"noise signals\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes of Processes\n",
    "\n",
    "#### Markov Process\n",
    "\n",
    "A Markov Process X is a particular type of stochastic processes where only the present value X(t) is relevant for predicting the future evolution of X.  Therefore, the past and the future of a Markov process have no direct interconnection.  More formally we have:\n",
    "\n",
    "#### Definition 3: Markov Process\n",
    "A continuous-time stochastic process X(t),$t \\in T$, is called a Markov process if for any finite parameter set $\\{t_i:t_i<t_{i+1}\\}\\in T$ we have\n",
    "$$P(X(t_{n+1})\\in B|X(t_1),\\dots,X(t_n))=P(X(t_{n+1}\\in B|X(t_n))$$\n",
    "\n",
    "For a markov process X(t) we define the transition probability, denoted by P(s,x,t,B) as follows:\n",
    "$$ P(s,x,t,B)=P(X(t)\\in B|X(s)=x), 0\\le s\\le t $$\n",
    "\n",
    "The function P gives the probability of X(t) lying in the set B at time t, given the value x of the process at time s.  The transition density p is implicitly defined as \n",
    "$$ P(s,x,t,B)=\\int_B{p(s,x,t,y)dy} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Process\n",
    "\n",
    "A stochastic process is called Gaussian if all of its joint probability distributions are Gaussians.  If X(t) is a Gaussian process then $X(t)~\\mathcal{N}(\\mu(t),\\sigma^2(t))$ for all t, where $\\mu(t)$ and $\\sigma^2(t)$ are arbitrary functions.  A Gaussian process is fully characterised by its mean covariance function.  Gaussian processes do have many nice mathematical properties.  For example performing linear algebraic operations on a Gaussian process yields a Gaussian process.  Another important property is that the limit of a Gaussian random sequence remains a Gaussian process.  Hence, the mean square derivatives and integrals of Gaussian processes themselves.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Martingales\n",
    "\n",
    "A stochastic process X(t) is a martingale on the filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t\\ge 0},P)$ if the following conditions hold:\n",
    "- X(t) is $\\{\\mathcal{F}_t\\}_{t\\ge 0}-\\text{adapted, }E||X(t)||< \\infty\\text{ for all }t\\ge 0$\n",
    "- $E[X(t)|\\mathcal{F}_s]=X(s)$ a.s. for all $s \\in [0,t]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this definition, it follows that the best prediction of a martingale process is its current value.  We therefore state that martingale processes model fair games.  If we consider a coin tossing game where the player gains one dollar on head and loses one dollar on tail the wealth of the player follows a martingale. The martingale theory is a fundamental tool in finance, and the theory it is vast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIffusions\n",
    "\n",
    "A diffusion is a Markov process with continuous trajectories such that for each time t and state X(t) the following limits exist.\n",
    "$$\\mu(t,X(t)):=\\lim_{\\Delta\\downarrow 0}\\frac{1}{\\Delta t}E[X(t+\\Delta t)-X(t)|X(t)],$$\n",
    "$$\\sigma^2(t,X(t)):=\\lim_{\\Delta\\downarrow 0}\\frac{1}{\\Delta t}E[\\{X(t+\\Delta t)-X(t)\\}^2|X(t)]$$\n",
    "For these limits,$\\mu(t,X(t))$ is called drift and $\\sigma^2(t,X(t))$ is called the diffusion coefficient.  Since diffusion are Markov processes we expect a relationship between the transition probability and  $\\mu(t,X(t))$,  $\\sigma^2(t,X(t))$.  Actually, under certain assumptions, the transition probability is uniquely determined by $\\mu(t,X(t))$ and $\\sigma^2(t,X(t))$.  This is a pretty surprising result because usually distribtioni s not completely determined by its first two moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brownian Motion and White Noise\n",
    "\n",
    "#### Brownian Motion\n",
    "\n",
    "Motivated by the apparently random walk of a tiny particle in a fluid (observed by the Scottish botanist Robert Brownian in 1827), the American mathematician Norbert Wiener stipulated the following assumptions for a stationary random process W(-,-) with independents in 1923:\n",
    "\n",
    "#### Definition 2.6: Brownian Motion\n",
    "A stochastic process W(t) is called Brownian motion if\n",
    "1. Independence: $W(t+\\Delta t)-W(t)$ is independent of $\\{W(\\tau)\\}$ for all $\\tau\\le t$.\n",
    "2. Stationarity: The distribution of $W(t+\\Delta t) - W(t)$ does not depend on t.\n",
    "3. Continuity: $lim_{\\Delta\\downarrow 0}\\frac{P(|W(t+\\Delta t)-W(t)|\\ge \\delta)}{\\Delta t}=0 \\text{ for all } \\delta > 0$.\n",
    "\n",
    "Please note that the third assumption is expressed with probabilities: discontinuities in sample functions can only occur with probability zero.  Hence, there is a version of the Brownian motion with all sample functions continuous. (This technically is not of any practical importance.)\n",
    "\n",
    "This definition induces the distribution of the process $W_t$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 2.7 Normally distributed increments of Brownian motion \n",
    "Normally distributed increments of Brownian motion with mean $\\mu t$ and variance $\\sigma^2t$, where $\\mu$ and $\\sigma$ are constant real numbers.\n",
    "\n",
    "As a result of this theorem, we have the following density function of a Brownian motion:\n",
    "$$ f_{W(t)}(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2t}}e^\\frac{(x-\\mu t)^2}{2\\sigma^2 t}$$\n",
    "\n",
    "An irritating property of Brownian motion is that its sample paths are not differentiable.  This is easily verified in the mean-square sence:\n",
    "$$E\\left[\\left(\\frac{W(t+\\Delta t)-W(t)}{\\Delta t}\\right)^2\\right]=\n",
    "\\frac{E[(W(t+\\Delta t)-W(t))^2]}{\\Delta t^2}=\\frac{\\sigma^2}{\\Delta t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diverges for $\\Delta t\\rightarrow 0$ and therefore it is not differentiable in $L^2$.  This is also the case for almost sure convergence, but this is much mnore difficult to prove.\n",
    "\n",
    "The brownian motion has many bizarre and intriguing properties.  Some of them are listed below:\n",
    "\n",
    "- Autocovariance function: $E{(W(t)-\\mu t)(W(\\tau)-\\mu\\tau)}=\\sigma^2min(t,\\tau)$.\n",
    "- $Var\\left\\{\\frac{W(t)}{t}\\right\\}=\\frac{\\sigma^2}{t}$\n",
    "- $\\lim_{t\\rightarrow\\infty}\\frac{W(t)-\\mu t}{t}=0$ with probability 1\n",
    "- The total variation of the Brownian motion over a finite interval [0,T] is infinite!\n",
    "- The \"sum of squares\" of a drift-free Brownian motion is deterministic:\n",
    "$$\\lim_{N\\rightarrow\\infty}\\sum_{k=1}^N\\left[W\\left(k\\frac{T}{N}\\right)-W\\left((k-1)\\frac{T}{N}\\right)\\right]^2=\\sigma^2T$$\n",
    "- Infinite oscillations:  Let $Y_0,Y_1,\\dots$ be mutually independent random variables are identical normal distrubutions $\\mathcal{N}(0,1)$. The random process\n",
    "$$X(t)=\\frac{Y_0}{\\sqrt{\\pi}}t+\\sum_{k=1}^\\infty\\sqrt{\\frac{2}{pi}}\\frac{Y_k}{k}\\sin{kt}\\text{ for }t\\in[0,\\pi]$$\n",
    "is a normalised Brownian motion on the interval $[0,\\pi]$.\n",
    "\n",
    "- If W(.) is a Brownian motion on the interval $[0,\\infty)$ then the follwoing W*(.) is a Brownian motion as well:\n",
    "$$W*(t)=\\left\\{\\begin{matrix} tW(1/t), & \\text{ for }t>0;\\\\0, & \\text{ for }t=0 \\end{matrix}\\right.$$\n",
    "- Zero crossings:  In a finite interval $[0,T]$, every sample of a drift-free Brownian motion has infinitely many zero-crossings.  The set of zero-crossings is dense in [0,T], i.e., no sample path has isolated zero-crossings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2.8 Standard Brownian motion\n",
    "A Brownian motion is standard if\n",
    "\\begin{aligned} W(0)=0\\text{ a.s., }\n",
    "\\\\E[W(t)]=0\\text{ }(\\mu=0)\n",
    "\\\\E[W^2(t)]=t\\text{ }(\\sigma^2=1)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Brownian motionis usually assumed to be standard if not explicitly stated otherwise.\n",
    "\n",
    "We have already stated that the \"sum of squares\" of a drift-free Brownian motion is deterministic.  This can be formulated more generally as follows:\n",
    "\n",
    "#### Theorem 2.9.  Quadratic variation of standard Brownian motion\n",
    "The quadratic variation of standard Brownian motion over [0,t] exists and equals t.  Formally, we can also write $(dW(t))^2=dt$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise\n",
    "\n",
    "Brownian motion is continuous but nowhere differentiable.  Nevertheless, in engineering circles, it is customary to define a random process v(.) called a stationary white noise as the formal derivative of a general Brownian motion W(.) with the drift parameter $\\mu$ and the variance parameter $\\sigma^2$:\n",
    "$$v(t)=\\frac{dW(t)}{dt}$$\n",
    "\n",
    "Usually, the \"initial\" time is shifted from t = 0 to t= $-infty$.  In this way, the white noise v(.) becomes truly stationary on the infinite time interval $(-\\infty,\\infty)$.  Without loss of generality, we may assume that v(t) is Gaussian for all t.\n",
    "\n",
    "This stationary white noise is characterised uniquely as follows:\n",
    "\n",
    "- Expected value $$E{v(t)}\\equiv \\mu$$\n",
    "- Autocovariance function:$$\\sum_{(\\tau)}=E\\{[v(t+\\tau)-\\mu][v(t)-\\mu]\\}\\equiv\\sigma^2\\delta(\\tau)$$\n",
    "- Spectral density function: $$S(\\omega)=\\sum_{(\\tau)}=\\int_{-infty}^{infty}e^{-j\\omega\\tau}\\sum_{(\\tau)}d\\tau\\equiv\\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the characterisations by the autocovariance function and the spectral density function are redundant.\n",
    "\n",
    "Using white noise as the model of a completely unpredictable random process, we can say: the continuous-time measurement y of the third state variable $x_3$ is corrupted by an addictive white noise v:\n",
    "$$y(t)=x_3(t)+v(t)$$\n",
    "Expressing the same fact in full mathematical correctness using a Brownian motion, we would have to say:  The integral of the continuous-time measurement y of the third state variable $x_3$ is corrupted by an addictive Brownian motion W.\n",
    "$$ \\int_0^ty(t)dt=\\int_0^tx_3(t)+W(t)$$\n",
    "\n",
    "Yet another way of expressing ourselves in full mathematical correctness could be: The short-time averaged (or smoothed) measurement of $\\bar{y}$ of the third state variable $x_3$ is corrupted by an additive increment of a Brownian motion W:\n",
    "$$\\bar{y}(t)=\\frac{1}{\\Delta T}\\int_{t-\\Delta T}^ty(t)dt=\\frac{1}{\\Delta T}x_3(t)dt+\\frac{W(t)-W(t-\\Delta T)}{\\Delta T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be obvious where this leads to mathematically as $\\Delta T \\downarrow 0$.\n",
    "\n",
    "Of course, smoothing by averaging is not optimal.  Rather a Kalman (or extended Kalman) filter should be used.\n",
    "\n",
    "The Brownian motion W on the time interval [0,$infty$) can be retrieved from the stationary white noise v by integration:\n",
    "$$W(t)=\\int_0^t v(\\alpha)d\\alpha$$\n",
    "\n",
    "Mathematicians prefer to write this equation in the following way:\n",
    "$$W(t)=\\int_0^t v(\\alpha)d\\alpha=\\int_0^t\\frac{dW(\\alpha)}{d\\alpha}=\\int_0^tdW(\\alpha)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, a Brownian motion X with the drift parameter $\\mu$, the variance parameter $\\sigma^2$, and the initial time t=0 satisfies the following stochastic differential equation, where W is a standard Brownian motion:\n",
    "$$\\begin{aligned}dX(t) = &\\mu dt+\\sigma dW(t)\\\\X(0) = &0 \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
