{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CorpusId</th>\n",
       "      <th>Audio</th>\n",
       "      <th>BookStatsId</th>\n",
       "      <th>CText</th>\n",
       "      <th>Chapt</th>\n",
       "      <th>Verse</th>\n",
       "      <th>PText</th>\n",
       "      <th>ReadersId</th>\n",
       "      <th>UText</th>\n",
       "      <th>Image</th>\n",
       "      <th>Image2</th>\n",
       "      <th>Verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>nyo koruapu ma igbiki mi oki se ini duko ini p...</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>nyọ koruapụ ma igbiki mị ọkị se ini ḍuko ini p...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt28_15-20.PNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>ọḅụḍuko oyighọrịapụ fịnjị ma Galili chịngị mi ...</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>ọḅụḍuko oyighọrịapụ fịnjị ma Galili chịngị mi ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt28_15-20.PNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>Ini ori ori siki ini kpereki o tekeme, inia bi...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>Ini ori ọrị sịkị ini kpẹrẹkị ọ tẹkẹmẹ inia ḅie...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt28_15-20.PNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>jizọs Be kpekima mun se nwose ini ḅẹme “Ini Ku...</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>jizọs ḅe kpekima mun se nwọse ini ḅẹmẹ “Ini kụ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt28_15-20.PNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>Min Jizos Kraist be pakabo furo mi simeoku-e, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mịn jizọs kraịst ḅe pakaḅo furo mị simeọkụ-ẹ D...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt01_01-03.png</td>\n",
       "      <td>matt01_03-21.png</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CorpusId  Audio  BookStatsId  \\\n",
       "0         1    NaN           40   \n",
       "1         2    NaN           40   \n",
       "2         3    NaN           40   \n",
       "3         4    NaN           40   \n",
       "4        75    NaN           40   \n",
       "\n",
       "                                               CText  Chapt  Verse  \\\n",
       "0  nyo koruapu ma igbiki mi oki se ini duko ini p...     28     15   \n",
       "1  ọḅụḍuko oyighọrịapụ fịnjị ma Galili chịngị mi ...     28     16   \n",
       "2  Ini ori ori siki ini kpereki o tekeme, inia bi...     28     17   \n",
       "3  jizọs Be kpekima mun se nwose ini ḅẹme “Ini Ku...     28     18   \n",
       "4  Min Jizos Kraist be pakabo furo mi simeoku-e, ...      1      1   \n",
       "\n",
       "                                               PText  ReadersId  UText  \\\n",
       "0  nyọ koruapụ ma igbiki mị ọkị se ini ḍuko ini p...          1    NaN   \n",
       "1  ọḅụḍuko oyighọrịapụ fịnjị ma Galili chịngị mi ...          1    NaN   \n",
       "2  Ini ori ọrị sịkị ini kpẹrẹkị ọ tẹkẹmẹ inia ḅie...          1    NaN   \n",
       "3  jizọs ḅe kpekima mun se nwọse ini ḅẹmẹ “Ini kụ...          1    NaN   \n",
       "4  mịn jizọs kraịst ḅe pakaḅo furo mị simeọkụ-ẹ D...          1    NaN   \n",
       "\n",
       "              Image            Image2  Verified  \n",
       "0  matt28_15-20.PNG               NaN       NaN  \n",
       "1  matt28_15-20.PNG               NaN       NaN  \n",
       "2  matt28_15-20.PNG               NaN       NaN  \n",
       "3  matt28_15-20.PNG               NaN       NaN  \n",
       "4  matt01_01-03.png  matt01_03-21.png       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = data[\"CText\"].copy()\n",
    "dst = data[\"PText\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nyo koruapu ma igbiki mi oki se ini duko ini p...\n",
       "1    ọḅụḍuko oyighọrịapụ fịnjị ma Galili chịngị mi ...\n",
       "2    Ini ori ori siki ini kpereki o tekeme, inia bi...\n",
       "3    jizọs Be kpekima mun se nwose ini ḅẹme “Ini Ku...\n",
       "4    Min Jizos Kraist be pakabo furo mi simeoku-e, ...\n",
       "Name: CText, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove punctuation symbols\n",
    "Punctuation Rules in English\n",
    "1. the period (or full stop in British English)\n",
    "2. the comma.\n",
    "3. the exclamation mark.\n",
    "4. the question mark.\n",
    "5. the colon.\n",
    "6. the semicolon.\n",
    "7. the quotation mark.\n",
    "8. the apostrophe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1=[txt.lower().replace(\".\",\"\").replace(\",\",\"\").replace(\"ẹ\",\"e\")\n",
    "      .replace(\"!\",\"\").replace(\"?\",\"\").replace(\"“\",\"\").replace(\"ḍ\",\"d\")\n",
    "      .replace(\":\",\"\").replace(\";\",\"\").replace(\"ị\",\"i\").replace(\"ḅ\",\"b\")\n",
    "      .replace(\"'\",\"\").replace(\"”\",\"\").replace(\"ọ\",\"o\")\n",
    "      .replace(\"'\",\"\").replace(\"”\",\"\").replace(\"ụ\",\"u\")\n",
    "      .replace('\"',\"\") for txt in src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst1=[txt.lower().replace(\".\",\"\").replace(\",\",\"\")\n",
    "      .replace(\"!\",\"\").replace(\"?\",\"\").replace(\"“\",\"\")\n",
    "      .replace(\":\",\"\").replace(\";\",\"\")\n",
    "      .replace(\"'\",\"\").replace(\"”\",\"\")\n",
    "      .replace('\"',\"\") for txt in dst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dst1)==len(src1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(src1[i].split())==len(dst1[i].split()) for i in range(len(src1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40, 40),\n",
       " (16, 16),\n",
       " (16, 16),\n",
       " (19, 18),\n",
       " (22, 22),\n",
       " (20, 18),\n",
       " (25, 25),\n",
       " (15, 15),\n",
       " (21, 21),\n",
       " (18, 18),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (21, 21),\n",
       " (19, 19),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (15, 15),\n",
       " (18, 18),\n",
       " (50, 50),\n",
       " (37, 37),\n",
       " (24, 24),\n",
       " (42, 42),\n",
       " (19, 19),\n",
       " (34, 34),\n",
       " (34, 34),\n",
       " (24, 24),\n",
       " (22, 22),\n",
       " (15, 15),\n",
       " (29, 29),\n",
       " (28, 28),\n",
       " (32, 32),\n",
       " (38, 38),\n",
       " (15, 15),\n",
       " (21, 21),\n",
       " (19, 19),\n",
       " (28, 28),\n",
       " (21, 21),\n",
       " (43, 41),\n",
       " (30, 30),\n",
       " (53, 53),\n",
       " (18, 18),\n",
       " (45, 45),\n",
       " (63, 63),\n",
       " (14, 13),\n",
       " (34, 34),\n",
       " (16, 16),\n",
       " (41, 41),\n",
       " (16, 16),\n",
       " (43, 43),\n",
       " (39, 39),\n",
       " (18, 18),\n",
       " (15, 15),\n",
       " (31, 31),\n",
       " (27, 27),\n",
       " (21, 19),\n",
       " (14, 14),\n",
       " (36, 36),\n",
       " (12, 12),\n",
       " (37, 37),\n",
       " (27, 27),\n",
       " (41, 41),\n",
       " (40, 40),\n",
       " (20, 18),\n",
       " (28, 28),\n",
       " (32, 32),\n",
       " (39, 39),\n",
       " (21, 21),\n",
       " (15, 15),\n",
       " (16, 16)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(src1[i].split()),len(dst1[i].split())) for i in range(len(src1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[len(src1[i].split())==len(dst1[i].split()) for i in range(len(src1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=[i for indx,i in enumerate(src1) if f[indx] == True]\n",
    "dst=[i for indx,i in enumerate(dst1) if f[indx] == True]\n",
    "src0=[i for indx,i in enumerate(src1) if f[indx] == False]\n",
    "dst0=[i for indx,i in enumerate(dst1) if f[indx] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715 1715 ['nyo', 'koruapu'] ['nyọ', 'koruapụ']\n"
     ]
    }
   ],
   "source": [
    "src2=[]\n",
    "dst2=[]\n",
    "for i in range(len(src)):\n",
    "    src2+=src[i].split()\n",
    "    dst2+=dst[i].split()\n",
    "print(len(src2),len(dst2),src2[:2],dst2[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ds=pd.DataFrame({'Source':src2, 'Target':dst2})\n",
    "ds.to_csv('mle.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=[];y=[]\n",
    "[x.extend(i) for i in dst]\n",
    "[y.extend(i) for i in src]\n",
    "cy=set(x)\n",
    "cx=set(y)\n",
    "cx.add('*')\n",
    "cy.add('*')\n",
    "# print((cx),(cy))\n",
    "cx2ix = { ch:i for i,ch in enumerate(cx) }\n",
    "ix2cx = { i:ch for i,ch in enumerate(cx) }\n",
    "cy2ix = { ch:i for i,ch in enumerate(cy) }\n",
    "ix2cy = { i:ch for i,ch in enumerate(cy) }\n",
    "cyi=np.array([i for i,_ in enumerate(cy)])\n",
    "#cyi=np.append(cyi,[-1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715 1715\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for x in src:\n",
    "    X.extend(x.split())\n",
    "Y=[]\n",
    "[Y.extend(x.split()) for x in dst]\n",
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1715"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inpX = [list(data) for data in X]\n",
    "iX=[]\n",
    "for data in inpX:\n",
    "    subl=[]\n",
    "    for ch in data:\n",
    "        subl.append(cx2ix[ch])\n",
    "    iX.append(subl)\n",
    "len(iX)\n",
    "#iX=np.array(iX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tgtY=[list(data) for data in Y]\n",
    "tY=[]\n",
    "#tY=[cy2ix[ch] for subl in tgtY for ch in data]\n",
    "for data in tgtY:\n",
    "    subl=[]\n",
    "    for ch in data:\n",
    "        subl.append(cy2ix[ch])\n",
    "    tY.append(subl)\n",
    "#tY=np.array(tY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 18 34 ..., 32 32 32]\n",
      " [25  5 13 ..., 32 32 32]\n",
      " [39 14 32 ..., 32 32 32]\n",
      " ..., \n",
      " [ 5 27 23 ..., 32 32 32]\n",
      " [12 42 39 ..., 32 32 32]\n",
      " [37 21 32 ..., 32 32 32]] [[ 1 12  3 ..., 24 24 24]\n",
      " [18  3  9 ..., 24 24 24]\n",
      " [28 10 24 ..., 24 24 24]\n",
      " ..., \n",
      " [ 3 20 16 ..., 24 24 24]\n",
      " [ 8 30 28 ..., 24 24 24]\n",
      " [16  4 24 ..., 24 24 24]]\n"
     ]
    }
   ],
   "source": [
    "sx=[len(x) for x in iX]\n",
    "sy=[len(x) for x in tY]\n",
    "\n",
    "def seqpad(seq,seql):\n",
    "    arr=[]\n",
    "    m=max(seql)\n",
    "    for i in seq:\n",
    "        n=m-len(i)\n",
    "        for j in range(n):\n",
    "            i.append(-1)\n",
    "        arr.append(i)\n",
    "    return arr\n",
    "\n",
    "def seqpad2(seq,m,ix):\n",
    "    arr=[]\n",
    "    for i in seq:\n",
    "        n=m-len(i)\n",
    "        for j in range(n):\n",
    "            i.append(ix)\n",
    "        arr.append(i)\n",
    "    return arr\n",
    "\n",
    "iX=np.array(seqpad2(iX,50,cx2ix['*']))\n",
    "tY=np.array(seqpad2(tY,50,cy2ix['*']))\n",
    "print(tY,iX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,7).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098 274\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "def split_train_test(x,y, test_ratio):\n",
    "    shuffled_indices=np.random.permutation(len(x))\n",
    "    test_set_size=int(len(x)*test_ratio)\n",
    "    test_indices=shuffled_indices[:test_set_size]\n",
    "    train_indices=shuffled_indices[test_set_size:]\n",
    "    return x.iloc[train_indices],x.iloc[test_indices],y.iloc[train_indices],y.iloc[test_indices]\n",
    "\n",
    "xtr, xts,ytr,yts = split_train_test(pd.DataFrame(iX),pd.DataFrame(tY), 0.2)\n",
    "iX = xtr.values\n",
    "tY = ytr.values\n",
    "print(len(tY),len(yts.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "reset_graph()\n",
    "\n",
    "n_steps = 50\n",
    "n_neurons = 200\n",
    "n_layers = 3\n",
    "num_encoder_symbols = len(cx) #20000\n",
    "num_decoder_symbols = len(cy) #20000\n",
    "embedding_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, n_steps]) # English sentences\n",
    "Y = tf.placeholder(tf.int32, [None, n_steps]) # French translations\n",
    "#y = tf.placeholder(tf.int32,[None])\n",
    "w = np.ones( (len(iX), n_steps - 1, 1), dtype=np.float32 )\n",
    "W = tf.Variable(w,name='W')\n",
    "\n",
    "Y_input = Y[:, :-1]\n",
    "Y_target = Y[:, 1:]\n",
    "\n",
    "encoder_inputs = tf.unstack(tf.transpose(X)) # list of 1D tensors\n",
    "decoder_inputs = tf.unstack(tf.transpose(Y_input)) # list of 1D tensors\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "\n",
    "output_seqs, states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "#output_seqs, states = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq(\n",
    "    # X, \n",
    "    encoder_inputs,\n",
    "    # Y_input, \n",
    "    decoder_inputs,\n",
    "    cell,\n",
    "    num_encoder_symbols,num_decoder_symbols,embedding_size\n",
    "    )\n",
    "# encoder_outputs: [max_time, batch_size, num_units]\n",
    "logits = tf.transpose(tf.unstack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "logits_flat = tf.reshape(logits, [-1, num_decoder_symbols])\n",
    "\n",
    "#logits_flat = tf.layers.dense(states,num_decoder_symbols)\n",
    "Y_target_flat = tf.reshape(Y_target, [-1])\n",
    "W_flat = tf.reshape(W, [-1])\n",
    "xentropy = W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y_target_flat, logits=logits_flat)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits_flat, Y_target_flat, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.939184 Test accuracy: 0.94034\n",
      "1 Train accuracy: 0.939184 Test accuracy: 0.94034\n",
      "2 Train accuracy: 0.939184 Test accuracy: 0.94034\n",
      "3 Train accuracy: 0.937679 Test accuracy: 0.937137\n",
      "4 Train accuracy: 0.937177 Test accuracy: 0.936318\n",
      "5 Train accuracy: 0.937177 Test accuracy: 0.93304\n",
      "6 Train accuracy: 0.930635 Test accuracy: 0.927976\n",
      "7 Train accuracy: 0.931824 Test accuracy: 0.929391\n",
      "8 Train accuracy: 0.935207 Test accuracy: 0.935051\n",
      "9 Train accuracy: 0.941322 Test accuracy: 0.942276\n",
      "10 Train accuracy: 0.941378 Test accuracy: 0.942351\n",
      "11 Train accuracy: 0.94134 Test accuracy: 0.942276\n",
      "12 Train accuracy: 0.942734 Test accuracy: 0.94384\n",
      "13 Train accuracy: 0.942883 Test accuracy: 0.943542\n",
      "14 Train accuracy: 0.942902 Test accuracy: 0.943766\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 150\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        #for iteration in range(mnist.train.num_examples // batch_size):\n",
    "        #    X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        #    X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "        sess.run(training_op, feed_dict={X: iX, Y: tY})\n",
    "        acc_train = accuracy.eval(feed_dict={X: iX, Y: tY})\n",
    "        acc_test = accuracy.eval(feed_dict={X: xts.values, Y:yts.values})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "    saver.save(sess,\"./okd_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    return np.ravel(seqpad2([[cx2ix[ch] for ch in x]],50,cx2ix['*']))\n",
    "b=predict('jizos') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def xlate(x):\n",
    "    return np.ravel([ix2cx[c] for c in x])\n",
    "def ylate(x):\n",
    "    return np.ravel([ix2cy[c] for c in x])\n",
    "#xlate(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./okd_model.mdl\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                          # not shown in the book\n",
    "    saver.restore(sess, \"./okd_model.mdl\")   # not shown\n",
    "\n",
    "    X_new = np.array([b])\n",
    "    ypad = np.array([np.ravel(seqpad2([[cy2ix['*']]],50,cy2ix['*']))])\n",
    "    y_pred = sess.run(logits_flat, feed_dict={X: X_new, Y:ypad })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-568bb88910d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_flat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\u1273400\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\u001b[0m in \u001b[0;36msparse_softmax\u001b[0;34m(sp_input, name)\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \"\"\"\n\u001b[1;32m   1656\u001b[0m   with ops.name_scope(name, \"SparseSoftmax\",\n\u001b[0;32m-> 1657\u001b[0;31m                       [sp_input.indices, sp_input.values]) as name:\n\u001b[0m\u001b[1;32m   1658\u001b[0m     out_vals = gen_sparse_ops.sparse_softmax(sp_input.indices, sp_input.values,\n\u001b[1;32m   1659\u001b[0m                                              sp_input.dense_shape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "smp=W_flat * tf.sparse_softmax(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse_softmax() got an unexpected keyword argument 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-23c418e649fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_flat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse_softmax() got an unexpected keyword argument 'logits'"
     ]
    }
   ],
   "source": [
    "for pred in y_pred:\n",
    "    smp=W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=cyi, logits=pred)\n",
    "    print(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
