{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import my_txtutils\n",
    "import re\n",
    "import nltk\n",
    "mypath='./new_txts/'\n",
    "txts='./txts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acts_new.txt', 'gal_eph_new.txt', 'heb_new.txt', 'jam_jud_new.txt', 'john_new.txt', 'jud_rev_new.txt', 'luke_8_john_new.txt', 'mark01_new.txt', 'matt02_new.txt', 'matt_new.txt', 'phil_col_new.txt', 'thes_tim_new.txt', 'tit_phl_new.txt']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(txts) if isfile(join(txts, f))]\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 lines written\n"
     ]
    }
   ],
   "source": [
    "#large files\n",
    "def large_f():\n",
    "    #filenames = ['file1.txt', 'file2.txt', ...]\n",
    "    with open(mypath+'full.txt', 'w') as outfile:\n",
    "        for fname in onlyfiles:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "#large files\n",
    "def decimate_f(f):\n",
    "    #filenames = ['file1.txt', 'file2.txt', ...]\n",
    "    with open(mypath+'tmp.txt', 'w') as outfile:\n",
    "        with open(mypath+f) as infile:\n",
    "            lc=0\n",
    "            for line in infile:\n",
    "                wrap=False\n",
    "                cx=0\n",
    "                tmp=\"\"\n",
    "                for i in line:\n",
    "                    wrap=True if cx>99 else False\n",
    "                    if (wrap==True and i==' '):\n",
    "                        tmp+='\\n'\n",
    "                        cx=-1\n",
    "                    else:\n",
    "                        tmp+=i\n",
    "                    cx+=1\n",
    "                outfile.write(tmp)\n",
    "                lc+=1\n",
    "    print(lc,'lines written')\n",
    "decimate_f('full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#small files\n",
    "def small_f():\n",
    "    #filenames = ['file1.txt', 'file2.txt', ...]\n",
    "    with open(mypath+'full.txt', 'w') as outfile:\n",
    "        for fname in onlyfiles:\n",
    "            print('writing file',fname)\n",
    "            with open(txts+fname) as infile:\n",
    "                outfile.write(infile.read())\n",
    "    return open(mypath+\"full.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing file acts_new.txt\n",
      "writing file gal_eph_new.txt\n",
      "writing file heb_new.txt\n",
      "writing file jam_jud_new.txt\n",
      "writing file john_new.txt\n",
      "writing file jud_rev_new.txt\n",
      "writing file luke_8_john_new.txt\n",
      "writing file mark01_new.txt\n",
      "writing file matt02_new.txt\n",
      "writing file matt_new.txt\n",
      "writing file phil_col_new.txt\n",
      "writing file thes_tim_new.txt\n",
      "writing file tit_phl_new.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "649190"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt=small_f()\n",
    "words=re.sub(' +', ' ',txt.replace('\\n',' ')).split(' ')\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6507438"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/rnn_train_1563814502-18000000\n",
      "OODRDD,\u0000 \u0000s\u0000a\u0000y\u0000i\u0000n\u0000g\u0000,\u0000\n",
      "\u0000T\u0000h\u0000e\u0000 \u0000s\u0000e\u0000n\u0000 \u0000o\u0000f\u0000 \u0000I\u0000s\u0000r\u0000a\u0000e\u0000l\u0000,\u0000 \u0000s\u0000a\u0000y\u0000i\u0000n\u0000g\u0000,\u0000 \u0000T\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000h\u0000a\u0000t\u0000h\u0000 \u0000s\u0000e\u0000e\u0000n\u0000 \u0000t\u0000h\u0000e\u0000e\n",
      "\u0000 \u0000t\u0000o\u0000 \u0000p\u0000a\u0000s\u0000s\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000,\u0000 \u0000t\u0000h\u0000a\u0000t\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000s\u0000h\u0000a\u0000l\u0000l\u0000 \u0000b\u0000e\u0000 \u0000u\u0000n\u0000c\u0000l\u0000e\u0000a\u0000n\u0000.\n",
      "\u0000\n",
      "\u0000A\u0000n\u0000d\u0000 \u0000t\u0000h\u0000e\u0000 \u0000s\u0000a\u0000m\u0000e\u0000 \u0000s\u0000a\u0000w\u0000 \u0000t\u0000h\u0000e\u0000r\u0000e\u0000o\u0000f\u0000 \u0000s\u0000h\u0000a\u0000l\u0000l\u0000 \u0000b\u0000e\u0000 \u0000u\u0000n\u0000c\u0000l\u0000e\u0000a\u0000n\u0000.\u0000\n",
      "\u0000A\u0000n\u0000d\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000s\u0000a\u0000i\u0000d\u0000,\u0000 \u0000T\u0000h\u0000u\u0000s\u0000 \u0000s\u0000a\u0000i\u0000t\u0000h\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000,\u0000 \u0000t\u0000h\u0000a\u0000t\u0000 \u0000t\u0000h\u0000e\u0000y\u0000 \n",
      "\u0000s\u0000h\u0000a\u0000l\u0000l\u0000 \u0000b\u0000r\u0000i\u0000n\u0000g\u0000 \u0000t\u0000h\u0000y\u0000 \u0000s\u0000o\u0000u\u0000l\u0000 \u0000w\u0000i\u0000t\u0000h\u0000 \u0000t\u0000h\u0000e\u0000 \u0000s\u0000t\u0000r\u0000a\u0000n\u0000g\u0000e\u0000r\u0000s\u0000,\u0000 \u0000a\u0000n\u0000d\u0000 \u0000t\u0000o\u0000 \u0000s\u0000p\n",
      "\u0000e\u0000a\u0000k\u0000,\u0000 \u0000t\u0000o\u0000 \u0000s\u0000a\u0000y\u0000 \u0000u\u0000n\u0000t\u0000o\u0000 \u0000t\u0000h\u0000e\u0000m\u0000,\u0000 \u0000W\u0000h\u0000a\u0000t\u0000 \u0000s\u0000a\u0000y\u0000 \u0000u\u0000n\u0000t\u0000o\u0000 \u0000t\u0000h\u0000e\u0000e\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\n",
      "\u0000,\u0000 \u0000a\u0000n\u0000d\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000s\u0000h\u0000o\u0000u\u0000l\u0000d\u0000 \u0000s\u0000a\u0000y\u0000 \u0000u\u0000n\u0000t\u0000o\u0000 \u0000h\u0000i\u0000m\u0000,\u0000 \u0000T\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000s\u0000p\u0000a\u0000k\u0000e\n",
      "\u0000 \u0000u\u0000n\u0000t\u0000o\u0000 \u0000h\u0000i\u0000m\u0000,\u0000 \u0000W\u0000h\u0000o\u0000 \u0000h\u0000a\u0000t\u0000h\u0000 \u0000s\u0000e\u0000n\u0000t\u0000 \u0000t\u0000o\u0000 \u0000p\u0000a\u0000s\u0000s\u0000 \u0000i\u0000n\u0000t\u0000o\u0000 \u0000t\u0000h\u0000e\u0000 \u0000s\u0000e\u0000r\u0000v\u0000a\u0000n\u0000t\u0000,\n",
      "\u0000 \u0000a\u0000n\u0000d\u0000 \u0000t\u0000o\u0000 \u0000s\u0000e\u0000r\u0000v\u0000e\u0000 \u0000t\u0000h\u0000e\u0000 \u0000c\u0000h\u0000i\u0000e\u0000f\u0000 \u0000o\u0000f\u0000f\u0000e\u0000r\u0000i\u0000n\u0000g\u0000,\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000s\u0000h\u0000a\u0000l\u0000l\u0000 \u0000s\n",
      "\u0000e\u0000e\u0000 \u0000t\u0000h\u0000e\u0000 \u0000L\u0000O\u0000R\u0000D\u0000 \u0000t\u0000o\u0000 \u0000G\u0000o\u0000d\u0000 \u0000i\u0000n\u0000 \u0000t\u0000h\u0000e\u0000 \u0000s\u0000e\u0000r\u0000v\u0000a\u0000n\u0000t\u0000 \u0000o\u0000f\u0000 \u0000I\u0000s\u0000r\u0000a\u0000e\u0000l\u0000"
     ]
    }
   ],
   "source": [
    "# these must match what was saved !\n",
    "ALPHASIZE = my_txtutils.ALPHASIZE\n",
    "NLAYERS = 3\n",
    "INTERNALSIZE = 512\n",
    "\n",
    "ok02 =\"checkpoints/rnn_train_1560839489-30000000\" # okrika 2019-06-18\n",
    "ok03 =\"checkpoints/rnn_train_1563601394-60000000\" # okrika 2019-07-20\n",
    "bb01 =\"checkpoints/rnn_train_1563814502-18000000\" # bible 2019-07-22\n",
    "\n",
    "author=bb01\n",
    "\n",
    "ncnt = 0\n",
    "with tf.Session() as sess:\n",
    "    # new_saver = tf.train.import_meta_graph('checkpoints/rnn_train_1512567262-0.meta')\n",
    "    new_saver = tf.train.import_meta_graph(author+'.meta')\n",
    "    new_saver.restore(sess, author)\n",
    "    x = my_txtutils.convert_from_alphabet(ord(\"L\"))\n",
    "    x = np.array([[x]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "\n",
    "    # initial values\n",
    "    y = x\n",
    "    h = np.zeros([1, INTERNALSIZE * NLAYERS], dtype=np.float32)  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n",
    "    for i in range(1000):\n",
    "        yo, h = sess.run(['Yo:0', 'H:0'], feed_dict={'X:0': y, 'pkeep:0': 1., 'Hin:0': h, 'batchsize:0': 1})\n",
    "        #print(tf.shape(yo))\n",
    "        #print(len(yo))\n",
    "        c = my_txtutils.sample_from_probabilities(yo, topn=2)\n",
    "        y = np.array([[c]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "        c = chr(my_txtutils.convert_to_alphabet(c))\n",
    "        print(c, end=\"\")\n",
    "        if c == '\\n':\n",
    "            ncnt = 0\n",
    "        else:\n",
    "            ncnt += 1\n",
    "        if ncnt == 100:\n",
    "            print(\"\")\n",
    "            ncnt = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/rnn_train_1563814502-18000000\n",
      "I : 2 : 0.0 ,max= 0.021843001 ='\u0000' or \u0000\n",
      "  : 89 : 0.0 ,max= 0.03725405 ='s' or s\n",
      "w : 75 : 0.0 ,max= 0.08176538 ='s' or s\n",
      "i : 78 : 0.0 ,max= 0.15770254 ='\u0000' or \u0000\n",
      "l : 78 : 0.0 ,max= 0.26536465 ='s' or s\n",
      "l : 2 : 0.0 ,max= 0.9873104 ='\u0000' or \u0000\n",
      "  : 85 : 0.0 ,max= 0.15239526 ='t' or t\n",
      "s : 67 : 0.0 ,max= 0.15094186 ='\u0000' or \u0000\n",
      "a : 91 : 0.0 ,max= 0.8122729 ='\u0000' or \u0000\n",
      "y : 2 : 0.45777845 ,max= 0.45777845 =' ' or  \n",
      "  : 87 : 0.0 ,max= 0.9496611 ='\u0000' or \u0000\n",
      "u : 80 : 0.2012075 ,max= 0.2012075 ='n' or n\n",
      "n : 86 : 0.0 ,max= 0.66236836 ='n' or n\n",
      "t : 81 : 0.0 ,max= 0.9999535 ='\u0000' or \u0000\n",
      "o : 2 : 0.0 ,max= 0.35473773 ='t' or t\n",
      "  : 74 : 0.0 ,max= 0.99999845 ='\u0000' or \u0000\n",
      "h : 75 : 0.0 ,max= 0.39989376 ='o' or o\n",
      "i : 85 : 0.0 ,max= 0.9999908 ='\u0000' or \u0000\n",
      "s : 2 : 0.0 ,max= 0.7822604 ='n' or n\n",
      "  : 85 : 0.0 ,max= 0.9999951 ='\u0000' or \u0000\n",
      "s : 81 : 0.0 ,max= 0.2110508 ='t' or t\n",
      "o : 80 : 0.0 ,max= 0.9999993 ='\u0000' or \u0000\n",
      "n : 14 : 0.0 ,max= 0.83871084 ='n' or n\n",
      ", : 2 : 0.0 ,max= 0.99997795 ='\u0000' or \u0000\n",
      "  : 54 : 0.0 ,max= 0.9832993 =' ' or  \n",
      "T : 74 : 0.0 ,max= 0.99977905 ='\u0000' or \u0000\n",
      "h : 81 : 0.0 ,max= 0.5378415 ='a' or a\n",
      "o : 87 : 0.0 ,max= 0.9999913 ='\u0000' or \u0000\n",
      "u : 2 : 0.0 ,max= 0.2569724 ='m' or m\n",
      "  : 85 : 0.0 ,max= 0.9999769 ='\u0000' or \u0000\n",
      "s : 74 : 0.0 ,max= 0.20792098 ='t' or t\n",
      "h : 67 : 0.0 ,max= 0.99999344 ='\u0000' or \u0000\n",
      "a : 78 : 0.0 ,max= 0.32169816 ='i' or i\n",
      "l : 86 : 0.0 ,max= 0.9999993 ='\u0000' or \u0000\n",
      "t : 97 : 0.0 ,max= 0.31453747 ='a' or a\n",
      "\n",
      " : 2 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "  : 80 : 0.11167173 ,max= 0.11167173 ='n' or n\n",
      "n : 81 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "o : 86 : 0.0 ,max= 0.42303726 ='o' or o\n",
      "t : 2 : 0.0 ,max= 0.9999999 ='\u0000' or \u0000\n",
      "  : 68 : 0.0 ,max= 0.5764722 =' ' or  \n",
      "b : 71 : 0.0 ,max= 0.9999925 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.32240865 ='l' or l\n",
      "  : 85 : 0.0 ,max= 0.9999932 ='\u0000' or \u0000\n",
      "s : 67 : 0.0 ,max= 0.19251288 ='t' or t\n",
      "a : 88 : 0.0 ,max= 0.99978524 ='\u0000' or \u0000\n",
      "v : 71 : 0.0 ,max= 0.61519724 ='n' or n\n",
      "e : 70 : 0.0 ,max= 0.9999982 ='\u0000' or \u0000\n",
      "d : 14 : 0.0 ,max= 0.47168446 ='d' or d\n",
      ", : 2 : 0.0 ,max= 0.9999584 ='\u0000' or \u0000\n",
      "  : 86 : 0.0 ,max= 0.9713969 =' ' or  \n",
      "t : 74 : 0.0 ,max= 0.9999746 ='\u0000' or \u0000\n",
      "h : 67 : 0.0 ,max= 0.3104499 ='h' or h\n",
      "a : 86 : 0.0 ,max= 0.99999547 ='\u0000' or \u0000\n",
      "t : 2 : 0.0 ,max= 0.31219465 ='n' or n\n",
      "  : 43 : 0.0 ,max= 0.9999747 ='\u0000' or \u0000\n",
      "I : 2 : 0.0 ,max= 0.17879158 ='d' or d\n",
      "  : 85 : 0.0 ,max= 0.9999864 ='\u0000' or \u0000\n",
      "s : 67 : 0.0 ,max= 0.2389179 ='t' or t\n",
      "a : 91 : 0.0 ,max= 0.99999535 ='\u0000' or \u0000\n",
      "y : 2 : 0.0 ,max= 0.80949414 ='n' or n\n",
      "  : 87 : 0.0 ,max= 0.9999918 ='\u0000' or \u0000\n",
      "u : 80 : 0.0 ,max= 0.2185347 ='d' or d\n",
      "n : 86 : 0.0 ,max= 0.99997175 ='\u0000' or \u0000\n",
      "t : 81 : 0.0 ,max= 0.3000389 ='a' or a\n",
      "o : 2 : 0.0 ,max= 0.9999999 ='\u0000' or \u0000\n",
      "  : 86 : 0.38343862 ,max= 0.38343862 ='t' or t\n",
      "t : 74 : 0.0 ,max= 0.9999907 ='\u0000' or \u0000\n",
      "h : 71 : 0.0 ,max= 0.58840495 =' ' or  \n",
      "e : 79 : 0.0 ,max= 0.9999813 ='\u0000' or \u0000\n",
      "m : 14 : 0.0 ,max= 0.44266346 ='o' or o\n",
      ", : 2 : 0.0 ,max= 0.999984 ='\u0000' or \u0000\n",
      "  : 57 : 0.0 ,max= 0.9580292 =' ' or  \n",
      "W : 71 : 0.0 ,max= 0.99968886 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.37265202 ='a' or a\n",
      "  : 74 : 0.0 ,max= 0.99943393 ='\u0000' or \u0000\n",
      "h : 67 : 0.0 ,max= 0.6540426 ='t' or t\n",
      "a : 88 : 0.0 ,max= 0.9999622 ='\u0000' or \u0000\n",
      "v : 71 : 0.0 ,max= 0.17537138 ='l' or l\n",
      "e : 2 : 0.0 ,max= 0.9999994 ='\u0000' or \u0000\n",
      "  : 69 : 0.0 ,max= 0.24337645 =' ' or  \n",
      "c : 81 : 0.0 ,max= 0.9999893 ='\u0000' or \u0000\n",
      "o : 80 : 0.0 ,max= 0.6665061 ='h' or h\n",
      "n : 85 : 0.0 ,max= 0.99995553 ='\u0000' or \u0000\n",
      "s : 87 : 0.0 ,max= 0.29341754 ='e' or e\n",
      "u : 97 : 0.0 ,max= 0.9999987 ='\u0000' or \u0000\n",
      "\n",
      " : 79 : 0.0 ,max= 0.23028229 ='s' or s\n",
      "m : 71 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "e : 70 : 0.0 ,max= 0.4088169 ='e' or e\n",
      "d : 2 : 0.0 ,max= 0.99999964 ='\u0000' or \u0000\n",
      "  : 79 : 0.0 ,max= 0.4934578 ='e' or e\n",
      "m : 91 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "y : 2 : 0.0 ,max= 0.3555947 ='e' or e\n",
      "  : 72 : 0.0 ,max= 0.99998784 ='\u0000' or \u0000\n",
      "f : 67 : 0.0 ,max= 0.3192123 ='o' or o\n",
      "a : 86 : 0.0 ,max= 0.99995506 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.5863802 ='n' or n\n",
      "h : 71 : 0.0 ,max= 0.99998045 ='\u0000' or \u0000\n",
      "e : 84 : 0.0 ,max= 0.48223498 ='e' or e\n",
      "r : 14 : 0.0 ,max= 0.99991226 ='\u0000' or \u0000\n",
      ", : 2 : 0.0 ,max= 0.43343726 ='e' or e\n",
      "  : 67 : 0.0 ,max= 0.9993068 ='\u0000' or \u0000\n",
      "a : 80 : 0.0 ,max= 0.20760004 ='t' or t\n",
      "n : 70 : 0.0 ,max= 0.99994373 ='\u0000' or \u0000\n",
      "d : 2 : 0.0 ,max= 0.4034478 ='a' or a\n",
      "  : 86 : 0.0 ,max= 0.9999001 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.35999116 ='t' or t\n",
      "h : 71 : 0.0 ,max= 0.99996436 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.5257878 ='i' or i\n",
      "  : 79 : 0.0 ,max= 0.9999889 ='\u0000' or \u0000\n",
      "m : 75 : 0.0 ,max= 0.1921801 ='s' or s\n",
      "i : 73 : 0.0 ,max= 0.9999827 ='\u0000' or \u0000\n",
      "g : 74 : 0.0 ,max= 0.630117 ='n' or n\n",
      "h : 86 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "t : 91 : 0.0 ,max= 0.30944675 =' ' or  \n",
      "y : 2 : 0.0 ,max= 0.9999975 ='\u0000' or \u0000\n",
      "  : 79 : 0.0 ,max= 0.5360932 =' ' or  \n",
      "m : 67 : 0.0 ,max= 0.99999774 ='\u0000' or \u0000\n",
      "a : 80 : 0.0 ,max= 0.3271257 ='a' or a\n",
      "n : 2 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "  : 86 : 0.0 ,max= 0.16985317 =' ' or  \n",
      "t : 74 : 0.0 ,max= 0.99999833 ='\u0000' or \u0000\n",
      "h : 67 : 0.0 ,max= 0.6402618 ='e' or e\n",
      "a : 86 : 0.0 ,max= 0.9999888 ='\u0000' or \u0000\n",
      "t : 2 : 0.0 ,max= 0.35850045 ='r' or r\n",
      "  : 85 : 0.0 ,max= 0.99999595 ='\u0000' or \u0000\n",
      "s : 74 : 0.0 ,max= 0.17762661 ='t' or t\n",
      "h : 67 : 0.0 ,max= 0.9999838 ='\u0000' or \u0000\n",
      "a : 78 : 0.0 ,max= 0.35572112 ='e' or e\n",
      "l : 78 : 0.0 ,max= 0.99997723 ='\u0000' or \u0000\n",
      "l : 2 : 0.0 ,max= 0.35593906 ='d' or d\n",
      "  : 68 : 0.0 ,max= 0.9999987 ='\u0000' or \u0000\n",
      "b : 71 : 0.0 ,max= 0.11158287 ='t' or t\n",
      "e : 2 : 0.0 ,max= 0.99999166 ='\u0000' or \u0000\n",
      "  : 87 : 0.0 ,max= 0.23933676 =' ' or  \n",
      "u : 80 : 0.0 ,max= 0.99996424 ='\u0000' or \u0000\n",
      "n : 97 : 0.0 ,max= 0.73859614 ='n' or n\n",
      "\n",
      " : 69 : 0.0 ,max= 0.9999769 ='\u0000' or \u0000\n",
      "c : 78 : 0.0 ,max= 0.15239069 ='t' or t\n",
      "l : 71 : 0.0 ,max= 0.99991167 ='\u0000' or \u0000\n",
      "e : 67 : 0.0 ,max= 0.65961045 ='e' or e\n",
      "a : 80 : 0.0 ,max= 0.9999964 ='\u0000' or \u0000\n",
      "n : 2 : 0.0 ,max= 0.25200877 ='t' or t\n",
      "  : 87 : 0.0 ,max= 0.99999976 ='\u0000' or \u0000\n",
      "u : 80 : 0.0 ,max= 0.15547007 ='k' or k\n",
      "n : 86 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "t : 81 : 0.0 ,max= 0.22385569 ='g' or g\n",
      "o : 2 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "  : 74 : 0.0 ,max= 0.3335628 ='t' or t\n",
      "h : 75 : 0.0 ,max= 0.9999895 ='\u0000' or \u0000\n",
      "i : 79 : 0.0 ,max= 0.685196 ='e' or e\n",
      "m : 14 : 0.0 ,max= 0.9999994 ='\u0000' or \u0000\n",
      ", : 2 : 0.37761027 ,max= 0.37761027 =' ' or  \n",
      "  : 67 : 0.0 ,max= 0.9999958 ='\u0000' or \u0000\n",
      "a : 80 : 0.0 ,max= 0.22994964 ='w' or w\n",
      "n : 70 : 0.0 ,max= 0.99999976 ='\u0000' or \u0000\n",
      "d : 2 : 0.0 ,max= 0.55563545 ='o' or o\n",
      "  : 86 : 0.0 ,max= 0.99999475 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.38124543 ='t' or t\n",
      "h : 71 : 0.0 ,max= 0.9999895 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.4418268 ='i' or i\n",
      "  : 46 : 0.0 ,max= 0.9999938 ='\u0000' or \u0000\n",
      "L : 49 : 0.0 ,max= 0.19068044 ='s' or s\n",
      "O : 52 : 0.0 ,max= 0.99999845 ='\u0000' or \u0000\n",
      "R : 38 : 0.0 ,max= 0.195103 =' ' or  \n",
      "D : 2 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "  : 74 : 0.0 ,max= 0.3323366 =' ' or  \n",
      "h : 67 : 0.0 ,max= 0.99998367 ='\u0000' or \u0000\n",
      "a : 86 : 0.0 ,max= 0.3174082 ='o' or o\n",
      "t : 74 : 0.0 ,max= 0.99999225 ='\u0000' or \u0000\n",
      "h : 2 : 0.0 ,max= 0.4687864 ='h' or h\n",
      "  : 85 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "s : 67 : 0.0 ,max= 0.18711397 ='t' or t\n",
      "a : 75 : 0.0 ,max= 0.99998987 ='\u0000' or \u0000\n",
      "i : 70 : 0.0 ,max= 0.56594366 ='n' or n\n",
      "d : 14 : 0.0 ,max= 0.9999999 ='\u0000' or \u0000\n",
      ", : 2 : 0.44262365 ,max= 0.44262365 =' ' or  \n",
      "  : 43 : 0.0 ,max= 0.9999527 ='\u0000' or \u0000\n",
      "I : 2 : 0.0 ,max= 0.29800826 ='t' or t\n",
      "  : 89 : 0.0 ,max= 0.9999778 ='\u0000' or \u0000\n",
      "w : 75 : 0.0 ,max= 0.32719448 ='a' or a\n",
      "i : 78 : 0.0 ,max= 0.99997544 ='\u0000' or \u0000\n",
      "l : 78 : 0.0 ,max= 0.39385256 ='n' or n\n",
      "l : 2 : 0.0 ,max= 0.9999963 ='\u0000' or \u0000\n",
      "  : 82 : 0.0 ,max= 0.4005391 =' ' or  \n",
      "p : 84 : 0.0 ,max= 0.99997807 ='\u0000' or \u0000\n",
      "r : 81 : 0.0 ,max= 0.41389358 ='e' or e\n",
      "o : 97 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "\n",
      " : 88 : 0.0 ,max= 0.21696404 =' ' or  \n",
      "v : 81 : 0.0 ,max= 0.99999833 ='\u0000' or \u0000\n",
      "o : 77 : 0.0 ,max= 0.9655097 ='e' or e\n",
      "k : 71 : 0.0 ,max= 0.99999774 ='\u0000' or \u0000\n",
      "e : 2 : 0.37706822 ,max= 0.37706822 =' ' or  \n",
      "  : 79 : 0.0 ,max= 0.9999869 ='\u0000' or \u0000\n",
      "m : 71 : 0.0 ,max= 0.37076843 ='t' or t\n",
      "e : 2 : 0.0 ,max= 0.99992096 ='\u0000' or \u0000\n",
      "  : 86 : 0.0 ,max= 0.4462391 ='v' or v\n",
      "t : 81 : 0.0 ,max= 0.9996991 ='\u0000' or \u0000\n",
      "o : 2 : 0.0 ,max= 0.82562155 ='h' or h\n",
      "  : 79 : 0.0 ,max= 0.9999132 ='\u0000' or \u0000\n",
      "m : 71 : 0.34869537 ,max= 0.34869537 ='e' or e\n",
      "e : 14 : 0.0 ,max= 0.9998197 ='\u0000' or \u0000\n",
      ", : 2 : 0.0 ,max= 0.23249777 ='r' or r\n",
      "  : 67 : 0.0 ,max= 0.999982 ='\u0000' or \u0000\n",
      "a : 80 : 0.0 ,max= 0.1736673 ='w' or w\n",
      "n : 70 : 0.0 ,max= 0.9999995 ='\u0000' or \u0000\n",
      "d : 2 : 0.0 ,max= 0.37656897 ='o' or o\n",
      "  : 86 : 0.0 ,max= 0.9999976 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.3456767 ='w' or w\n",
      "h : 71 : 0.0 ,max= 0.9999963 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.42875206 ='i' or i\n",
      "  : 84 : 0.0 ,max= 0.99999785 ='\u0000' or \u0000\n",
      "r : 71 : 0.0 ,max= 0.1676601 ='n' or n\n",
      "e : 79 : 0.0 ,max= 0.9999989 ='\u0000' or \u0000\n",
      "m : 71 : 0.0 ,max= 0.3307395 ='v' or v\n",
      "e : 79 : 0.0 ,max= 0.99999905 ='\u0000' or \u0000\n",
      "m : 68 : 0.0 ,max= 0.23750876 =' ' or  \n",
      "b : 84 : 0.0 ,max= 0.9999994 ='\u0000' or \u0000\n",
      "r : 75 : 0.0 ,max= 0.19735947 ='e' or e\n",
      "i : 80 : 0.0 ,max= 0.99999964 ='\u0000' or \u0000\n",
      "n : 73 : 0.0 ,max= 0.21400984 ='d' or d\n",
      "g : 2 : 0.0 ,max= 0.9999876 ='\u0000' or \u0000\n",
      "  : 81 : 0.0 ,max= 0.7444146 ='h' or h\n",
      "o : 72 : 0.0 ,max= 0.9999988 ='\u0000' or \u0000\n",
      "f : 2 : 0.0 ,max= 0.56683457 ='t' or t\n",
      "  : 86 : 0.0 ,max= 0.9999424 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.13598122 ='e' or e\n",
      "h : 71 : 0.0 ,max= 0.99989116 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.5232474 ='e' or e\n",
      "  : 69 : 0.0 ,max= 0.9999076 ='\u0000' or \u0000\n",
      "c : 74 : 0.0 ,max= 0.21761572 ='t' or t\n",
      "h : 75 : 0.0 ,max= 0.9999968 ='\u0000' or \u0000\n",
      "i : 78 : 0.0 ,max= 0.36664736 ='i' or i\n",
      "l : 70 : 0.0 ,max= 0.99999475 ='\u0000' or \u0000\n",
      "d : 84 : 0.0 ,max= 0.2716951 ='d' or d\n",
      "r : 71 : 0.0 ,max= 0.9999988 ='\u0000' or \u0000\n",
      "e : 80 : 0.0 ,max= 0.5336071 ='e' or e\n",
      "n : 2 : 0.0 ,max= 0.9999937 ='\u0000' or \u0000\n",
      "  : 97 : 0.0 ,max= 0.33888268 ='t' or t\n",
      "\n",
      " : 81 : 0.0 ,max= 0.9999987 ='\u0000' or \u0000\n",
      "o : 72 : 0.0 ,max= 0.38056225 ='A' or A\n",
      "f : 2 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "  : 43 : 0.0 ,max= 0.7711303 ='o' or o\n",
      "I : 85 : 0.0 ,max= 0.99999905 ='\u0000' or \u0000\n",
      "s : 84 : 0.7145696 ,max= 0.7145696 ='r' or r\n",
      "r : 67 : 0.0 ,max= 1.0 ='\u0000' or \u0000\n",
      "a : 71 : 0.0 ,max= 0.95928866 =' ' or  \n",
      "e : 78 : 0.0 ,max= 0.9999633 ='\u0000' or \u0000\n",
      "l : 2 : 0.1627773 ,max= 0.1627773 =' ' or  \n",
      "  : 85 : 0.0 ,max= 0.99999774 ='\u0000' or \u0000\n",
      "s : 67 : 0.0 ,max= 0.23942672 ='t' or t\n",
      "a : 89 : 0.0 ,max= 0.999997 ='\u0000' or \u0000\n",
      "w : 2 : 0.0 ,max= 0.49425548 ='n' or n\n",
      "  : 86 : 0.0 ,max= 0.9999993 ='\u0000' or \u0000\n",
      "t : 74 : 0.0 ,max= 0.19803031 ='s' or s\n",
      "h : 71 : 0.0 ,max= 0.99999726 ='\u0000' or \u0000\n",
      "e : 2 : 0.0 ,max= 0.3585454 ='a' or a\n",
      "  : 46 : 0.0 ,max= 0.9999927 ='\u0000' or \u0000\n",
      "L : 49 : 0.0 ,max= 0.137048 ='t' or t\n",
      "O : 52 : 0.0 ,max= 0.9999968 ='\u0000' or \u0000\n",
      "R : 38 : 0.0 ,max= 0.16053632 =' ' or  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.007018808645146493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pcx(txt):\n",
    "    # these must match what was saved !\n",
    "    ALPHASIZE = my_txtutils.ALPHASIZE\n",
    "    NLAYERS = 3\n",
    "    INTERNALSIZE = 512\n",
    "\n",
    "    ok03 =\"checkpoints/rnn_train_1563601394-60000000\" # okrika 2019-07-20\n",
    "    bb01 =\"checkpoints/rnn_train_1563814502-18000000\" # bible 2019-07-22\n",
    "\n",
    "    author=bb01\n",
    "\n",
    "    ncnt = 0\n",
    "    with tf.Session() as sess:\n",
    "        # new_saver = tf.train.import_meta_graph('checkpoints/rnn_train_1512567262-0.meta')\n",
    "        new_saver = tf.train.import_meta_graph(author+'.meta')\n",
    "        new_saver.restore(sess, author)\n",
    "        x = my_txtutils.convert_from_alphabet(ord(txt[0]))\n",
    "        x = np.array([[x]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "\n",
    "        # initial values\n",
    "        y = x\n",
    "        h = np.zeros([1, INTERNALSIZE * NLAYERS], dtype=np.float32)  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n",
    "        arr=[]\n",
    "        for i in range(len(txt)-1):\n",
    "            yo, h = sess.run(['Yo:0', 'H:0'], feed_dict={'X:0': y, 'pkeep:0': 1., 'Hin:0': h, 'batchsize:0': 1})\n",
    "            c = my_txtutils.convert_from_alphabet(ord(txt[i+1]))\n",
    "            d = my_txtutils.sample_from_probabilities(yo, topn=1)\n",
    "            d = chr(my_txtutils.convert_to_alphabet(d))\n",
    "            y = np.array([[c]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "            y1=np.reshape(yo,[ALPHASIZE,-1])\n",
    "            y1=y1.flatten()\n",
    "            #c = chr(my_txtutils.convert_to_alphabet(i))\n",
    "            print(txt[i],':',c,':',y1[c],',max=',np.max(y1),\"='%s' or %s\"%(chr(my_txtutils.convert_to_alphabet(np.argmax(y1))),d))\n",
    "            arr.append(y1[c])\n",
    "    return np.log2(np.sum(arr))*(-1/len(txt))\n",
    "    #return np.prod(arr))**(-1/len(txt)\n",
    "t='''I will say unto his son, Thou shalt\n",
    " not be saved, that I say unto them, We have consu\n",
    "med my father, and the mighty man that shall be un\n",
    "clean unto him, and the LORD hath said, I will pro\n",
    "voke me to me, and the remembring of the children \n",
    "of Israel saw the LORD'''\n",
    "pcx(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/rnn_train_1563814502-18000000\n",
      "I will say unto his son, Thou shalt\n",
      " not be saved, that I say unto them, We have consu\n",
      "med my father, and the mighty man that shall be un\n",
      "clean unto him, and the LORD hath said, I will pro\n",
      "voke me to me, and the remembring of the children \n",
      "of Israel saw the LORD \n",
      "\n",
      "I\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \n",
      "\n",
      "I\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \n",
      "\n",
      "I\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 \n",
      "\n",
      "Iss \u0000s\u0000t\u0000\u0000n\u0000nn\u0000h\u0000o\u0000n\u0000t\u0000n\u0000 \u0000a\u0000 \u0000t\u0000a\u0000a\u0000t\u0000o\u0000 \u0000l\u0000t\u0000n\u0000d\u0000 \u0000h\u0000k\u0000d\u0000t\u0000n\u0000m\u0000a\u0000t\u0000 \u0000o\u0000 \u0000i\u0000a\u0000n\u0000d\u0000h\u0000o\u0000r\u0000e\u0000e\u0000i\u0000o\u0000n\u0000e\u0000e\u0000t\u0000o\u0000w\u0000i\u0000a\u0000s\u0000 \u0000 \u0000a\u0000n\u0000e\u0000r\u0000u\u0000e\u0000d\u0000m\u0000 \u0000n\u0000A\u0000e\u0000y\u0000k\u0000e\u0000t\u0000e\u0000a\u0000t\u0000o\u0000t\u0000i\u0000s\u0000r\u0000 \u0000a\u0000h\u0000t\u0000n\u0000 \u0000a\u0000a\u0000n\u0000 \u0000e\u0000n\u0000i\u0000 \u0000a\u0000v\u0000h\u0000e\u0000r\u0000w\u0000o\u0000w\u0000e\u0000n\u0000v\u0000 \u0000s\u0000d\u0000h\u0000t\u0000e\u0000e\u0000t\u0000i\u0000o\u0000e\u0000c\u0000A\u0000o\u0000r\u0000 \u0000 \u0000w\u0000n\u0000m\u0000e\u0000t\u0000r \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00962196597616181"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pcx2(txt):\n",
    "    # these must match what was saved !\n",
    "    ALPHASIZE = my_txtutils.ALPHASIZE\n",
    "    NLAYERS = 3\n",
    "    INTERNALSIZE = 512\n",
    "\n",
    "    bb01 =\"checkpoints/rnn_train_1563814502-18000000\" # bible 2019-07-22\n",
    "    ok03 =\"checkpoints/rnn_train_1563601394-60000000\" # okrika 2019-07-20\n",
    "\n",
    "    author=bb01\n",
    "\n",
    "    ncnt = 0\n",
    "    with tf.Session() as sess:\n",
    "        # new_saver = tf.train.import_meta_graph('checkpoints/rnn_train_1512567262-0.meta')\n",
    "        new_saver = tf.train.import_meta_graph(author+'.meta')\n",
    "        new_saver.restore(sess, author)\n",
    "        x = my_txtutils.convert_from_alphabet(ord(txt[0]))\n",
    "        x = np.array([[x]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "\n",
    "        # initial values\n",
    "        y = x\n",
    "        h = np.zeros([1, INTERNALSIZE * NLAYERS], dtype=np.float32)  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n",
    "        fi=se=th=rn=txt[0]\n",
    "        arr=[]\n",
    "        for i in range(len(txt)-1):\n",
    "            yo, h = sess.run(['Yo:0', 'H:0'], feed_dict={'X:0': y, 'pkeep:0': 1., 'Hin:0': h, 'batchsize:0': 1})\n",
    "            c = my_txtutils.convert_from_alphabet(ord(txt[i+1]))\n",
    "            d = my_txtutils.sample_from_probabilities(yo, topn=2)\n",
    "            d = chr(my_txtutils.convert_to_alphabet(d))\n",
    "            y = np.array([[c]])  # shape [BATCHSIZE, SEQLEN] with BATCHSIZE=1 and SEQLEN=1\n",
    "            y1=np.reshape(yo,[ALPHASIZE,-1])\n",
    "            y1=y1.flatten()\n",
    "            y2=y1.argsort()[-3:][::-1]\n",
    "            fi+=chr(my_txtutils.convert_to_alphabet(y1[y2[0]]))\n",
    "            se+=chr(my_txtutils.convert_to_alphabet(y1[y2[1]]))\n",
    "            th+=chr(my_txtutils.convert_to_alphabet(y1[y2[2]]))\n",
    "            rn+=d\n",
    "            #c = chr(my_txtutils.convert_to_alphabet(i))\n",
    "            #print(txt[0:i+1],'|',fi,'|',se,'|',th,'|',rn)\n",
    "            arr.append(y1[c])\n",
    "    print(txt,'\\n')\n",
    "    print(fi,'\\n')\n",
    "    print(se,'\\n')\n",
    "    print(th,'\\n')\n",
    "    print(rn,'\\n')\n",
    "    return np.log2(np.sum(arr))*(-1/len(txt))\n",
    "    #return np.prod(arr))**(-1/len(txt)\n",
    "t='''I will say unto his son, Thou shalt\n",
    " not be saved, that I say unto them, We have consu\n",
    "med my father, and the mighty man that shall be un\n",
    "clean unto him, and the LORD hath said, I will pro\n",
    "voke me to me, and the remembring of the children \n",
    "of Israel saw the LORD'''\n",
    "pcx2(t)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Softmax layer implementation:\n",
    "# Flatten the first two dimension of the output [ BATCHSIZE, SEQLEN, ALPHASIZE ] => [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "# then apply softmax readout layer. This way, the weights and biases are shared across unrolled time steps.\n",
    "# From the readout point of view, a value coming from a sequence time step or a minibatch item is the same thing.\n",
    "'''\n",
    "Yflat = tf.reshape(Yr, [-1, INTERNALSIZE])    # [ BATCHSIZE x SEQLEN, INTERNALSIZE ]\n",
    "Ylogits = layers.linear(Yflat, ALPHASIZE)     # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "Yflat_ = tf.reshape(Yo_, [-1, ALPHASIZE])     # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Yflat_)  # [ BATCHSIZE x SEQLEN ]\n",
    "loss = tf.reshape(loss, [batchsize, -1])      # [ BATCHSIZE, SEQLEN ]\n",
    "Yo = tf.nn.softmax(Ylogits, name='Yo')        # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "Y = tf.argmax(Yo, 1)                          # [ BATCHSIZE x SEQLEN ]\n",
    "Y = tf.reshape(Y, [batchsize, -1], name=\"Y\")  # [ BATCHSIZE, SEQLEN ]\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "'''\n",
    "        # If sampling is be done from the topn most likely characters, the generated text\n",
    "        # is more credible and more \"english\". If topn is not set, it defaults to the full\n",
    "        # distribution (ALPHASIZE)\n",
    "\n",
    "        # Recommended: topn = 10 for intermediate checkpoints, topn=2 or 3 for fully trained checkpoints\n",
    "        print('yes' if re.search(\"g\", \"abcdef\") else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "print('yes' if re.search(\"g\", \"abcdef\") else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_txtutils.convert_from_alphabet(ord('i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.array([1,3,5,0])\n",
    "b=dict(zip([x for x in range(len(a))],a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c='hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
