{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: UTF-8\n",
    "# Copyright 2017 Google.com\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.contrib import layers\n",
    "#from tensorflow.contrib import rnn  # rnn stuff temporarily in contrib, moving back to code in TF 1.1\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import my_txtutils as txt\n",
    "import torch\n",
    "import json\n",
    "#tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model parameters\n",
    "#\n",
    "# Usage:\n",
    "#   Training only:\n",
    "#         Leave all the parameters as they are\n",
    "#         Disable validation to run a bit faster (set validation=False below)\n",
    "#         You can follow progress in Tensorboard: tensorboard --log-dir=log\n",
    "#   Training and experimentation (default):\n",
    "#         Keep validation enabled\n",
    "#         You can now play with the parameters anf follow the effects in Tensorboard\n",
    "#         A good choice of parameters ensures that the testing and validation curves stay close\n",
    "#         To see the curves drift apart (\"overfitting\") try to use an insufficient amount of\n",
    "#         training data (shakedir = \"shakespeare/t*.txt\" for example)\n",
    "#\n",
    "nb_epoch=90\n",
    "SEQLEN = 30\n",
    "VALI_SEQLEN = 30\n",
    "BATCHSIZE = 256\n",
    "ALPHASIZE = txt.ALPHASIZE\n",
    "INTERNALSIZE = 512\n",
    "NLAYERS = 3\n",
    "learning_rate = 0.001  # fixed learning rate\n",
    "dropout_pkeep = 0.8    # some dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: UTF-8\n",
    "# Copyright 2017 Google.com\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# size of the alphabet that we work with\n",
    "ALPHASIZE = 98\n",
    "\n",
    "\n",
    "# Specification of the supported alphabet (subset of ASCII-7)\n",
    "# 10 line feed LF\n",
    "# 32-64 numbers and punctuation\n",
    "# 65-90 upper-case letters\n",
    "# 91-97 more punctuation\n",
    "# 97-122 lower-case letters\n",
    "# 123-126 more punctuation\n",
    "def convert_from_alphabet(a):\n",
    "    \"\"\"Encode a character\n",
    "    :param a: one character\n",
    "    :return: the encoded value\n",
    "    \"\"\"\n",
    "    if a == 9:\n",
    "        return 1\n",
    "    if a == 10:\n",
    "        return 127 - 30  # LF\n",
    "    elif 32 <= a <= 126:\n",
    "        return a - 30\n",
    "    else:\n",
    "        return 0  # unknown\n",
    "\n",
    "\n",
    "# encoded values:\n",
    "# unknown = 0\n",
    "# tab = 1\n",
    "# space = 2\n",
    "# all chars from 32 to 126 = c-30\n",
    "# LF mapped to 127-30\n",
    "def convert_to_alphabet(c, avoid_tab_and_lf=False):\n",
    "    \"\"\"Decode a code point\n",
    "    :param c: code point\n",
    "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
    "    :return: decoded character\n",
    "    \"\"\"\n",
    "    if c == 1:\n",
    "        return 32 if avoid_tab_and_lf else 9  # space instead of TAB\n",
    "    if c == 127 - 30:\n",
    "        return 92 if avoid_tab_and_lf else 10  # \\ instead of LF\n",
    "    if 32 <= c + 30 <= 126:\n",
    "        return c + 30\n",
    "    else:\n",
    "        return 0  # unknown\n",
    "\n",
    "\n",
    "def encode_text(s):\n",
    "    \"\"\"Encode a string.\n",
    "    :param s: a text string\n",
    "    :return: encoded list of code points\n",
    "    \"\"\"\n",
    "    return list(map(lambda a: convert_from_alphabet(ord(a)), s))\n",
    "\n",
    "\n",
    "def decode_to_text(c, avoid_tab_and_lf=False):\n",
    "    \"\"\"Decode an encoded string.\n",
    "    :param c: encoded list of code points\n",
    "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return \"\".join(map(lambda a: chr(convert_to_alphabet(a, avoid_tab_and_lf)), c))\n",
    "\n",
    "\n",
    "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
    "\n",
    "\n",
    "def rnn_minibatch_sequencer(raw_data, batch_size, sequence_size, nb_epochs):\n",
    "    \"\"\"\n",
    "    Divides the data into batches of sequences so that all the sequences in one batch\n",
    "    continue in the next batch. This is a generator that will keep returning batches\n",
    "    until the input data has been seen nb_epochs times. Sequences are continued even\n",
    "    between epochs, apart from one, the one corresponding to the end of raw_data.\n",
    "    The remainder at the end of raw_data that does not fit in an full batch is ignored.\n",
    "    :param raw_data: the training text\n",
    "    :param batch_size: the size of a training minibatch\n",
    "    :param sequence_size: the unroll size of the RNN\n",
    "    :param nb_epochs: number of epochs to train on\n",
    "    :return:\n",
    "        x: one batch of training sequences\n",
    "        y: on batch of target sequences, i.e. training sequences shifted by 1\n",
    "        epoch: the current epoch number (starting at 0)\n",
    "    \"\"\"\n",
    "    data = np.array(raw_data)\n",
    "    data_len = data.shape[0]\n",
    "    # using (data_len-1) because we must provide for the sequence shifted by 1 too\n",
    "    nb_batches = (data_len - 1) // (batch_size * sequence_size)\n",
    "    assert nb_batches > 0, \"Not enough data, even for a single batch. Try using a smaller batch_size.\"\n",
    "    rounded_data_len = nb_batches * batch_size * sequence_size\n",
    "    xdata = np.reshape(data[0:rounded_data_len], [batch_size, nb_batches * sequence_size])\n",
    "    ydata = np.reshape(data[1:rounded_data_len + 1], [batch_size, nb_batches * sequence_size])\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        for batch in range(nb_batches):\n",
    "            x = xdata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            y = ydata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            x = np.roll(x, -epoch, axis=0)  # to continue the text from epoch to epoch (do not reset rnn state!)\n",
    "            y = np.roll(y, -epoch, axis=0)\n",
    "            yield x, y, epoch\n",
    "\n",
    "\n",
    "def find_book(index, bookranges):\n",
    "    return next(\n",
    "        book[\"name\"] for book in bookranges if (book[\"start\"] <= index < book[\"end\"]))\n",
    "\n",
    "\n",
    "def find_book_index(index, bookranges):\n",
    "    return next(\n",
    "        i for i, book in enumerate(bookranges) if (book[\"start\"] <= index < book[\"end\"]))\n",
    "\n",
    "\n",
    "def print_learning_learned_comparison(X, Y, losses, bookranges, batch_loss, batch_accuracy, epoch_size, index, epoch):\n",
    "    \"\"\"Display utility for printing learning statistics\"\"\"\n",
    "    print()\n",
    "    # epoch_size in number of batches\n",
    "    batch_size = X.shape[0]  # batch_size in number of sequences\n",
    "    sequence_len = X.shape[1]  # sequence_len in number of characters\n",
    "    start_index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
    "    for k in range(batch_size):\n",
    "        index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
    "        decx = decode_to_text(X[k], avoid_tab_and_lf=True)\n",
    "        decy = decode_to_text(Y[k], avoid_tab_and_lf=True)\n",
    "        bookname = find_book(index_in_epoch, bookranges)\n",
    "        formatted_bookname = \"{: <10.40}\".format(bookname)  # min 10 and max 40 chars\n",
    "        epoch_string = \"{:4d}\".format(index) + \" (epoch {}) \".format(epoch)\n",
    "        loss_string = \"loss: {:.5f}\".format(losses[k])\n",
    "        print_string = epoch_string + formatted_bookname + \" │ {} │ {} │ {}\"\n",
    "        print(print_string.format(decx, decy, loss_string))\n",
    "        index += sequence_len\n",
    "    # box formatting characters:\n",
    "    # │ \\u2502\n",
    "    # ─ \\u2500\n",
    "    # └ \\u2514\n",
    "    # ┘ \\u2518\n",
    "    # ┴ \\u2534\n",
    "    # ┌ \\u250C\n",
    "    # ┐ \\u2510\n",
    "    format_string = \"└{:─^\" + str(len(epoch_string)) + \"}\"\n",
    "    format_string += \"{:─^\" + str(len(formatted_bookname)) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(decx) + 2) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(decy) + 2) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(loss_string)) + \"}┘\"\n",
    "    footer = format_string.format('INDEX', 'BOOK NAME', 'TRAINING SEQUENCE', 'PREDICTED SEQUENCE', 'LOSS')\n",
    "    print(footer)\n",
    "    # print statistics\n",
    "    batch_index = start_index_in_epoch // (batch_size * sequence_len)\n",
    "    batch_string = \"batch {}/{} in epoch {},\".format(batch_index, epoch_size, epoch)\n",
    "    stats = \"{: <28} batch loss: {:.5f}, batch accuracy: {:.5f}\".format(batch_string, batch_loss, batch_accuracy)\n",
    "    print()\n",
    "    print(\"TRAINING STATS: {}\".format(stats))\n",
    "\n",
    "\n",
    "class Progress:\n",
    "    \"\"\"Text mode progress bar.\n",
    "    Usage:\n",
    "            p = Progress(30)\n",
    "            p.step()\n",
    "            p.step()\n",
    "            p.step(start=True) # to restart form 0%\n",
    "    The progress bar displays a new header at each restart.\"\"\"\n",
    "    def __init__(self, maxi, size=100, msg=\"\"):\n",
    "        \"\"\"\n",
    "        :param maxi: the number of steps required to reach 100%\n",
    "        :param size: the number of characters taken on the screen by the progress bar\n",
    "        :param msg: the message displayed in the header of the progress bat\n",
    "        \"\"\"\n",
    "        self.maxi = maxi\n",
    "        self.p = self.__start_progress(maxi)()  # () to get the iterator from the generator\n",
    "        self.header_printed = False\n",
    "        self.msg = msg\n",
    "        self.size = size\n",
    "\n",
    "    def step(self, reset=False):\n",
    "        if reset:\n",
    "            self.__init__(self.maxi, self.size, self.msg)\n",
    "        if not self.header_printed:\n",
    "            self.__print_header()\n",
    "        next(self.p)\n",
    "\n",
    "    def __print_header(self):\n",
    "        print()\n",
    "        format_string = \"0%{: ^\" + str(self.size - 6) + \"}100%\"\n",
    "        print(format_string.format(self.msg))\n",
    "        self.header_printed = True\n",
    "\n",
    "    def __start_progress(self, maxi):\n",
    "        def print_progress():\n",
    "            # Bresenham's algorithm. Yields the number of dots printed.\n",
    "            # This will always print 100 dots in max invocations.\n",
    "            dx = maxi\n",
    "            dy = self.size\n",
    "            d = dy - dx\n",
    "            for x in range(maxi):\n",
    "                k = 0\n",
    "                while d >= 0:\n",
    "                    print('=', end=\"\", flush=True)\n",
    "                    k += 1\n",
    "                    d -= dx\n",
    "                d += dy\n",
    "                yield k\n",
    "\n",
    "        return print_progress\n",
    "\n",
    "\n",
    "def read_data_files(directory, validation=True):\n",
    "    \"\"\"Read data files according to the specified glob pattern\n",
    "    Optionnaly set aside the last file as validation data.\n",
    "    No validation data is returned if there are 5 files or less.\n",
    "    :param directory: for example \"data/*.txt\"\n",
    "    :param validation: if True (default), sets the last file aside as validation data\n",
    "    :return: training data, validation data, list of loaded file names with ranges\n",
    "     If validation is\n",
    "    \"\"\"\n",
    "    codetext = []\n",
    "    bookranges = []\n",
    "    shakelist = glob.glob(directory, recursive=True)\n",
    "    for shakefile in shakelist:\n",
    "        shaketext = open(shakefile, \"r\")\n",
    "        print(\"Loading file \" + shakefile)\n",
    "        start = len(codetext)\n",
    "        codetext.extend(encode_text(shaketext.read()))\n",
    "        end = len(codetext)\n",
    "        bookranges.append({\"start\": start, \"end\": end, \"name\": shakefile.rsplit(\"/\", 1)[-1]})\n",
    "        shaketext.close()\n",
    "\n",
    "    if len(bookranges) == 0:\n",
    "        sys.exit(\"No training data has been found. Aborting.\")\n",
    "\n",
    "    # For validation, use roughly 90K of text,\n",
    "    # but no more than 10% of the entire text\n",
    "    # and no more than 1 book in 5 => no validation at all for 5 files or fewer.\n",
    "\n",
    "    # 10% of the text is how many files ?\n",
    "    total_len = len(codetext)\n",
    "    validation_len = 0\n",
    "    nb_books1 = 0\n",
    "    for book in reversed(bookranges):\n",
    "        validation_len += book[\"end\"]-book[\"start\"]\n",
    "        nb_books1 += 1\n",
    "        if validation_len > total_len // 10:\n",
    "            break\n",
    "\n",
    "    # 90K of text is how many books ?\n",
    "    validation_len = 0\n",
    "    nb_books2 = 0\n",
    "    for book in reversed(bookranges):\n",
    "        validation_len += book[\"end\"]-book[\"start\"]\n",
    "        nb_books2 += 1\n",
    "        if validation_len > 90*1024:\n",
    "            break\n",
    "\n",
    "    # 20% of the books is how many books ?\n",
    "    nb_books3 = len(bookranges) // 5\n",
    "\n",
    "    # pick the smallest\n",
    "    nb_books = min(nb_books1, nb_books2, nb_books3)\n",
    "\n",
    "    if nb_books == 0 or not validation:\n",
    "        cutoff = len(codetext)\n",
    "    else:\n",
    "        cutoff = bookranges[-nb_books][\"start\"]\n",
    "    valitext = codetext[cutoff:]\n",
    "    codetext = codetext[:cutoff]\n",
    "    return codetext, valitext, bookranges\n",
    "\n",
    "\n",
    "def print_data_stats(datalen, valilen, epoch_size):\n",
    "    datalen_mb = datalen/1024.0/1024.0\n",
    "    valilen_kb = valilen/1024.0\n",
    "    print(\"Training text size is {:.2f}MB with {:.2f}KB set aside for validation.\".format(datalen_mb, valilen_kb)\n",
    "          + \" There will be {} batches per epoch\".format(epoch_size))\n",
    "\n",
    "\n",
    "def print_validation_header(validation_start, bookranges):\n",
    "    bookindex = find_book_index(validation_start, bookranges)\n",
    "    books = ''\n",
    "    for i in range(bookindex, len(bookranges)):\n",
    "        books += bookranges[i][\"name\"]\n",
    "        if i < len(bookranges)-1:\n",
    "            books += \", \"\n",
    "    print(\"{: <60}\".format(\"Validating on \" + books), flush=True)\n",
    "\n",
    "\n",
    "def print_validation_stats(loss, accuracy):\n",
    "    print(\"VALIDATION STATS:                                  loss: {:.5f},       accuracy: {:.5f}\".format(loss,\n",
    "                                                                                                           accuracy))\n",
    "\n",
    "\n",
    "def print_text_generation_header():\n",
    "    print()\n",
    "    print(\"┌{:─^111}┐\".format('Generating random text from learned state'))\n",
    "\n",
    "\n",
    "def print_text_generation_footer():\n",
    "    print()\n",
    "    print(\"└{:─^111}┘\".format('End of generation'))\n",
    "\n",
    "\n",
    "def frequency_limiter(n, multiple=1, modulo=0):\n",
    "    def limit(i):\n",
    "        return i % (multiple * n) == modulo*multiple\n",
    "    return limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file txts/gal_eph_new.txt\n",
      "Loading file txts/acts_new.txt\n",
      "Loading file txts/tit_phl_new.txt\n",
      "Loading file txts/matt02_new.txt\n",
      "Loading file txts/jam_jud_new.txt\n",
      "Loading file txts/john_new.txt\n",
      "Loading file txts/jud_rev_new.txt\n",
      "Loading file txts/phil_col_new.txt\n",
      "Loading file txts/luke_8_john_new.txt\n",
      "Loading file txts/matt_new.txt\n",
      "Loading file txts/heb_new.txt\n",
      "Loading file txts/thes_tim_new.txt\n",
      "Loading file txts/mark01_new.txt\n"
     ]
    }
   ],
   "source": [
    "# load data, either shakespeare, or the Python source of Tensorflow itself\n",
    "shakedir = \"txts/*.txt\"\n",
    "#shakedir = \"../tensorflow/**/*.py\"\n",
    "codetext, valitext, bookranges = txt.read_data_files(shakedir, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text size is 2.89MB with 213.92KB set aside for validation. There will be 395 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "# display some stats on the data\n",
    "epoch_size = len(codetext) // (BATCHSIZE * SEQLEN)\n",
    "txt.print_data_stats(len(codetext), len(valitext), epoch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "#\n",
    "# the model (see FAQ in README.md)\n",
    "#\n",
    "lr = tf.placeholder(tf.float32, name='lr')  # learning rate\n",
    "pkeep = tf.placeholder(tf.float32, name='pkeep')  # dropout parameter\n",
    "batchsize = tf.placeholder(tf.int32, name='batchsize')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# inputs\n",
    "X = tf.placeholder(tf.uint8, [None, None], name='X')    # [ BATCHSIZE, SEQLEN ]\n",
    "Xo = tf.one_hot(X, ALPHASIZE, 1.0, 0.0)                 # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n",
    "# expected outputs = same sequence shifted by 1 since we are trying to predict the next character\n",
    "Y_ = tf.placeholder(tf.uint8, [None, None], name='Y_')  # [ BATCHSIZE, SEQLEN ]\n",
    "Yo_ = tf.one_hot(Y_, ALPHASIZE, 1.0, 0.0)               # [ BATCHSIZE, SEQLEN, ALPHASIZE ]\n",
    "# input state\n",
    "Hin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name='Hin')  # [ BATCHSIZE, INTERNALSIZE * NLAYERS]\n",
    "\n",
    "# using a NLAYERS=3 layers of GRU cells, unrolled SEQLEN=30 times\n",
    "# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n",
    "\n",
    "# How to properly apply dropout in RNNs: see README.md\n",
    "cells = [rnn.GRUCell(INTERNALSIZE) for _ in range(NLAYERS)]\n",
    "# \"naive dropout\" implementation\n",
    "dropcells = [rnn.DropoutWrapper(cell,input_keep_prob=pkeep) for cell in cells]\n",
    "multicell = rnn.MultiRNNCell(dropcells, state_is_tuple=False)\n",
    "multicell = rnn.DropoutWrapper(multicell, output_keep_prob=pkeep)  # dropout for the softmax layer\n",
    "\n",
    "Yr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state=Hin)\n",
    "# Yr: [ BATCHSIZE, SEQLEN, INTERNALSIZE ]\n",
    "# H:  [ BATCHSIZE, INTERNALSIZE*NLAYERS ] # this is the last state in the sequence\n",
    "\n",
    "H = tf.identity(H, name='H')  # just to give it a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu..\n",
      "weights loaded from ./slrnn_epoch90.model\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(BATCHSIZE, self.hidden_size, device=device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using gpu..' if torch.cuda.is_available() else 'using cpu..')\n",
    "rnn = RNN(ALPHASIZE, INTERNALSIZE, ALPHASIZE)\n",
    "rnn.to(device)\n",
    "PATH='./slrnn_epoch90.model'\n",
    "if os.path.exists(PATH):\n",
    "    rnn.load_state_dict(torch.load(PATH, map_location=torch.device(device)))\n",
    "    print(f'weights loaded from {PATH}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": true
    }
   },
   "source": [
    "# Softmax layer implementation:\n",
    "# Flatten the first two dimension of the output [ BATCHSIZE, SEQLEN, ALPHASIZE ] => [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "# then apply softmax readout layer. This way, the weights and biases are shared across unrolled time steps.\n",
    "# From the readout point of view, a value coming from a sequence time step or a minibatch item is the same thing.\n",
    "\n",
    "Yflat = tf.reshape(Yr, [-1, INTERNALSIZE])    # [ BATCHSIZE x SEQLEN, INTERNALSIZE ]\n",
    "Ylogits = layers.linear(Yflat, ALPHASIZE)     # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "Yflat_ = tf.reshape(Yo_, [-1, ALPHASIZE])     # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Yflat_)  # [ BATCHSIZE x SEQLEN ]\n",
    "loss = tf.reshape(loss, [batchsize, -1])      # [ BATCHSIZE, SEQLEN ]\n",
    "Yo = tf.nn.softmax(Ylogits, name='Yo')        # [ BATCHSIZE x SEQLEN, ALPHASIZE ]\n",
    "Y = tf.argmax(Yo, 1)                          # [ BATCHSIZE x SEQLEN ]\n",
    "Y = tf.reshape(Y, [batchsize, -1], name=\"Y\")  # [ BATCHSIZE, SEQLEN ]\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# loss fn\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#from ok_seq2seq import EncoderRNN \\\n",
    "#                        ,DecoderRNN \\\n",
    "#                        ,AttnDecoderRNN \\\n",
    "#                        ,evaluateRandomly \\\n",
    "#                        ,teacher_forcing_ratio \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# stats for display\n",
    "seqloss = tf.reduce_mean(loss, 1)\n",
    "batchloss = tf.reduce_mean(seqloss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(Y_, tf.cast(Y, tf.uint8)), tf.float32))\n",
    "loss_summary = tf.summary.scalar(\"batch_loss\", batchloss)\n",
    "acc_summary = tf.summary.scalar(\"batch_accuracy\", accuracy)\n",
    "summaries = tf.summary.merge([loss_summary, acc_summary])\n",
    "\n",
    "# Init Tensorboard stuff. This will save Tensorboard information into a different\n",
    "# folder at each run named 'log/<timestamp>/'. Two sets of data are saved so that\n",
    "# you can compare training and validation curves visually in Tensorboard.\n",
    "timestamp = str(math.trunc(time.time()))\n",
    "summary_writer = tf.summary.FileWriter(\"log/\" + timestamp + \"-training\")\n",
    "validation_writer = tf.summary.FileWriter(\"log/\" + timestamp + \"-validation\")\n",
    "\n",
    "# Init for saving models. They will be saved into a directory named 'checkpoints'.\n",
    "# Only the last checkpoint is kept.\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")\n",
    "saver = tf.train.Saver(max_to_keep=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "\n",
    "evaluateRandomly(encoder1, attn_decoder1)\n",
    "\n",
    "\"\"\"Visualizing Attention\n",
    "---------------------\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable\n",
    "outputs. Because it is used to weight specific encoder outputs of the\n",
    "input sequence, we can imagine looking where the network is focused most\n",
    "at each time step.\n",
    "\n",
    "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
    "displayed as a matrix, with the columns being input steps and rows being\n",
    "output steps:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())\n",
    "\n",
    "\"\"\"For a better viewing experience we will do the extra work of adding axes\n",
    "and labels:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training fn\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    lint = []\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        lint.append(output)\n",
    "    input = torch.stack(lint).transpose(0,1).transpose(1,2)\n",
    "#     print(f'is={input.size()}, cs={category_tensor.size()}')\n",
    "#     print(f'is[1:]={input.size()[1:]}, cs[1:]={category_tensor.size()[1:]}')\n",
    "#     print(f'is[2:]={input.size()[2:]}, cs[2:]={category_tensor.size()[2:]}')\n",
    "    loss = criterion(input, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return torch.stack(lint).transpose(0,1), loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# init train\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def one_hot(chcode):\n",
    "    tensor = torch.zeros(1, ALPHASIZE)\n",
    "    tensor[0][chcode] = 1\n",
    "    return tensor\n",
    "\n",
    "def mb2t(rows):\n",
    "    rows=rows.transpose()\n",
    "    tensor = torch.zeros(rows.shape[0], rows.shape[1], ALPHASIZE, device=device)\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, letter_code in enumerate(row):\n",
    "            tensor[i][j][letter_code] = 1\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def lin2txt(lt):\n",
    "    return ''.join([chr(txt.convert_to_alphabet(c))  if c != 0 else '' for c in lt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 90 (26.67 %) 2.1442 galesia sime minapu mamgba ibu / b i e  be i ni   i ma a o b i  ✗ initialising stats..\n",
      "epoch 1 of 90 (53.33 %) 2.1442  boka siki mi bu, ori kokomaye / b i e  be i ni   i ma a o b i  ✗ initialising stats..\n",
      "epoch 1 of 90 (53.33 %) 2.1460 tamuno be seni o piri, piki om /   a a be ne i b biki  biki b i ✗ initialising stats..\n",
      "epoch 1 of 90 (33.33 %) 2.1460 maa ye ma ari oloko na tuburuk /   a a be ne i b biki  biki b i ✗ initialising stats..\n",
      "epoch 2 of 90 (40.00 %) 2.1408 nwose maa ye ma kainbobia. mam / io e ea  be ni bi aio e   ba a ✗ average epoch rate per hr = 14.17,  eta = 6:16:49\n",
      "epoch 2 of 90 (43.33 %) 2.1408 oria tomoni ma piri bugbiripum / io e ea  be ni bi aio e   ba a ✗ average epoch rate per hr = 14.17,  eta = 6:16:49\n",
      "epoch 2 of 90 (36.67 %) 2.1277 oni ma piriabe na mi ton korom /  i ba biki  i bi sa bikibiri a ✗ average epoch rate per hr = 9.45,  eta = 9:25:09\n",
      "epoch 2 of 90 (36.67 %) 2.1277 sime mi nwo koko, omine fina g /  i ba biki  i bi sa bikibiri a ✗ average epoch rate per hr = 9.45,  eta = 9:25:09\n",
      "epoch 3 of 90 (26.67 %) 2.1537  nweni o gbori kraist-be-na-gb / bio e b bio i oi  ai ee e  abo ✗ average epoch rate per hr = 14.23,  eta = 6:11:03\n",
      "epoch 3 of 90 (53.33 %) 2.1537 inibo tabo belema bo be, ori o / bio e b bio i oi  ai ee e  abo ✗ average epoch rate per hr = 14.23,  eta = 6:11:03\n",
      "epoch 4 of 90 (36.67 %) 2.1457  kraist oju mi bu gbori apu-e. / bii ai m i mi bi bao i m i m   ✗ average epoch rate per hr = 17.07,  eta = 5:05:51\n",
      "epoch 4 of 90 (36.67 %) 2.1457 se ori na yemieke, dapu dokime / bii ai m i mi bi bao i m i m   ✗ average epoch rate per hr = 17.07,  eta = 5:05:51\n",
      "epoch 4 of 90 (43.33 %) 2.0927 uma bu. min mi gose obi bu sim /  a be  ma  oi bi e e o be be i ✗ average epoch rate per hr = 14.25,  eta = 6:06:17\n",
      "epoch 4 of 90 (30.00 %) 2.0927 ani minea bu kuro nyaname okim /  a be  ma  oi bi e e o be be i ✗ average epoch rate per hr = 14.25,  eta = 6:06:17\n",
      "epoch 5 of 90 (33.33 %) 2.1370 oku a konari dumo mi, a tamuno /  u oniiri i mi a bi  oniomi o  ✗ average epoch rate per hr = 16.28,  eta = 5:17:01\n",
      "epoch 5 of 90 (33.33 %) 2.1370 a omine ineda o miebia erechi  /  u oniiri i mi a bi  oniomi o  ✗ average epoch rate per hr = 16.28,  eta = 5:17:01\n",
      "epoch 6 of 90 (36.67 %) 2.1372 e ibi yee nwo bebe  min mi ko /  nni be  mio be e bimanioi bir ✗ average epoch rate per hr = 17.83,  eta = 4:46:04\n",
      "epoch 6 of 90 (46.67 %) 2.1372 bi nyana nwose oria tomoni ma  /  nni be  mio be e bimanioi bir ✗ average epoch rate per hr = 17.83,  eta = 4:46:04\n",
      "epoch 6 of 90 (36.67 %) 2.1286 inia dumo bu, min oloko mi now /  i  bika be  oan o i o oa bi o ✗ average epoch rate per hr = 15.84,  eta = 5:22:02\n",
      "epoch 6 of 90 (53.33 %) 2.1286 amuno be piri, ori ineda wa be /  i  bika be  oan o i o oa bi o ✗ average epoch rate per hr = 15.84,  eta = 5:22:02\n",
      "epoch 7 of 90 (46.67 %) 2.1230 nake, ani tamuno be bereni ori / i i  mni simi o be ne e a b i  ✗ average epoch rate per hr = 17.12,  eta = 4:54:21\n",
      "epoch 7 of 90 (40.00 %) 2.1230 i nwo miweme chochi mi seni to / i i  mni simi o be ne e a b i  ✗ average epoch rate per hr = 17.12,  eta = 4:54:21\n",
      "epoch 7 of 90 (43.33 %) 2.1262 sime karakara mi ini nwose o d / e i ni i a a ai nai sio e e oi ✗ average epoch rate per hr = 15.56,  eta = 5:23:58\n",
      "epoch 7 of 90 (40.00 %) 2.1262  iri na, taitos be nwo oki ibu / e i ni i a a ai nai sio e e oi ✗ average epoch rate per hr = 15.56,  eta = 5:23:58\n",
      "epoch 8 of 90 (50.00 %) 2.1323 mi be deinma mi duko mi, seni  / a be nikeia ba niko bi  se e b ✗ average epoch rate per hr = 16.65,  eta = 4:59:06\n",
      "epoch 8 of 90 (46.67 %) 2.1323 no be na karakarabia ania bipi / a be nikeia ba niko bi  se e b ✗ average epoch rate per hr = 16.65,  eta = 4:59:06\n",
      "epoch 9 of 90 (43.33 %) 2.1154 oforie a nemikase saki piki a  /  i i  b ii ini e mi i oiki b i ✗ average epoch rate per hr = 17.56,  eta = 4:40:13\n",
      "epoch 9 of 90 (43.33 %) 2.1154 lama okuma, omine obu ma obi a /  i i  b ii ini e mi i oiki b i ✗ average epoch rate per hr = 17.56,  eta = 4:40:13\n",
      "epoch 9 of 90 (40.00 %) 2.1200 neda miebia nwo be okuma  miok /     ia  e  bao be nnu a bbin u ✗ average epoch rate per hr = 16.32,  eta = 5:01:33\n",
      "epoch 9 of 90 (33.33 %) 2.1200 o tamuno tomoni now some o kok /     ia  e  bao be nnu a bbin u ✗ average epoch rate per hr = 16.32,  eta = 5:01:33\n",
      "epoch 10 of 90 (40.00 %) 2.1292  min miese omine ani miemieye  / bi ioi  e e i i b i sa  i  e m ✗ average epoch rate per hr = 17.12,  eta = 4:43:47\n",
      "epoch 10 of 90 (50.00 %) 2.1292 , na, belema bu o weri ominea  / bi ioi  e e i i b i sa  i  e m ✗ average epoch rate per hr = 17.12,  eta = 4:43:47\n",
      "epoch 11 of 90 (43.33 %) 2.1207 a wa piri na wa mie nwobe ye m /  bo biki bi so ba  bio e ee na ✗ average epoch rate per hr = 17.85,  eta = 4:28:54\n",
      "epoch 11 of 90 (40.00 %) 2.1207 inea deapu ma  aniatibi bdebo  /  bo biki bi so ba  bio e ee na ✗ average epoch rate per hr = 17.85,  eta = 4:28:54\n",
      "epoch 11 of 90 (43.33 %) 2.1213 sokapu ma, piki mina kubie ma  / e i a ma  oiki bi   bi o  ba n ✗ average epoch rate per hr = 16.79,  eta = 4:45:50\n",
      "epoch 11 of 90 (53.33 %) 2.1213 ri diepiriye mi nwo koru, a du / e i a ma  oiki bi   bi o  ba n ✗ average epoch rate per hr = 16.79,  eta = 4:45:50\n",
      "epoch 12 of 90 (36.67 %) 2.1083 ae  anierechi mioku  o tamuno  /   bnni  i ei mi  u onroori a b ✗ average epoch rate per hr = 17.45,  eta = 4:31:33\n",
      "epoch 12 of 90 (40.00 %) 2.1083 d be se mie bara mi devid be t /   bnni  i ei mi  u onroori a b ✗ average epoch rate per hr = 17.45,  eta = 4:31:33\n",
      "epoch 13 of 90 (23.33 %) 2.1231 okibia bo, okunwengibo bara bu /  u e  be  b i ao e  e be i ai  ✗ average epoch rate per hr = 18.03,  eta = 4:19:31\n",
      "epoch 13 of 90 (36.67 %) 2.1231 inia toroko chiema se ini gbel /  u e  be  b i ao e  e be i ai  ✗ average epoch rate per hr = 18.03,  eta = 4:19:31\n",
      "epoch 13 of 90 (50.00 %) 2.0841 w dikiabe. pita be nwose o bem / obiki  i  mikimbe nio e e oe e ✗ average epoch rate per hr = 17.14,  eta = 4:33:05\n",
      "epoch 13 of 90 (40.00 %) 2.0841 a ski, ikoli wari mi bie okunw / obiki  i  mikimbe nio e e oe e ✗ average epoch rate per hr = 17.14,  eta = 4:33:05\n",
      "epoch 14 of 90 (43.33 %) 2.0841 iya kuro bu ton piki bereni na /  e ai a be oaribiki be e a bi  ✗ average epoch rate per hr = 17.67,  eta = 4:21:23\n",
      "epoch 14 of 90 (40.00 %) 2.0841 biejuadapu ma ini ineda fiaye  /  e ai a be oaribiki be e a bi  ✗ average epoch rate per hr = 17.67,  eta = 4:21:23\n",
      "epoch 14 of 90 (66.67 %) 2.1134 aya be ibi bere mi duko se pik /  e ae nni be e mi biko be iiki ✗ average epoch rate per hr = 16.88,  eta = 4:33:44\n",
      "epoch 14 of 90 (23.33 %) 2.1134 o se ton-a apu bie pakabome, t /  e ae nni be e mi biko be iiki ✗ average epoch rate per hr = 16.88,  eta = 4:33:44\n",
      "epoch 15 of 90 (33.33 %) 2.0858 akumabo ye-e, bugbiripumaye na /  i a e be e  oe oo i i a e mi  ✗ average epoch rate per hr = 17.38,  eta = 4:22:22\n",
      "epoch 15 of 90 (50.00 %) 2.0858 uko mi piki bo kuro nyana tein /  i a e be e  oe oo i i a e mi  ✗ average epoch rate per hr = 17.38,  eta = 4:22:22\n",
      "epoch 16 of 90 (33.33 %) 2.1000 irinwengi bo be pekereme, nde  /  i io e  ii be niri e e  oii o ✗ average epoch rate per hr = 17.85,  eta = 4:12:05\n",
      "epoch 16 of 90 (43.33 %) 2.1000  omi-e, nyanabo be ton i piri  /  i io e  ii be niri e e  oii o ✗ average epoch rate per hr = 17.85,  eta = 4:12:05\n",
      "epoch 16 of 90 (33.33 %) 2.0894 n nwose jopa bie simeme, namap /  oio e ei u io  mi i e  ai a i ✗ average epoch rate per hr = 17.13,  eta = 4:22:39\n",
      "epoch 16 of 90 (30.00 %) 2.0894 lbo firimame, se bo herod kuro /  oio e ei u io  mi i e  ai a i ✗ average epoch rate per hr = 17.13,  eta = 4:22:39\n",
      "epoch 17 of 90 (43.33 %) 2.1071 iki fama ma, ari ini na mun. m /  i bi a ba  bni mni si ba a ba ✗ average epoch rate per hr = 17.58,  eta = 4:12:35\n",
      "epoch 17 of 90 (50.00 %) 2.1071  wa bime o nemi na jizos be bu /  i bi a ba  bni mni si ba a ba ✗ average epoch rate per hr = 17.58,  eta = 4:12:35\n",
      "epoch 18 of 90 (50.00 %) 2.0980 rechi. okuma ori majikbo be an / i ei  b u a b i mi i ie be nni ✗ average epoch rate per hr = 17.98,  eta = 4:03:36\n",
      "epoch 18 of 90 (36.67 %) 2.0980 e gose. nde aniokuma o gose ta / i ei  b u a b i mi i ie be nni ✗ average epoch rate per hr = 17.98,  eta = 4:03:36\n",
      "epoch 18 of 90 (40.00 %) 2.0885 a o bereni nyaname o piki ined /  b oe e a bie a a n biki bei i ✗ average epoch rate per hr = 17.34,  eta = 4:12:32\n",
      "epoch 18 of 90 (46.67 %) 2.0885 u ma juapu-e, se ini minea ama /  b oe e a bie a a n biki bei i ✗ average epoch rate per hr = 17.34,  eta = 4:12:32\n",
      "epoch 19 of 90 (40.00 %) 2.0780 so siki biebele inia bie beinm / e be i be  e e mni  be  so eia ✗ average epoch rate per hr = 17.73,  eta = 4:03:42\n",
      "epoch 19 of 90 (36.67 %) 2.0780 i oria awo-e. mine tamuno awo- / e be i be  e e mni  be  so eia ✗ average epoch rate per hr = 17.73,  eta = 4:03:42\n",
      "epoch 19 of 90 (40.00 %) 2.0811 ime-a ye go piki, ari pufinji  /  i e be ni oiki  bni mi i i  b ✗ average epoch rate per hr = 17.14,  eta = 4:12:01\n",
      "epoch 19 of 90 (50.00 %) 2.0811 pu kuro mi mi bu nyanabo be ok /  i e be ni oiki  bni mi i i  b ✗ average epoch rate per hr = 17.14,  eta = 4:12:01\n",
      "epoch 20 of 90 (33.33 %) 2.0680 ukume, se berekon wari mi toro /  o a  oe ii e a  bo i mi biki  ✗ average epoch rate per hr = 17.51,  eta = 4:03:20\n",
      "epoch 20 of 90 (20.00 %) 2.0680  pakabobia dapu iruoaye dukobi /  o a  oe ii e a  bo i mi biki  ✗ average epoch rate per hr = 17.51,  eta = 4:03:20\n",
      "epoch 21 of 90 (46.67 %) 2.1078 ia. anitibi balafama kiri bu w /    b i i i ie a a a bi i bi bo ✗ average epoch rate per hr = 17.86,  eta = 3:55:13\n",
      "epoch 21 of 90 (46.67 %) 2.1078 u ma oloko ma bie yedawome, se /    b i i i ie a a a bi i bi bo ✗ average epoch rate per hr = 17.86,  eta = 3:55:13\n",
      "epoch 21 of 90 (30.00 %) 2.1308 mume, se mine oki wa simebia w / a a  oe iini n u io beki e  ao ✗ average epoch rate per hr = 17.31,  eta = 4:02:36\n",
      "epoch 21 of 90 (16.67 %) 2.1308 , asun se nwengibia owuni-a te / a a  oe iini n u io beki e  ao ✗ average epoch rate per hr = 17.31,  eta = 4:02:36\n",
      "epoch 22 of 90 (26.67 %) 2.0545 retonbo be damamun se o gbelam / i emue be niri a  ae i oio e a ✗ average epoch rate per hr = 17.65,  eta = 3:54:35\n",
      "epoch 22 of 90 (50.00 %) 2.0545 nyanabo be pirime. gbori owubo / i emue be niri a  ae i oio e a ✗ average epoch rate per hr = 17.65,  eta = 3:54:35\n",
      "epoch 23 of 90 (46.67 %) 2.1029 mi bie nweni na bere pikiari o / a be  sio e ba be e mi i  i m  ✗ average epoch rate per hr = 17.96,  eta = 3:47:12\n",
      "epoch 23 of 90 (40.00 %) 2.1029  be sikima nyo nwo lame. foru  / a be  sio e ba be e mi i  i m  ✗ average epoch rate per hr = 17.96,  eta = 3:47:12\n",
      "epoch 23 of 90 (56.67 %) 2.1003 e tamuno be teteari ye mi bu , /  nimano be nomomii be ni be b  ✗ average epoch rate per hr = 17.46,  eta = 3:53:38\n",
      "epoch 23 of 90 (43.33 %) 2.1003 e-a igoniapu wari mi bie na. p /  nimano be nomomii be ni be b  ✗ average epoch rate per hr = 17.46,  eta = 3:53:38\n",
      "epoch 24 of 90 (46.67 %) 2.0897  mi bie sime firinwengiapu ma  / bi bi  si i ni i io e   i ma n ✗ average epoch rate per hr = 17.76,  eta = 3:46:21\n",
      "epoch 24 of 90 (46.67 %) 2.0897 a be gboribobia, nyanabo jizos / bi bi  si i ni i io e   i ma n ✗ average epoch rate per hr = 17.76,  eta = 3:46:21\n",
      "epoch 25 of 90 (33.33 %) 2.0772 na ani piki wasama mun mediter /   b i siki bo e a ba  ai eki i ✗ average epoch rate per hr = 18.05,  eta = 3:39:25\n",
      "epoch 25 of 90 (30.00 %) 2.0772  gbori owubo omie, ikelibo, or /   b i siki bo e a ba  ai eki i ✗ average epoch rate per hr = 18.05,  eta = 3:39:25\n",
      "epoch 25 of 90 (30.00 %) 2.0820 nakanabia, akalu mi dinma pulo /   i a o   oni a ma nikia bi o  ✗ average epoch rate per hr = 17.58,  eta = 3:45:13\n",
      "epoch 25 of 90 (40.00 %) 2.0820 ma karakaramame, beretonapu ma /   i a o   oni a ma nikia bi o  ✗ average epoch rate per hr = 17.58,  eta = 3:45:13\n",
      "epoch 26 of 90 (33.33 %) 2.0755 bie gboribo now sobia, o duko  / e  bio i e ba obe o   o iiko b ✗ average epoch rate per hr = 17.86,  eta = 3:38:21\n",
      "epoch 26 of 90 (46.67 %) 2.0755 a, anisiki ini inia bubarasinm / e  bio i e ba obe o   o iiko b ✗ average epoch rate per hr = 17.86,  eta = 3:38:21\n",
      "epoch 26 of 90 (46.67 %) 2.0757 ngiapu ma nwo mieme tomoni ma  /     i ma nio bi  i bamu i ba b ✗ average epoch rate per hr = 17.42,  eta = 3:43:51\n",
      "epoch 26 of 90 (36.67 %) 2.0757 eretonbo na berekonbo na nwo m /     i ma nio bi  i bamu i ba b ✗ average epoch rate per hr = 17.42,  eta = 3:43:51\n",
      "epoch 27 of 90 (33.33 %) 2.0879  mi mun,. ani o kaldia ama mi  / bi ba    bni s biram  b i ba b ✗ average epoch rate per hr = 17.69,  eta = 3:37:03\n",
      "epoch 27 of 90 (26.67 %) 2.0879 irinwengiaru mi na kpekima sim / bi ba    bni s biram  b i ba b ✗ average epoch rate per hr = 17.69,  eta = 3:37:03\n",
      "epoch 28 of 90 (60.00 %) 2.0864  so diki se tamuno be boma mi  / be oiki bi iimuno be nora ba b ✗ average epoch rate per hr = 17.94,  eta = 3:30:41\n",
      "epoch 28 of 90 (50.00 %) 2.0864 se ini pirime. min mi gboloma  / be oiki bi iimuno be nora ba b ✗ average epoch rate per hr = 17.94,  eta = 3:30:41\n",
      "epoch 28 of 90 (40.00 %) 2.0890  piki yeoribia oku. ananayas b / biki be  i e  b u ab i a a abe ✗ average epoch rate per hr = 17.54,  eta = 3:35:32\n",
      "epoch 28 of 90 (30.00 %) 2.0890 apu bo a bian mun wari mi lame / biki be  i e  b u ab i a a abe ✗ average epoch rate per hr = 17.54,  eta = 3:35:32\n",
      "epoch 29 of 90 (46.67 %) 2.0673  bipi se piri oria ikiapu mamg / be i ii eiki b i  b i  i ma ab ✗ average epoch rate per hr = 17.78,  eta = 3:29:13\n",
      "epoch 29 of 90 (53.33 %) 2.0673  okuma ori majikbo be ani ini  / be i ii eiki b i  b i  i ma ab ✗ average epoch rate per hr = 17.78,  eta = 3:29:13\n",
      "epoch 30 of 90 (46.67 %) 2.0992 i bie chu yee, okuma chochi ap /  bi  sii me   o u a bai  i b u ✗ average epoch rate per hr = 18.02,  eta = 3:23:07\n",
      "epoch 30 of 90 (46.67 %) 2.0992 gbukukuma o diki yee, se gele  /  bi  sii me   o u a bai  i b u ✗ average epoch rate per hr = 18.02,  eta = 3:23:07\n",
      "epoch 30 of 90 (36.67 %) 2.0643 oroapu ma kon okweinma bo koko /  i  i ma nirim ue eia be birom ✗ average epoch rate per hr = 17.63,  eta = 3:27:34\n",
      "epoch 30 of 90 (43.33 %) 2.0643 ailas be na, ini soni ikiankor /  i  i ma nirim ue eia be birom ✗ average epoch rate per hr = 17.63,  eta = 3:27:34\n",
      "epoch 31 of 90 (43.33 %) 2.0693 a piki seniapu ma na iria. cho /  biki be e  i ma ni sni  ibai  ✗ average epoch rate per hr = 17.86,  eta = 3:21:32\n",
      "epoch 31 of 90 (50.00 %) 2.0693 re beari jizos be ani mesaya b /  biki be e  i ma ni sni  ibai  ✗ average epoch rate per hr = 17.86,  eta = 3:21:32\n",
      "epoch 32 of 90 (46.67 %) 2.0626 deribo. ari ani tamuno teketek /   i e  b i mni simuno bemo ime ✗ average epoch rate per hr = 18.08,  eta = 3:15:48\n",
      "epoch 32 of 90 (36.67 %) 2.0626 be nab u so se doku paka siria /   i e  b i mni simuno bemo ime ✗ average epoch rate per hr = 18.08,  eta = 3:15:48\n",
      "epoch 32 of 90 (6.67 %) 2.0724 ono y gieinme, sime nweni ma  /  i bemaa  ia  aei i bao e ba b ✗ average epoch rate per hr = 17.72,  eta = 3:19:46\n",
      "epoch 32 of 90 (30.00 %) 2.0724 , o kobirima mi kanme. masidon /  i bemaa  ia  aei i bao e ba b ✗ average epoch rate per hr = 17.72,  eta = 3:19:46\n",
      "epoch 33 of 90 (50.00 %) 2.0766 sime siateme ma piki inia bie  / e i ni  ame ni biki bni  be  s ✗ average epoch rate per hr = 17.93,  eta = 3:14:05\n",
      "epoch 33 of 90 (43.33 %) 2.0766 se beinma ye goyegoye now duko / e i ni  ame ni biki bni  be  s ✗ average epoch rate per hr = 17.93,  eta = 3:14:05\n",
      "epoch 33 of 90 (30.00 %) 2.0795 a teme be ori i beri jinesam n /  bamenni n i mnio e mi i   iba ✗ average epoch rate per hr = 17.59,  eta = 3:17:52\n",
      "epoch 33 of 90 (33.33 %) 2.0795 owuniberetonbo be o balafame o /  bamenni n i mnio e mi i   iba ✗ average epoch rate per hr = 17.59,  eta = 3:17:52\n",
      "epoch 34 of 90 (43.33 %) 2.0357 nibo be piri yee, i bereni se  /   i be niki be   onio e a be e ✗ average epoch rate per hr = 17.79,  eta = 3:12:13\n",
      "epoch 34 of 90 (60.00 %) 2.0357 . a piki ini so tamuno be bu n /   i be niki be   onio e a be e ✗ average epoch rate per hr = 17.79,  eta = 3:12:13\n",
      "epoch 35 of 90 (36.67 %) 2.0549  owuniberetonbo be bara bu ori / b o a i e emue be nera ai b i  ✗ average epoch rate per hr = 17.99,  eta = 3:06:43\n",
      "epoch 35 of 90 (30.00 %) 2.0549  mie kurommame. tona siki a nw / b o a i e emue be nera ai b i  ✗ average epoch rate per hr = 17.99,  eta = 3:06:43\n",
      "epoch 35 of 90 (40.00 %) 2.0828 punumaye ma now duko beuu pol  / i i a e ma ni obeko be  mmirim ✗ average epoch rate per hr = 17.67,  eta = 3:10:11\n",
      "epoch 35 of 90 (30.00 %) 2.0828 ele ti mun owoinaru kulo limo  / i i a e ma ni obeko be  mmirim ✗ average epoch rate per hr = 17.67,  eta = 3:10:11\n",
      "epoch 36 of 90 (36.67 %) 2.0564 ma mun dokiari aru mi se wa ar / a ba  aiku  i mni ma bi eo bni ✗ average epoch rate per hr = 17.86,  eta = 3:04:44\n",
      "epoch 36 of 90 (26.67 %) 2.0564 eretibi ma oruru bu simeoku mi / a ba  aiku  i mni ma bi eo bni ✗ average epoch rate per hr = 17.86,  eta = 3:04:44\n",
      "epoch 37 of 90 (40.00 %) 2.0745 ru mi bie sein wa pirime.   mo / i mi bi  si eioo biki a  anii  ✗ average epoch rate per hr = 18.05,  eta = 2:59:30\n",
      "epoch 37 of 90 (46.67 %) 2.0745 iri se ini os seni mgbesechin  / i mi bi  si eioo biki a  anii  ✗ average epoch rate per hr = 18.05,  eta = 2:59:30\n",
      "epoch 37 of 90 (40.00 %) 2.1001 i bu judas be anyanabo igbike  /  be bi omibe nnia a o beiori a ✗ average epoch rate per hr = 17.74,  eta = 3:02:38\n",
      "epoch 37 of 90 (43.33 %) 2.1001 tatari o se o firimmame, o bel /  be bi omibe nnia a o beiori a ✗ average epoch rate per hr = 17.74,  eta = 3:02:38\n",
      "epoch 38 of 90 (43.33 %) 2.0361 wo deri, se anibe igbiki dia n / o biki  oe ini i bniori aik bi ✗ average epoch rate per hr = 17.92,  eta = 2:57:26\n",
      "epoch 38 of 90 (40.00 %) 2.0361 bie sime bome, inia obi apu ma / o biki  oe ini i bniori aik bi ✗ average epoch rate per hr = 17.92,  eta = 2:57:26\n",
      "epoch 38 of 90 (30.00 %) 2.0482  be kura mesi nengima ye o now / be niro ai e ii io i be nrbi o ✗ average epoch rate per hr = 17.62,  eta = 3:00:25\n",
      "epoch 38 of 90 (46.67 %) 2.0482  se bie ini angabia, ani ini o / be niro ai e ii io i be nrbi o ✗ average epoch rate per hr = 17.62,  eta = 3:00:25\n",
      "epoch 39 of 90 (46.67 %) 2.0609 obu pirime, okuma ini piki ori /  o biki a  a i a bai siki b i  ✗ average epoch rate per hr = 17.80,  eta = 2:55:15\n",
      "epoch 39 of 90 (23.33 %) 2.0609 kume, nyanabo mi sib u barasin /  o biki a  a i a bai siki b i  ✗ average epoch rate per hr = 17.80,  eta = 2:55:15\n",
      "epoch 40 of 90 (50.00 %) 2.0591 e ori ori ye mi ijira se obu s /  n i m i me mi bni i ae n i be ✗ average epoch rate per hr = 17.98,  eta = 2:50:12\n",
      "epoch 40 of 90 (53.33 %) 2.0591 , jizos be na minabu na, ateil /  n i m i me mi bni i ae n i be ✗ average epoch rate per hr = 17.98,  eta = 2:50:12\n",
      "epoch 40 of 90 (43.33 %) 2.0600 ip be na etiopia firitibinibo  /  ibe na s em uk biri ame i i b ✗ average epoch rate per hr = 17.69,  eta = 2:52:57\n",
      "epoch 40 of 90 (40.00 %) 2.0600 miese i i firima siki a bome a /  ibe na s em uk biri ame i i b ✗ average epoch rate per hr = 17.69,  eta = 2:52:57\n",
      "epoch 41 of 90 (36.67 %) 2.0511 ama owuapu se o firimmame, mi  /  a b o  i ma n biri ae a  ai b ✗ average epoch rate per hr = 17.86,  eta = 2:47:56\n",
      "epoch 41 of 90 (36.67 %) 2.0511 ita be oko mieme, se enjelbo b /  a b o  i ma n biri ae a  ai b ✗ average epoch rate per hr = 17.86,  eta = 2:47:56\n",
      "epoch 42 of 90 (43.33 %) 2.0723  mi bie tekeari siki a ikian o / bi bi  same  i me i i ini  ib  ✗ average epoch rate per hr = 18.03,  eta = 2:43:05\n",
      "epoch 42 of 90 (63.33 %) 2.0723 nwo be ye mi, mioku ori ani mi / bi bi  same  i me i i ini  ib  ✗ average epoch rate per hr = 18.03,  eta = 2:43:05\n",
      "epoch 42 of 90 (30.00 %) 2.0399 ame  saipros bie banabas be na /  a nne eik  me  so a o ebe ni  ✗ average epoch rate per hr = 17.76,  eta = 2:45:34\n",
      "epoch 42 of 90 (43.33 %) 2.0399 se koroma nyana min bere mi pi /  a nne eik  me  so a o ebe ni  ✗ average epoch rate per hr = 17.76,  eta = 2:45:34\n",
      "epoch 43 of 90 (56.67 %) 2.0636 i bie sime tomoni ma ini puame /  be  si i namuni ba bni bikma  ✗ average epoch rate per hr = 17.92,  eta = 2:40:45\n",
      "epoch 43 of 90 (30.00 %) 2.0636 e, se olokuabe, mina owuapu ma /  be  si i namuni ba bni bikma  ✗ average epoch rate per hr = 17.92,  eta = 2:40:45\n",
      "epoch 44 of 90 (50.00 %) 2.0566 e ini bo toru na gieina ye ma  /  nni se bemu oi siki i be mi b ✗ average epoch rate per hr = 18.07,  eta = 2:36:01\n",
      "epoch 44 of 90 (53.33 %) 2.0566 gba nwo tememe, se ini miese i /  nni se bemu oi siki i be mi b ✗ average epoch rate per hr = 18.07,  eta = 2:36:01\n",
      "epoch 44 of 90 (36.67 %) 2.0576 siki ikoli bie ini pakuma bome / e i bni o mi  sni siri a be a  ✗ average epoch rate per hr = 17.81,  eta = 2:38:19\n",
      "epoch 44 of 90 (43.33 %) 2.0576  anga juapu mamgba piki jinsea / e i bni o mi  sni siri a be a  ✗ average epoch rate per hr = 17.81,  eta = 2:38:19\n",
      "epoch 45 of 90 (33.33 %) 2.0435 kuro bara se oki sa ye oforie, / i a be i ai i u mi be mri i    ✗ average epoch rate per hr = 17.71,  eta = 2:35:49\n",
      "epoch 45 of 90 (43.33 %) 2.0435 ose okwein ini piria bara ini  / i a be i ai i u mi be mri i    ✗ average epoch rate per hr = 17.71,  eta = 2:35:49\n",
      "epoch 46 of 90 (36.67 %) 2.0551 be tibi gose fi mi soni a buka / e bomo bi e iirbi be i b ie o  ✗ average epoch rate per hr = 17.86,  eta = 2:31:08\n",
      "epoch 46 of 90 (46.67 %) 2.0551 ibo be be se o some  pol be se / e bomo bi e iirbi be i b ie o  ✗ average epoch rate per hr = 17.86,  eta = 2:31:08\n",
      "epoch 47 of 90 (33.33 %) 2.0541  ini o fomubia erechi o fina s / bni s biri o  b i ei b biri be ✗ average epoch rate per hr = 18.01,  eta = 2:26:35\n",
      "epoch 47 of 90 (46.67 %) 2.0541 a banaisi ma na ini sizaria fe / bni s biri o  b i ei b biri be ✗ average epoch rate per hr = 18.01,  eta = 2:26:35\n",
      "epoch 47 of 90 (40.00 %) 2.0587 ari i bipi duko  ineda barana  /  i mnie i mako bbei ikbera a b ✗ average epoch rate per hr = 17.77,  eta = 2:28:35\n",
      "epoch 47 of 90 (40.00 %) 2.0587 indeinma ani dokume, piki opu  /  i mnie i mako bbei ikbera a b ✗ average epoch rate per hr = 17.77,  eta = 2:28:35\n",
      "epoch 48 of 90 (46.67 %) 2.0510 ni gbori breni ye mi, mi minea /   biori mei e be mi  si ba     ✗ average epoch rate per hr = 17.91,  eta = 2:24:02\n",
      "epoch 48 of 90 (43.33 %) 2.0510  fe mi bie na piki terea igoni /   biori mei e be mi  si ba     ✗ average epoch rate per hr = 17.91,  eta = 2:24:02\n",
      "epoch 49 of 90 (36.67 %) 2.0533 u mi bie wa fonoma mume  karak /  ma bi  so niri i ba a nniri a ✗ average epoch rate per hr = 18.05,  eta = 2:19:35\n",
      "epoch 49 of 90 (36.67 %) 2.0533 lemasam. ani dikibugerere mi y /  ma bi  so niri i ba a nniri a ✗ average epoch rate per hr = 18.05,  eta = 2:19:35\n",
      "epoch 49 of 90 (40.00 %) 2.0299 i ikiaso dumo kon mi, se dikib /  bni  i baka bi ama  se iiki e ✗ average epoch rate per hr = 17.82,  eta = 2:21:26\n",
      "epoch 49 of 90 (43.33 %) 2.0299 u be tetema ani nwose taitos b /  bni  i baka bi ama  se iiki e ✗ average epoch rate per hr = 17.82,  eta = 2:21:26\n",
      "epoch 50 of 90 (43.33 %) 2.0308 s nwo chin omonibo be nyana bo / emio bii  b i   i be nie a be  ✗ average epoch rate per hr = 17.96,  eta = 2:16:59\n",
      "epoch 50 of 90 (33.33 %) 2.0308 minea kerenibipima seni bereni / emio bii  b i   i be nie a be  ✗ average epoch rate per hr = 17.96,  eta = 2:16:59\n",
      "epoch 51 of 90 (40.00 %) 2.0479 e inia bu okime, okuma miemiey /  nni  be b u a  a u a ba  i  e ✗ average epoch rate per hr = 18.09,  eta = 2:12:40\n",
      "epoch 51 of 90 (43.33 %) 2.0479  mi siki apu ma bar abo yema   /  nni  be b u a  a u a ba  i  e ✗ average epoch rate per hr = 18.09,  eta = 2:12:40\n",
      "epoch 51 of 90 (33.33 %) 2.0466  gbeinbia. iri ani se i biekor / bio eio   bni mni si inier eri ✗ average epoch rate per hr = 17.87,  eta = 2:14:20\n",
      "epoch 51 of 90 (40.00 %) 2.0466 ki nyanabo be bie minabo bara  / bio eio   bni mni si inier eri ✗ average epoch rate per hr = 17.87,  eta = 2:14:20\n",
      "epoch 52 of 90 (36.67 %) 2.0416  o fiafia teme be bu boro wa d / b bir i  bamenni ne be i bo ni ✗ average epoch rate per hr = 18.00,  eta = 2:10:01\n",
      "epoch 52 of 90 (46.67 %) 2.0416  sime apu ma bie siteme ma des / b bir i  bamenni ne be i bo ni ✗ average epoch rate per hr = 18.00,  eta = 2:10:01\n",
      "epoch 52 of 90 (30.00 %) 2.0282  firi mi .  ..  galili bie sa / biri bi bionm inni i a be  si  ✗ average epoch rate per hr = 17.78,  eta = 2:11:36\n",
      "epoch 52 of 90 (46.67 %) 2.0282 o mieari ye ma ini nwo name. t / biri bi bionm inni i a be  si  ✗ average epoch rate per hr = 17.78,  eta = 2:11:36\n",
      "epoch 53 of 90 (46.67 %) 2.0577 iari ogbo, tomonibo be o sise  /   i m ior oamuni i be n be e i ✗ average epoch rate per hr = 17.91,  eta = 2:07:19\n",
      "epoch 53 of 90 (43.33 %) 2.0577 o ma na kikina jin-a kabo nwos /   i m ior oamuni i be n be e i ✗ average epoch rate per hr = 17.91,  eta = 2:07:19\n",
      "epoch 54 of 90 (23.33 %) 2.0489  aka bu yediesimeme. kobiriima / bnu ai be ak e i e  airo i  i  ✗ average epoch rate per hr = 18.04,  eta = 2:03:04\n",
      "epoch 54 of 90 (50.00 %) 2.0489 eri ini firima pakumame. o kur / bnu ai be ak e i e  airo i  i  ✗ average epoch rate per hr = 18.04,  eta = 2:03:04\n",
      "epoch 54 of 90 (43.33 %) 1.9896 kkere mi nwo koromaso.  se jiz / i  i mi bio birima e  bni iino ✗ average epoch rate per hr = 17.82,  eta = 2:04:33\n",
      "epoch 54 of 90 (36.67 %) 1.9896 o duko nwengime, ari be daye,  / i  i mi bio birima e  bni iino ✗ average epoch rate per hr = 17.82,  eta = 2:04:33\n",
      "epoch 55 of 90 (46.67 %) 2.0456 nde finji na oyeasi ma nwo pir /  a oirii bi bru  i mi nio biki ✗ average epoch rate per hr = 17.95,  eta = 2:00:20\n",
      "epoch 55 of 90 (50.00 %) 2.0456 lu punbo nwose bo jizos be pir /  a oirii bi bru  i mi nio biki ✗ average epoch rate per hr = 17.95,  eta = 2:00:20\n",
      "epoch 56 of 90 (40.00 %) 2.0460 eni awomeni ma piri. ani karak /  i b u i e ba biki  b i siri a ✗ average epoch rate per hr = 18.07,  eta = 1:56:12\n",
      "epoch 56 of 90 (63.33 %) 2.0460 e, okuma piki i se firima bo b /  i b u i e ba biki  b i siri a ✗ average epoch rate per hr = 18.07,  eta = 1:56:12\n",
      "epoch 56 of 90 (46.67 %) 2.0306 oriye sime mozizi be piri, gbo /  i e mi i na     be niki  onor ✗ average epoch rate per hr = 17.87,  eta = 1:57:32\n",
      "epoch 56 of 90 (46.67 %) 2.0306 wo bime bebe o firinwengibo so /  i e mi i na     be niki  onor ✗ average epoch rate per hr = 17.87,  eta = 1:57:32\n",
      "epoch 57 of 90 (33.33 %) 2.0337 s be oputekewari mi mume (mati / eme n u ome o i mi ba a nii ab ✗ average epoch rate per hr = 17.79,  eta = 1:54:41\n",
      "epoch 57 of 90 (30.00 %) 2.0337 matio .- luk .-)    opuma bala / eme n u ome o i mi ba a nii ab ✗ average epoch rate per hr = 17.79,  eta = 1:54:41\n",
      "epoch 58 of 90 (46.67 %) 2.0426 na nyanabo be kenge mi tamuno- /   bae a o be nirio ni bomuno   ✗ average epoch rate per hr = 17.90,  eta = 1:50:35\n",
      "epoch 58 of 90 (46.67 %) 2.0426 n jizos be bie beinme, se ori  /   bae a o be nirio ni bomuno   ✗ average epoch rate per hr = 17.90,  eta = 1:50:35\n",
      "epoch 59 of 90 (66.67 %) 2.0288  se tamuno be ori ominea si ma / be iimuno be nri m ine  bi ii  ✗ average epoch rate per hr = 18.02,  eta = 1:46:32\n",
      "epoch 59 of 90 (36.67 %) 2.0288 uapuawo ma jizos be boanajis n / be iimuno be nri m ine  bi ii  ✗ average epoch rate per hr = 18.02,  eta = 1:46:32\n",
      "epoch 59 of 90 (53.33 %) 2.0318 i duko ye mi na se pekereme, b /  biko be mi bi be iiki e e  ae ✗ average epoch rate per hr = 17.83,  eta = 1:47:42\n",
      "epoch 59 of 90 (46.67 %) 2.0318 okuma inia bala opuma fame, se /  biko be mi bi be iiki e e  ae ✗ average epoch rate per hr = 17.83,  eta = 1:47:42\n",
      "epoch 60 of 90 (36.67 %) 2.0381 okuma, o beri nyaname bebe, o  /  u a  a ie e bie a a ni e  oni ✗ average epoch rate per hr = 17.94,  eta = 1:43:39\n",
      "epoch 60 of 90 (30.00 %) 2.0381 be jon mengisarabo be ari o ti /  u a  a ie e bie a a ni e  oni ✗ average epoch rate per hr = 17.94,  eta = 1:43:39\n",
      "epoch 61 of 90 (40.00 %) 2.0354 iapu a gwosam nwo be soni. ari /   i m iiori abao be ne i  bni  ✗ average epoch rate per hr = 18.05,  eta = 1:39:42\n",
      "epoch 61 of 90 (26.67 %) 2.0354 rachua dabo anikanika nyengibo /   i m iiori abao be ne i  bni  ✗ average epoch rate per hr = 18.05,  eta = 1:39:42\n",
      "epoch 61 of 90 (13.33 %) 2.0350 ini gbelayee, nde  nyana fitu /  i biore a   oii oimie a sirim ✗ average epoch rate per hr = 17.87,  eta = 1:40:44\n",
      "epoch 61 of 90 (40.00 %) 2.0350 se seniapu ma na, tibini agbam /  i biore a   oii oimie a sirim ✗ average epoch rate per hr = 17.87,  eta = 1:40:44\n",
      "epoch 62 of 90 (43.33 %) 2.0207 name, se bipiiniki kon bo be p /   a  ae ii i    i iirimo be ni ✗ average epoch rate per hr = 17.98,  eta = 1:36:47\n",
      "epoch 62 of 90 (40.00 %) 2.0207 e inibo mie kpainma bia yee, a /   a  ae ii i    i iirimo be ni ✗ average epoch rate per hr = 17.98,  eta = 1:36:47\n",
      "epoch 63 of 90 (40.00 %) 2.0359  nwo okibo i pirime, anatibi s / bio b u e beiiri e  ani abo be ✗ average epoch rate per hr = 18.09,  eta = 1:32:53\n",
      "epoch 63 of 90 (33.33 %) 2.0359  no nwose o gbelame bebe, o du / bio b u e beiiri e  ani abo be ✗ average epoch rate per hr = 18.09,  eta = 1:32:53\n",
      "epoch 63 of 90 (36.67 %) 1.9946 nwo la siki, ani gbotubara obu /  o bimai i  oni sioromo i aru  ✗ average epoch rate per hr = 17.90,  eta = 1:33:50\n",
      "epoch 63 of 90 (43.33 %) 1.9946 i bu sise bia ene mi bu, tubo  /  o bimai i  oni sioromo i aru  ✗ average epoch rate per hr = 17.90,  eta = 1:33:50\n",
      "epoch 64 of 90 (36.67 %) 1.9999  soni omina sima bu o barasin  / be i b i i be i be o beri a ib ✗ average epoch rate per hr = 18.01,  eta = 1:29:56\n",
      "epoch 64 of 90 (43.33 %) 1.9999 na tuburu apu ma ini pa ori na / be i b i i be i be o beri a ib ✗ average epoch rate per hr = 18.01,  eta = 1:29:56\n",
      "epoch 64 of 90 (43.33 %) 2.0311 ama fediama ari pa gbori kobo  /  a bi ek a b i mi iaori mi o b ✗ average epoch rate per hr = 17.83,  eta = 1:30:51\n",
      "epoch 64 of 90 (43.33 %) 2.0311 oromau nwose be feinkabo be na /  a bi ek a b i mi iaori mi o b ✗ average epoch rate per hr = 17.83,  eta = 1:30:51\n",
      "epoch 65 of 90 (53.33 %) 2.0072  be na ini oko owuapu ma na we / be ni sni b u oko mi ma ni so  ✗ average epoch rate per hr = 17.94,  eta = 1:26:58\n",
      "epoch 65 of 90 (60.00 %) 2.0072 o kelema tomoni ma o nwo diki  / be ni sni b u oko mi ma ni so  ✗ average epoch rate per hr = 17.94,  eta = 1:26:58\n",
      "epoch 66 of 90 (43.33 %) 2.0178 ia tomoni ma soni now pirime   /   bamuni ba be i ba obiki e nn ✗ average epoch rate per hr = 18.04,  eta = 1:23:09\n",
      "epoch 66 of 90 (46.67 %) 2.0178 ori apu ma, siateme ma bie sim /   bamuni ba be i ba obiki e nn ✗ average epoch rate per hr = 18.04,  eta = 1:23:09\n",
      "epoch 66 of 90 (56.67 %) 2.0095 e o na ye ma bu weri o seni be /  n bi ne mi be oo i m be i be  ✗ average epoch rate per hr = 17.87,  eta = 1:23:57\n",
      "epoch 66 of 90 (43.33 %) 2.0095 i na siki, ini bo oria oju mi  /  n bi ne mi be oo i m be i be  ✗ average epoch rate per hr = 17.87,  eta = 1:23:57\n",
      "epoch 67 of 90 (53.33 %) 2.0228 ri a bara olo se nwose i beabe / i bniera a u be nio e inie  e  ✗ average epoch rate per hr = 17.97,  eta = 1:20:08\n",
      "epoch 67 of 90 (26.67 %) 2.0228 koroma obirima piri    nyanab / i bniera a u be nio e inie  e  ✗ average epoch rate per hr = 17.97,  eta = 1:20:08\n",
      "epoch 68 of 90 (43.33 %) 2.0145  mi kpo koroma nyo mi  ini aru / bi bir marima bae bi bbei s i  ✗ average epoch rate per hr = 18.07,  eta = 1:16:22\n",
      "epoch 68 of 90 (30.00 %) 2.0145 kabome, be ibu yela toku bee o / bi bir marima bae bi bbei s i  ✗ average epoch rate per hr = 18.07,  eta = 1:16:22\n",
      "epoch 68 of 90 (46.67 %) 2.0061 apu ma biebaramaye nwo some na /  i ma ni  e a a e mio be i ni  ✗ average epoch rate per hr = 17.90,  eta = 1:17:05\n",
      "epoch 68 of 90 (43.33 %) 2.0061 so eke  anisiki ori o bara fin /  i ma ni  e a a e mio be i ni  ✗ average epoch rate per hr = 17.90,  eta = 1:17:05\n",
      "epoch 69 of 90 (33.33 %) 1.9982  neme, anatibi o ye seni ora o / bi i  ani abo b be ni e b i ak ✗ average epoch rate per hr = 18.00,  eta = 1:13:20\n",
      "epoch 69 of 90 (43.33 %) 1.9982 i mi, tomoni mamgba tekewari i / bi i  ani abo b be ni e b i ak ✗ average epoch rate per hr = 18.00,  eta = 1:13:20\n",
      "epoch 69 of 90 (40.00 %) 2.0005 ibo iya amabara anga, gboribo  /  i bee ani e a anio  iiori e b ✗ average epoch rate per hr = 17.83,  eta = 1:14:01\n",
      "epoch 69 of 90 (56.67 %) 2.0005   jizos be oputekewari mi bie  /  i bee ani e a anio  iiori e b ✗ average epoch rate per hr = 17.83,  eta = 1:14:01\n",
      "epoch 70 of 90 (43.33 %) 1.9852 ee  ye mangba be kuluma ori or /   mne mi abo bo ni oma b i m i ✗ average epoch rate per hr = 17.93,  eta = 1:10:15\n",
      "epoch 70 of 90 (33.33 %) 1.9852 ominea kubie bu dipi okwein mi /   mne mi abo bo ni oma b i m i ✗ average epoch rate per hr = 17.93,  eta = 1:10:15\n",
      "epoch 71 of 90 (43.33 %) 2.0319 bia  se ini o kun se o se bere / e  bbe ini s birami i be ii e  ✗ average epoch rate per hr = 18.03,  eta = 1:06:34\n",
      "epoch 71 of 90 (56.67 %) 2.0319  se ani o bara ake bebe, ani o / e  bbe ini s birami i be ii e  ✗ average epoch rate per hr = 18.03,  eta = 1:06:34\n",
      "epoch 71 of 90 (50.00 %) 2.0561 fori-e bebe, ani okuma, ani fi / i i a ni e  oni s u a  ani sir ✗ average epoch rate per hr = 17.87,  eta = 1:07:09\n",
      "epoch 71 of 90 (23.33 %) 2.0561 kara nwo nemibia erechi-e. gol / i i a ni e  oni s u a  ani sir ✗ average epoch rate per hr = 17.87,  eta = 1:07:09\n",
      "epoch 72 of 90 (33.33 %) 1.9751 o lame. omine soni oko se yein /  be a  a i i ne i i u oe ie ei ✗ average epoch rate per hr = 17.96,  eta = 1:03:28\n",
      "epoch 72 of 90 (36.67 %) 1.9751 erima piki yawu teme bu simegb /  be a  a i i ne i i u oe ie ei ✗ average epoch rate per hr = 17.96,  eta = 1:03:28\n",
      "epoch 73 of 90 (30.00 %) 2.0279 o simeoku sime, siki mamgba te /  be i  u oe i  ae i ii abo bom ✗ average epoch rate per hr = 18.05,  eta = 0:59:49\n",
      "epoch 73 of 90 (40.00 %) 2.0279 abia oku. ominea bubalabalama  /  be i  u oe i  ae i ii abo bom ✗ average epoch rate per hr = 18.05,  eta = 0:59:49\n",
      "epoch 73 of 90 (36.67 %) 2.0214 wo ojumini bu torusioorisa sik / o b i a   be bomu o   i e ii i ✗ average epoch rate per hr = 17.90,  eta = 1:00:20\n",
      "epoch 73 of 90 (43.33 %) 2.0214 osimake.  okuma ini piri bie n / o b i a   be bomu o   i e ii i ✗ average epoch rate per hr = 17.90,  eta = 1:00:20\n",
      "epoch 74 of 90 (40.00 %) 2.0147  bie ikirima nyana o nwose chu / be  sni i a bae a s bio e iii  ✗ average epoch rate per hr = 17.99,  eta = 0:56:41\n",
      "epoch 74 of 90 (40.00 %) 2.0147 zos be pulo mi ye goyegoye bu  / be  sni i a bae a s bio e iii  ✗ average epoch rate per hr = 17.99,  eta = 0:56:41\n",
      "epoch 75 of 90 (43.33 %) 1.9990 nyanabo be bu gbori ene mi kur /  e a o be ne boori m i na bi o ✗ average epoch rate per hr = 18.08,  eta = 0:53:05\n",
      "epoch 75 of 90 (40.00 %) 1.9990 ara-e na wa sime kokoma ye mi  /  e a o be ne boori m i na bi o ✗ average epoch rate per hr = 18.08,  eta = 0:53:05\n",
      "epoch 75 of 90 (56.67 %) 2.0070  ini duko o pirime na kraist b / bni biko b oiri e na sir ai me ✗ average epoch rate per hr = 17.93,  eta = 0:53:32\n",
      "epoch 75 of 90 (36.67 %) 2.0070 e senibo be se sein yela ereme / bni biko b oiri e na sir ai me ✗ average epoch rate per hr = 17.93,  eta = 0:53:32\n",
      "epoch 76 of 90 (53.33 %) 1.9980 be piki ori na gboribu omi-e.  / e biki b i mi biori e b i e  a ✗ average epoch rate per hr = 18.02,  eta = 0:49:57\n",
      "epoch 76 of 90 (50.00 %) 1.9980 diki toru kirikiri bo o la sik / e biki b i mi biori e b i e  a ✗ average epoch rate per hr = 18.02,  eta = 0:49:57\n",
      "epoch 76 of 90 (50.00 %) 2.0002 ri se ini i firinwengi piriari / i be ini saiiri ao e amiki  i  ✗ average epoch rate per hr = 17.87,  eta = 0:50:22\n",
      "epoch 76 of 90 (40.00 %) 2.0002 in tomonikirie. minea oju bie  / i be ini saiiri ao e amiki  i  ✗ average epoch rate per hr = 17.87,  eta = 0:50:22\n",
      "epoch 77 of 90 (46.67 %) 2.0122 o pikirima mun si dumo bie chu /  biki i a ba  ae iiko be  sai  ✗ average epoch rate per hr = 17.95,  eta = 0:46:47\n",
      "epoch 77 of 90 (43.33 %) 2.0122  diri mi gienbo be min mi miem /  biki i a ba  ae iiko be  sai  ✗ average epoch rate per hr = 17.95,  eta = 0:46:47\n",
      "epoch 78 of 90 (20.00 %) 2.0109 a juo kraistdukonwengi minabo  /  bi  sei ai m o io e ami i i b ✗ average epoch rate per hr = 18.04,  eta = 0:43:13\n",
      "epoch 78 of 90 (43.33 %) 2.0109  o juo bereniapu ma belema, ta /  bi  sei ai m o io e ami i i b ✗ average epoch rate per hr = 18.04,  eta = 0:43:13\n",
      "epoch 78 of 90 (30.00 %) 2.0190 ime.  fiafia dumokonbia oku be /  i  anir i  baka o io  b u oi  ✗ average epoch rate per hr = 17.90,  eta = 0:43:35\n",
      "epoch 78 of 90 (40.00 %) 2.0190 rime nwo bebe, ani i bugererem /  i  anir i  baka o io  b u oi  ✗ average epoch rate per hr = 17.90,  eta = 0:43:35\n",
      "epoch 79 of 90 (36.67 %) 1.9909 se deinma dokibia. aniatibi ny / e iik ia bako e   ani  abo bie ✗ average epoch rate per hr = 17.98,  eta = 0:40:02\n",
      "epoch 79 of 90 (50.00 %) 1.9909  bo be, nwo pikibia. anierechi / e iik ia bako e   ani  abo bie ✗ average epoch rate per hr = 17.98,  eta = 0:40:02\n",
      "epoch 80 of 90 (40.00 %) 2.0285 i dada gose gien ye ani owu se /  biku ob e iiaiime mni s o mi  ✗ average epoch rate per hr = 18.07,  eta = 0:36:31\n",
      "epoch 80 of 90 (43.33 %) 2.0285 oma mi bie. min dieye mi na tu /  biku ob e iiaiime mni s o mi  ✗ average epoch rate per hr = 18.07,  eta = 0:36:31\n",
      "epoch 80 of 90 (33.33 %) 1.9931 ni kun se ini nengimame bebe,  /   bi ami ini sa ioai a ni e  o ✗ average epoch rate per hr = 17.92,  eta = 0:36:49\n",
      "epoch 80 of 90 (43.33 %) 1.9931  sime bara mi o bie ani omie,  /   bi ami ini sa ioai a ni e  o ✗ average epoch rate per hr = 17.92,  eta = 0:36:49\n",
      "epoch 81 of 90 (36.67 %) 2.0006 soabe, anisiki jokoma enekubu  / e  u  oni i i mi osa b i i o m ✗ average epoch rate per hr = 18.01,  eta = 0:33:19\n",
      "epoch 81 of 90 (36.67 %) 2.0006 si omie, a beke na oko sime si / e  u  oni i i mi osa b i i o m ✗ average epoch rate per hr = 18.01,  eta = 0:33:19\n",
      "epoch 82 of 90 (60.00 %) 1.9909  mine, wa sime tamuno be pirim / bini  oo niki namuno be niki e ✗ average epoch rate per hr = 18.09,  eta = 0:29:50\n",
      "epoch 82 of 90 (56.67 %) 1.9909 elema apu ma firimame  diri mi / bini  oo niki namuno be niki e ✗ average epoch rate per hr = 18.09,  eta = 0:29:50\n",
      "epoch 82 of 90 (36.67 %) 2.0033  karama fiafiamadiri mi senibo / biri a bi  i  i aki bi be e i  ✗ average epoch rate per hr = 17.95,  eta = 0:30:05\n",
      "epoch 82 of 90 (46.67 %) 2.0033 imeoku mie  aria firi bu a bor / biri a bi  i  i aki bi be e i  ✗ average epoch rate per hr = 17.95,  eta = 0:30:05\n",
      "epoch 83 of 90 (36.67 %) 2.0069 araye mi nwo nyanaboboke  anie /  i a mi bio bie a o e o onni   ✗ average epoch rate per hr = 18.03,  eta = 0:26:37\n",
      "epoch 83 of 90 (43.33 %) 2.0069 ia  anierechi, omine ominea si /  i a mi bio bie a o e o onni   ✗ average epoch rate per hr = 18.03,  eta = 0:26:37\n",
      "epoch 83 of 90 (60.00 %) 2.0120 ra ani bike  o ye bi se ani o  / i ani be i nnroe mi be ini s b ✗ average epoch rate per hr = 17.89,  eta = 0:26:49\n",
      "epoch 83 of 90 (53.33 %) 2.0120 bu omine tamunoa tomonike, oku / i ani be i nnroe mi be ini s b ✗ average epoch rate per hr = 17.89,  eta = 0:26:49\n",
      "epoch 84 of 90 (33.33 %) 1.9672 e elekima dikime anierechi oin /  n e e a buki i n i  i ei b  i ✗ average epoch rate per hr = 17.98,  eta = 0:23:21\n",
      "epoch 84 of 90 (56.67 %) 1.9672 ia kirikiria diepiriaye ma se  /  n e e a buki i n i  i ei b  i ✗ average epoch rate per hr = 17.98,  eta = 0:23:21\n",
      "epoch 85 of 90 (26.67 %) 1.9862  ma mie ibima ibimame buiderim / bi ba  bni a bae a a ni  i i i ✗ average epoch rate per hr = 18.06,  eta = 0:19:56\n",
      "epoch 85 of 90 (43.33 %) 1.9862 na torumgbolu se oria opu mi o / bi ba  bni a bae a a ni  i i i ✗ average epoch rate per hr = 18.06,  eta = 0:19:56\n",
      "epoch 85 of 90 (43.33 %) 2.0136 hin o piri, ngisi embe finji o /    o biki  oiiae b ee birii bi ✗ average epoch rate per hr = 17.92,  eta = 0:20:05\n",
      "epoch 85 of 90 (43.33 %) 2.0136 bu ma piri oku mie   okuma omi /    o biki  oiiae b ee birii bi ✗ average epoch rate per hr = 17.92,  eta = 0:20:05\n",
      "epoch 86 of 90 (33.33 %) 1.9888 eremame piki bu simame ini omi /  i e a ni i be be i a nai s i  ✗ average epoch rate per hr = 18.00,  eta = 0:16:40\n",
      "epoch 86 of 90 (60.00 %) 1.9888  laoku o nwo diki oria belema  /  i e a ni i be be i a nai s i  ✗ average epoch rate per hr = 18.00,  eta = 0:16:40\n",
      "epoch 87 of 90 (43.33 %) 2.0111  be iya awo, a min mi gien o s / be nne a o  inianibi bi  im be ✗ average epoch rate per hr = 18.08,  eta = 0:13:16\n",
      "epoch 87 of 90 (56.67 %) 2.0111 enime okuma tamuno be chieonye / be nne a o  inianibi bi  im be ✗ average epoch rate per hr = 18.08,  eta = 0:13:16\n",
      "epoch 87 of 90 (60.00 %) 2.0360 ribu omie, tamuno be piki inib / i e b i   oemuno be niki bni i ✗ average epoch rate per hr = 17.95,  eta = 0:13:22\n",
      "epoch 87 of 90 (23.33 %) 2.0360 ist firinwengibo piki jems num / i e b i   oemuno be niki bni i ✗ average epoch rate per hr = 17.95,  eta = 0:13:22\n",
      "epoch 88 of 90 (40.00 %) 1.9714 ara bu, oloko mi beme na omine /  i ai  arimu oa bi e na s i i  ✗ average epoch rate per hr = 18.02,  eta = 0:09:59\n",
      "epoch 88 of 90 (33.33 %) 1.9714 l be o gbelame, nde i nemi oku /  i ai  arimu oa bi e na s i i  ✗ average epoch rate per hr = 18.02,  eta = 0:09:59\n",
      "epoch 88 of 90 (43.33 %) 1.9819 dumo okwein mi tomonikiri mi m /  ka b u  eima bamuni i i mi ba ✗ average epoch rate per hr = 17.89,  eta = 0:10:03\n",
      "epoch 88 of 90 (40.00 %) 1.9819 a okwein-abe. okuma inia bu gb /  ka b u  eima bamuni i i mi ba ✗ average epoch rate per hr = 17.89,  eta = 0:10:03\n",
      "epoch 89 of 90 (53.33 %) 1.9931  bara ani ini seni tombo toku  / be a ani bni si e bomue bemuno ✗ average epoch rate per hr = 17.97,  eta = 0:06:40\n",
      "epoch 89 of 90 (46.67 %) 1.9931 engi mi pikirime. obudukoapu m / be a ani bni si e bomue bemuno ✗ average epoch rate per hr = 17.97,  eta = 0:06:40\n",
      "epoch 90 of 90 (40.00 %) 1.9958 ki se nwengi so nwose i be bo  / i be iio e ami bio e inie nerb ✗ average epoch rate per hr = 18.04,  eta = 0:03:19\n",
      "epoch 90 of 90 (33.33 %) 1.9958  diki ori ama ogbo sime okwein / i be iio e ami bio e inie nerb ✗ average epoch rate per hr = 18.04,  eta = 0:03:19\n",
      "epoch 90 of 90 (36.67 %) 1.9954 oye simegbaso dumo nyaname. ir /  e mi i ea e buko bie a a  ani ✗ average epoch rate per hr = 17.92,  eta = 0:03:20\n",
      "epoch 90 of 90 (30.00 %) 1.9954 bo goyegoye ngisi inibo fi eke /  e mi i ea e buko bie a a  ani ✗ average epoch rate per hr = 17.92,  eta = 0:03:20\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 250\n",
    "plot_every = 100\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "vloss = []\n",
    "accuracy = []\n",
    "iter=0\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "old_epoch=0\n",
    "for x, y_, epoch in txt.rnn_minibatch_sequencer(codetext, BATCHSIZE, SEQLEN, nb_epochs=nb_epoch):\n",
    "    #category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    category =  [lin2txt(l) for l in y_]\n",
    "    lines = [lin2txt(l) for l in x]\n",
    "    category_tensor=mb2t(y_)\n",
    "    line_tensor=mb2t(x)\n",
    "    output, loss = train(torch.tensor(y_,device=device, dtype=torch.long), line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess = [lin2txt([ch.argmax(dim=0) for ch in line]) for line in output]\n",
    "        for i in range(2):\n",
    "            elapsed_time = time.time() - start\n",
    "            #tss = str(datetime.timedelta(seconds=elapsed_time)) # time since start string\n",
    "            if epoch > 0:\n",
    "                speed = epoch/elapsed_time\n",
    "                eta = (nb_epoch-epoch)/speed\n",
    "                sspeed = speed*60*60\n",
    "                seta = str(datetime.timedelta(seconds=int(eta)))\n",
    "                stats = f'average epoch rate per hr = %3.2f,  eta = {seta}'%(sspeed)\n",
    "            else:\n",
    "                stats ='initialising stats..'\n",
    "            correct = '✓' if guess[i] == category[i] else '✗ %s' % stats \n",
    "            acc = [1 if guess[i][j] == category[i][j] else 0 for j in range(min(len(guess[i]),len(category[i])))] \n",
    "            print('epoch %d of %d (%.2f %%) %.4f %s / %s %s' % (epoch+1, nb_epoch, sum(acc)/SEQLEN*100, loss, lines[i], guess[0], correct))\n",
    "        if epoch != old_epoch and epoch % 5 == 0:\n",
    "            torch.save(rnn.state_dict(), PATH)\n",
    "            old_epoch=epoch\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "        vali_x, vali_y, _ = next(txt.rnn_minibatch_sequencer(valitext, BATCHSIZE, VALI_SEQLEN, 1))  # all data in 1 batch\n",
    "        line_tensor = mb2t(vali_x)\n",
    "        category =  [lin2txt(l) for l in vali_y]\n",
    "        output, loss = train(torch.tensor(vali_y, device=device, dtype=torch.long), line_tensor)\n",
    "        guess = [lin2txt([ch.argmax(dim=0) for ch in line]) for line in output]\n",
    "        acc = [1 if guess[0][j] == category[0][j] else 0 for j in range(min(len(guess[i]),len(category[i])))] \n",
    "        vloss.append(loss)\n",
    "        accuracy.append(sum(acc)/len(acc))\n",
    "        with open('vloss.json', 'w') as f:\n",
    "          json.dump(str({\"vloss\":vloss,\"tloss\":all_losses,\"acc\":accuracy}),f)\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa5607ffd0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374812734082397"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
