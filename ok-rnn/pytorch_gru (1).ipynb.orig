{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gXon3UzDNMJP"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "id": "gXon3UzDNMJP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "id": "vn3J_6wsCPu_",
    "outputId": "60976379-4e33-4c35-9b7c-aa2571a0b41d"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/h/Downloads/src/notebooks/research/ok-rnn\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn3J_6wsCPu_",
        "outputId": "40d2c9dc-afd3-4989-f0a9-d254368b212b"
      },
      "source": [
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia-smmi: command not found\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "id": "7eg98sgCNaGx",
    "outputId": "5cae79cb-235f-47a3-88ed-5e6e1b826eb7"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "\u001b[?25l  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
      "\u001b[K     | 2.5MB 6.7MB/s\n",
      "\u001b[?25hBuilding wheels for collected packages: kenlm\n",
      "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kenlm: filename=kenlm-0.0.0-cp36-cp36m-linux_x86_64.whl size=2333092 sha256=c7a402983ca5a550a310ba93b3ea3148ed62168f47d6c3996fa7b6a5224a2c5f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-001xf8e_/wheels/2d/32/73/e3093c9d11dc8abf79c156a4db1a1c5631428059d4f9ff2cba\n",
      "Successfully built kenlm\n",
      "Installing collected packages: kenlm\n",
      "Successfully installed kenlm-0.0.0\n",
      "--2020-12-19 22:07:16--  https://onedrive.live.com/download?cid=EB20651D09521520&resid=EB20651D09521520%21171763&authkey=AAAmYzTmYQLp4lU\n",
      "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
      "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ekou5w.am.files.1drv.com/y4ms7o4He00PteVlja42LG1D9levdYZaDcAxzCPZn6swkj5GPxox9zxniXGxWYSfIJH-vqJz2br7TIdN1qGCOuxjQTVgNcjEKtU2p_vyEoYhAbIwVdDJtu-B9p4JxP53qyDP45zkJyo04AYIAocHssj8Ko4xvxPLo-eiTEh_smW1zltUxpLtio-PmqZoICHRk75f9cUQ8YsMfWkIJie7TZsfA/txts.zip?download&psid=1 [following]\n",
      "--2020-12-19 22:07:18--  https://ekou5w.am.files.1drv.com/y4ms7o4He00PteVlja42LG1D9levdYZaDcAxzCPZn6swkj5GPxox9zxniXGxWYSfIJH-vqJz2br7TIdN1qGCOuxjQTVgNcjEKtU2p_vyEoYhAbIwVdDJtu-B9p4JxP53qyDP45zkJyo04AYIAocHssj8Ko4xvxPLo-eiTEh_smW1zltUxpLtio-PmqZoICHRk75f9cUQ8YsMfWkIJie7TZsfA/txts.zip?download&psid=1\n",
      "Resolving ekou5w.am.files.1drv.com (ekou5w.am.files.1drv.com)... 13.107.42.12\n",
      "Connecting to ekou5w.am.files.1drv.com (ekou5w.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1015212 (991K) [application/zip]\n",
      "Saving to: ‘txts.zip’\n",
      "\n",
      "txts.zip            100%[===================>] 991.42K   922KB/s    in 1.1s    \n",
      "\n",
      "2020-12-19 22:07:19 (922 KB/s) - ‘txts.zip’ saved [1015212/1015212]\n",
      "\n",
      "Archive:  txts.zip\n",
      "   creating: txts/\n",
      "  inflating: txts/acts_new.txt       \n",
      "  inflating: txts/gal_eph_new.txt    \n",
      "  inflating: txts/heb_new.txt        \n",
      "  inflating: txts/jam_jud_new.txt    \n",
      "  inflating: txts/john_new.txt       \n",
      "  inflating: txts/jud_rev_new.txt    \n",
      "  inflating: txts/luke_8_john_new.txt  \n",
      "  inflating: txts/mark01_new.txt     \n",
      "  inflating: txts/matt02_new.txt     \n",
      "  inflating: txts/matt_new.txt       \n",
      "  inflating: txts/phil_col_new.txt   \n",
      "  inflating: txts/thes_tim_new.txt   \n",
      "  inflating: txts/tit_phl_new.txt    \n",
      "Cloning into 'rpynotes'...\n",
      "remote: Enumerating objects: 102, done.\u001b[K\n",
      "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
      "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
      "remote: Total 2668 (delta 50), reused 71 (delta 30), pack-reused 2566\u001b[K\n",
      "Receiving objects: 100% (2668/2668), 205.41 MiB | 34.49 MiB/s, done.\n",
      "Resolving deltas: 100% (1014/1014), done.\n",
      "Checking out files: 100% (1108/1108), done.\n",
      "cp: missing destination file operand after 'rpynotes/ok-rnn/my_txtutils.py'\n",
      "Try 'cp --help' for more information.\n",
      "Sat Dec 19 22:07:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/kpu/kenlm/archive/master.zip\r\n",
    "!wget --no-check-certificate -c -O txts.zip \"https://onedrive.live.com/download?cid=EB20651D09521520&resid=EB20651D09521520%21171763&authkey=AAAmYzTmYQLp4lU\"\r\n",
    "!unzip txts.zip\r\n",
    "!git clone https://github.com/u1273400/rpynotes.git\r\n",
    "!cp rpynotes/ok-rnn/my_txtutils.py .\r\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQjt3TzHNMJZ"
   },
   "outputs": [],
   "source": [
    "# encoding: UTF-8\n",
    "# Copyright 2017 Google.com\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.contrib import layers\n",
    "#from tensorflow.contrib import rnn  # rnn stuff temporarily in contrib, moving back to code in TF 1.1\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import my_txtutils as txt\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq4pWpihNMJb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model parameters\n",
    "#\n",
    "# Usage:\n",
    "#   Training only:\n",
    "#         Leave all the parameters as they are\n",
    "#         Disable validation to run a bit faster (set validation=False below)\n",
    "#         You can follow progress in Tensorboard: tensorboard --log-dir=log\n",
    "#   Training and experimentation (default):\n",
    "#         Keep validation enabled\n",
    "#         You can now play with the parameters anf follow the effects in Tensorboard\n",
    "#         A good choice of parameters ensures that the testing and validation curves stay close\n",
    "#         To see the curves drift apart (\"overfitting\") try to use an insufficient amount of\n",
    "#         training data (shakedir = \"shakespeare/t*.txt\" for example)\n",
    "#\n",
    "nb_epoch=60\n",
    "SEQLEN = 30\n",
    "BATCHSIZE = 200\n",
    "VALI_SEQLEN = SEQLEN\n",
    "ALPHASIZE = txt.ALPHASIZE\n",
    "INTERNALSIZE = 512\n",
    "NLAYERS = 3\n",
    "learning_rate = 0.001  # fixed learning rate\n",
    "dropout_pkeep = 0.8    # some dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "u1osiVsZNMJc",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# encoding: UTF-8\n",
    "# Copyright 2017 Google.com\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# size of the alphabet that we work with\n",
    "ALPHASIZE = 98\n",
    "\n",
    "\n",
    "# Specification of the supported alphabet (subset of ASCII-7)\n",
    "# 10 line feed LF\n",
    "# 32-64 numbers and punctuation\n",
    "# 65-90 upper-case letters\n",
    "# 91-97 more punctuation\n",
    "# 97-122 lower-case letters\n",
    "# 123-126 more punctuation\n",
    "def convert_from_alphabet(a):\n",
    "    \"\"\"Encode a character\n",
    "    :param a: one character\n",
    "    :return: the encoded value\n",
    "    \"\"\"\n",
    "    if a == 9:\n",
    "        return 1\n",
    "    if a == 10:\n",
    "        return 127 - 30  # LF\n",
    "    elif 32 <= a <= 126:\n",
    "        return a - 30\n",
    "    else:\n",
    "        return 0  # unknown\n",
    "\n",
    "\n",
    "# encoded values:\n",
    "# unknown = 0\n",
    "# tab = 1\n",
    "# space = 2\n",
    "# all chars from 32 to 126 = c-30\n",
    "# LF mapped to 127-30\n",
    "def convert_to_alphabet(c, avoid_tab_and_lf=False):\n",
    "    \"\"\"Decode a code point\n",
    "    :param c: code point\n",
    "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
    "    :return: decoded character\n",
    "    \"\"\"\n",
    "    if c == 1:\n",
    "        return 32 if avoid_tab_and_lf else 9  # space instead of TAB\n",
    "    if c == 127 - 30:\n",
    "        return 92 if avoid_tab_and_lf else 10  # \\ instead of LF\n",
    "    if 32 <= c + 30 <= 126:\n",
    "        return c + 30\n",
    "    else:\n",
    "        return 0  # unknown\n",
    "\n",
    "\n",
    "def encode_text(s):\n",
    "    \"\"\"Encode a string.\n",
    "    :param s: a text string\n",
    "    :return: encoded list of code points\n",
    "    \"\"\"\n",
    "    return list(map(lambda a: convert_from_alphabet(ord(a)), s))\n",
    "\n",
    "\n",
    "def decode_to_text(c, avoid_tab_and_lf=False):\n",
    "    \"\"\"Decode an encoded string.\n",
    "    :param c: encoded list of code points\n",
    "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return \"\".join(map(lambda a: chr(convert_to_alphabet(a, avoid_tab_and_lf)), c))\n",
    "\n",
    "\n",
    "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
    "\n",
    "\n",
    "def rnn_minibatch_sequencer(raw_data, batch_size, sequence_size, nb_epochs):\n",
    "    \"\"\"\n",
    "    Divides the data into batches of sequences so that all the sequences in one batch\n",
    "    continue in the next batch. This is a generator that will keep returning batches\n",
    "    until the input data has been seen nb_epochs times. Sequences are continued even\n",
    "    between epochs, apart from one, the one corresponding to the end of raw_data.\n",
    "    The remainder at the end of raw_data that does not fit in an full batch is ignored.\n",
    "    :param raw_data: the training text\n",
    "    :param batch_size: the size of a training minibatch\n",
    "    :param sequence_size: the unroll size of the RNN\n",
    "    :param nb_epochs: number of epochs to train on\n",
    "    :return:\n",
    "        x: one batch of training sequences\n",
    "        y: on batch of target sequences, i.e. training sequences shifted by 1\n",
    "        epoch: the current epoch number (starting at 0)\n",
    "    \"\"\"\n",
    "    data = np.array(raw_data)\n",
    "    data_len = data.shape[0]\n",
    "    # using (data_len-1) because we must provide for the sequence shifted by 1 too\n",
    "    nb_batches = (data_len - 1) // (batch_size * sequence_size)\n",
    "    assert nb_batches > 0, \"Not enough data, even for a single batch. Try using a smaller batch_size.\"\n",
    "    rounded_data_len = nb_batches * batch_size * sequence_size\n",
    "    xdata = np.reshape(data[0:rounded_data_len], [batch_size, nb_batches * sequence_size])\n",
    "    ydata = np.reshape(data[1:rounded_data_len + 1], [batch_size, nb_batches * sequence_size])\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        for batch in range(nb_batches):\n",
    "            x = xdata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            y = ydata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
    "            x = np.roll(x, -epoch, axis=0)  # to continue the text from epoch to epoch (do not reset rnn state!)\n",
    "            y = np.roll(y, -epoch, axis=0)\n",
    "            yield x, y, epoch\n",
    "\n",
    "\n",
    "def find_book(index, bookranges):\n",
    "    return next(\n",
    "        book[\"name\"] for book in bookranges if (book[\"start\"] <= index < book[\"end\"]))\n",
    "\n",
    "\n",
    "def find_book_index(index, bookranges):\n",
    "    return next(\n",
    "        i for i, book in enumerate(bookranges) if (book[\"start\"] <= index < book[\"end\"]))\n",
    "\n",
    "\n",
    "def print_learning_learned_comparison(X, Y, losses, bookranges, batch_loss, batch_accuracy, epoch_size, index, epoch):\n",
    "    \"\"\"Display utility for printing learning statistics\"\"\"\n",
    "    print()\n",
    "    # epoch_size in number of batches\n",
    "    batch_size = X.shape[0]  # batch_size in number of sequences\n",
    "    sequence_len = X.shape[1]  # sequence_len in number of characters\n",
    "    start_index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
    "    for k in range(batch_size):\n",
    "        index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
    "        decx = decode_to_text(X[k], avoid_tab_and_lf=True)\n",
    "        decy = decode_to_text(Y[k], avoid_tab_and_lf=True)\n",
    "        bookname = find_book(index_in_epoch, bookranges)\n",
    "        formatted_bookname = \"{: <10.40}\".format(bookname)  # min 10 and max 40 chars\n",
    "        epoch_string = \"{:4d}\".format(index) + \" (epoch {}) \".format(epoch)\n",
    "        loss_string = \"loss: {:.5f}\".format(losses[k])\n",
    "        print_string = epoch_string + formatted_bookname + \" │ {} │ {} │ {}\"\n",
    "        print(print_string.format(decx, decy, loss_string))\n",
    "        index += sequence_len\n",
    "    # box formatting characters:\n",
    "    # │ \\u2502\n",
    "    # ─ \\u2500\n",
    "    # └ \\u2514\n",
    "    # ┘ \\u2518\n",
    "    # ┴ \\u2534\n",
    "    # ┌ \\u250C\n",
    "    # ┐ \\u2510\n",
    "    format_string = \"└{:─^\" + str(len(epoch_string)) + \"}\"\n",
    "    format_string += \"{:─^\" + str(len(formatted_bookname)) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(decx) + 2) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(decy) + 2) + \"}\"\n",
    "    format_string += \"┴{:─^\" + str(len(loss_string)) + \"}┘\"\n",
    "    footer = format_string.format('INDEX', 'BOOK NAME', 'TRAINING SEQUENCE', 'PREDICTED SEQUENCE', 'LOSS')\n",
    "    print(footer)\n",
    "    # print statistics\n",
    "    batch_index = start_index_in_epoch // (batch_size * sequence_len)\n",
    "    batch_string = \"batch {}/{} in epoch {},\".format(batch_index, epoch_size, epoch)\n",
    "    stats = \"{: <28} batch loss: {:.5f}, batch accuracy: {:.5f}\".format(batch_string, batch_loss, batch_accuracy)\n",
    "    print()\n",
    "    print(\"TRAINING STATS: {}\".format(stats))\n",
    "\n",
    "\n",
    "class Progress:\n",
    "    \"\"\"Text mode progress bar.\n",
    "    Usage:\n",
    "            p = Progress(30)\n",
    "            p.step()\n",
    "            p.step()\n",
    "            p.step(start=True) # to restart form 0%\n",
    "    The progress bar displays a new header at each restart.\"\"\"\n",
    "    def __init__(self, maxi, size=100, msg=\"\"):\n",
    "        \"\"\"\n",
    "        :param maxi: the number of steps required to reach 100%\n",
    "        :param size: the number of characters taken on the screen by the progress bar\n",
    "        :param msg: the message displayed in the header of the progress bat\n",
    "        \"\"\"\n",
    "        self.maxi = maxi\n",
    "        self.p = self.__start_progress(maxi)()  # () to get the iterator from the generator\n",
    "        self.header_printed = False\n",
    "        self.msg = msg\n",
    "        self.size = size\n",
    "\n",
    "    def step(self, reset=False):\n",
    "        if reset:\n",
    "            self.__init__(self.maxi, self.size, self.msg)\n",
    "        if not self.header_printed:\n",
    "            self.__print_header()\n",
    "        next(self.p)\n",
    "\n",
    "    def __print_header(self):\n",
    "        print()\n",
    "        format_string = \"0%{: ^\" + str(self.size - 6) + \"}100%\"\n",
    "        print(format_string.format(self.msg))\n",
    "        self.header_printed = True\n",
    "\n",
    "    def __start_progress(self, maxi):\n",
    "        def print_progress():\n",
    "            # Bresenham's algorithm. Yields the number of dots printed.\n",
    "            # This will always print 100 dots in max invocations.\n",
    "            dx = maxi\n",
    "            dy = self.size\n",
    "            d = dy - dx\n",
    "            for x in range(maxi):\n",
    "                k = 0\n",
    "                while d >= 0:\n",
    "                    print('=', end=\"\", flush=True)\n",
    "                    k += 1\n",
    "                    d -= dx\n",
    "                d += dy\n",
    "                yield k\n",
    "\n",
    "        return print_progress\n",
    "\n",
    "\n",
    "def read_data_files(directory, validation=True):\n",
    "    \"\"\"Read data files according to the specified glob pattern\n",
    "    Optionnaly set aside the last file as validation data.\n",
    "    No validation data is returned if there are 5 files or less.\n",
    "    :param directory: for example \"data/*.txt\"\n",
    "    :param validation: if True (default), sets the last file aside as validation data\n",
    "    :return: training data, validation data, list of loaded file names with ranges\n",
    "     If validation is\n",
    "    \"\"\"\n",
    "    codetext = []\n",
    "    bookranges = []\n",
    "    shakelist = glob.glob(directory, recursive=True)\n",
    "    for shakefile in shakelist:\n",
    "        shaketext = open(shakefile, \"r\")\n",
    "        print(\"Loading file \" + shakefile)\n",
    "        start = len(codetext)\n",
    "        codetext.extend(encode_text(shaketext.read()))\n",
    "        end = len(codetext)\n",
    "        bookranges.append({\"start\": start, \"end\": end, \"name\": shakefile.rsplit(\"/\", 1)[-1]})\n",
    "        shaketext.close()\n",
    "\n",
    "    if len(bookranges) == 0:\n",
    "        sys.exit(\"No training data has been found. Aborting.\")\n",
    "\n",
    "    # For validation, use roughly 90K of text,\n",
    "    # but no more than 10% of the entire text\n",
    "    # and no more than 1 book in 5 => no validation at all for 5 files or fewer.\n",
    "\n",
    "    # 10% of the text is how many files ?\n",
    "    total_len = len(codetext)\n",
    "    validation_len = 0\n",
    "    nb_books1 = 0\n",
    "    for book in reversed(bookranges):\n",
    "        validation_len += book[\"end\"]-book[\"start\"]\n",
    "        nb_books1 += 1\n",
    "        if validation_len > total_len // 10:\n",
    "            break\n",
    "\n",
    "    # 90K of text is how many books ?\n",
    "    validation_len = 0\n",
    "    nb_books2 = 0\n",
    "    for book in reversed(bookranges):\n",
    "        validation_len += book[\"end\"]-book[\"start\"]\n",
    "        nb_books2 += 1\n",
    "        if validation_len > 90*1024:\n",
    "            break\n",
    "\n",
    "    # 20% of the books is how many books ?\n",
    "    nb_books3 = len(bookranges) // 5\n",
    "\n",
    "    # pick the smallest\n",
    "    nb_books = min(nb_books1, nb_books2, nb_books3)\n",
    "\n",
    "    if nb_books == 0 or not validation:\n",
    "        cutoff = len(codetext)\n",
    "    else:\n",
    "        cutoff = bookranges[-nb_books][\"start\"]\n",
    "    valitext = codetext[cutoff:]\n",
    "    codetext = codetext[:cutoff]\n",
    "    return codetext, valitext, bookranges\n",
    "\n",
    "\n",
    "def print_data_stats(datalen, valilen, epoch_size):\n",
    "    datalen_mb = datalen/1024.0/1024.0\n",
    "    valilen_kb = valilen/1024.0\n",
    "    print(\"Training text size is {:.2f}MB with {:.2f}KB set aside for validation.\".format(datalen_mb, valilen_kb)\n",
    "          + \" There will be {} batches per epoch\".format(epoch_size))\n",
    "\n",
    "\n",
    "def print_validation_header(validation_start, bookranges):\n",
    "    bookindex = find_book_index(validation_start, bookranges)\n",
    "    books = ''\n",
    "    for i in range(bookindex, len(bookranges)):\n",
    "        books += bookranges[i][\"name\"]\n",
    "        if i < len(bookranges)-1:\n",
    "            books += \", \"\n",
    "    print(\"{: <60}\".format(\"Validating on \" + books), flush=True)\n",
    "\n",
    "\n",
    "def print_validation_stats(loss, accuracy):\n",
    "    print(\"VALIDATION STATS:                                  loss: {:.5f},       accuracy: {:.5f}\".format(loss,\n",
    "                                                                                                           accuracy))\n",
    "\n",
    "\n",
    "def print_text_generation_header():\n",
    "    print()\n",
    "    print(\"┌{:─^111}┐\".format('Generating random text from learned state'))\n",
    "\n",
    "\n",
    "def print_text_generation_footer():\n",
    "    print()\n",
    "    print(\"└{:─^111}┘\".format('End of generation'))\n",
    "\n",
    "\n",
    "def frequency_limiter(n, multiple=1, modulo=0):\n",
    "    def limit(i):\n",
    "        return i % (multiple * n) == modulo*multiple\n",
    "    return limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "NTbnELiONMJl",
    "jupyter": {
     "outputs_hidden": false
=======
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eg98sgCNaGx",
        "outputId": "43835b9d-95fe-4c19-9c2f-0d14fa2c91f3"
      },
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\r\n",
        "!wget --no-check-certificate -c -O txts.zip \"https://onedrive.live.com/download?cid=EB20651D09521520&resid=EB20651D09521520%21171763&authkey=AAAmYzTmYQLp4lU\"\r\n",
        "!unzip txts.zip\r\n",
        "!git clone https://github.com/u1273400/rpynotes.git\r\n",
        "!cp rpynotes/ok-rnn/my_txtutils.py .\r\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[K     - 2.8MB 12.1MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.0.0-cp36-cp36m-linux_x86_64.whl size=2337841 sha256=feaa39c1d62d0efee890621e8603418a5d1b31f275edfb0d2b18a4d2759d86da\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5yhkx3rd/wheels/2d/32/73/e3093c9d11dc8abf79c156a4db1a1c5631428059d4f9ff2cba\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.0.0\n",
            "--2020-12-22 05:44:49--  https://onedrive.live.com/download?cid=EB20651D09521520&resid=EB20651D09521520%21171763&authkey=AAAmYzTmYQLp4lU\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ekou5w.am.files.1drv.com/y4m9esZltZoLhq_i737DNbAUTW2hJLr92kN-2waOmtqCFglBwwbjmwVaUBF8wgU9dA05tIXXHL6IfFgka8O5-nctnNRVW0qKQbSjDMgP7e0FH37wPzLb03ZpcyiGruEvEHCjCGXgvWg3IUtkuEoHiQrfYqHIDx0D3ejrG0HtSraBu4nHPvryOw7Ag0ednuWo-YxC2TBAadLfbKP7IefUf52Mw/txts.zip?download&psid=1 [following]\n",
            "--2020-12-22 05:44:50--  https://ekou5w.am.files.1drv.com/y4m9esZltZoLhq_i737DNbAUTW2hJLr92kN-2waOmtqCFglBwwbjmwVaUBF8wgU9dA05tIXXHL6IfFgka8O5-nctnNRVW0qKQbSjDMgP7e0FH37wPzLb03ZpcyiGruEvEHCjCGXgvWg3IUtkuEoHiQrfYqHIDx0D3ejrG0HtSraBu4nHPvryOw7Ag0ednuWo-YxC2TBAadLfbKP7IefUf52Mw/txts.zip?download&psid=1\n",
            "Resolving ekou5w.am.files.1drv.com (ekou5w.am.files.1drv.com)... 13.107.42.12\n",
            "Connecting to ekou5w.am.files.1drv.com (ekou5w.am.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1015212 (991K) [application/zip]\n",
            "Saving to: ‘txts.zip’\n",
            "\n",
            "txts.zip            100%[===================>] 991.42K  1.49MB/s    in 0.7s    \n",
            "\n",
            "2020-12-22 05:44:51 (1.49 MB/s) - ‘txts.zip’ saved [1015212/1015212]\n",
            "\n",
            "Archive:  txts.zip\n",
            "   creating: txts/\n",
            "  inflating: txts/acts_new.txt       \n",
            "  inflating: txts/gal_eph_new.txt    \n",
            "  inflating: txts/heb_new.txt        \n",
            "  inflating: txts/jam_jud_new.txt    \n",
            "  inflating: txts/john_new.txt       \n",
            "  inflating: txts/jud_rev_new.txt    \n",
            "  inflating: txts/luke_8_john_new.txt  \n",
            "  inflating: txts/mark01_new.txt     \n",
            "  inflating: txts/matt02_new.txt     \n",
            "  inflating: txts/matt_new.txt       \n",
            "  inflating: txts/phil_col_new.txt   \n",
            "  inflating: txts/thes_tim_new.txt   \n",
            "  inflating: txts/tit_phl_new.txt    \n",
            "Cloning into 'rpynotes'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 2756 (delta 110), reused 133 (delta 63), pack-reused 2566\u001b[K\n",
            "Receiving objects: 100% (2756/2756), 205.49 MiB | 36.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1074/1074), done.\n",
            "Checking out files: 100% (1099/1099), done.\n",
            "Tue Dec 22 05:45:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQjt3TzHNMJZ"
      },
      "source": [
        "# encoding: UTF-8\n",
        "# Copyright 2017 Google.com\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.contrib import layers\n",
        "#from tensorflow.contrib import rnn  # rnn stuff temporarily in contrib, moving back to code in TF 1.1\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import my_txtutils as txt\n",
        "import json\n",
        "import datetime\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "outputId": "54c3a0fe-efd6-4d8b-f5d0-0e66bf1c64e9"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file txts/jam_jud_new.txt\n",
      "Loading file txts/acts_new.txt\n",
      "Loading file txts/gal_eph_new.txt\n",
      "Loading file txts/thes_tim_new.txt\n",
      "Loading file txts/jud_rev_new.txt\n",
      "Loading file txts/luke_8_john_new.txt\n",
      "Loading file txts/tit_phl_new.txt\n",
      "Loading file txts/phil_col_new.txt\n",
      "Loading file txts/heb_new.txt\n",
      "Loading file txts/matt_new.txt\n",
      "Loading file txts/matt02_new.txt\n",
      "Loading file txts/mark01_new.txt\n",
      "Loading file txts/john_new.txt\n"
     ]
    }
   ],
   "source": [
    "# load data, either shakespeare, or the Python source of Tensorflow itself\n",
    "shakedir = \"txts/*.txt\"\n",
    "#shakedir = \"../tensorflow/**/*.py\"\n",
    "codetext, valitext, bookranges = txt.read_data_files(shakedir, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "CnQShJG7NMJq",
    "jupyter": {
     "outputs_hidden": false
=======
      "cell_type": "code",
      "metadata": {
        "id": "pq4pWpihNMJb"
      },
      "source": [
        "\n",
        "# model parameters\n",
        "#\n",
        "# Usage:\n",
        "#   Training only:\n",
        "#         Leave all the parameters as they are\n",
        "#         Disable validation to run a bit faster (set validation=False below)\n",
        "#         You can follow progress in Tensorboard: tensorboard --log-dir=log\n",
        "#   Training and experimentation (default):\n",
        "#         Keep validation enabled\n",
        "#         You can now play with the parameters anf follow the effects in Tensorboard\n",
        "#         A good choice of parameters ensures that the testing and validation curves stay close\n",
        "#         To see the curves drift apart (\"overfitting\") try to use an insufficient amount of\n",
        "#         training data (shakedir = \"shakespeare/t*.txt\" for example)\n",
        "#\n",
        "nb_epoch=125\n",
        "SEQLEN = 30\n",
        "BATCHSIZE = 200\n",
        "VALI_SEQLEN = SEQLEN\n",
        "ALPHASIZE = txt.ALPHASIZE\n",
        "INTERNALSIZE = 512\n",
        "NLAYERS = 3\n",
        "learning_rate = 0.001  # fixed learning rate\n",
        "dropout_pkeep = 0.8    # some dropout"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "cellView": "form",
        "id": "u1osiVsZNMJc"
      },
      "source": [
        "#@title\n",
        "# encoding: UTF-8\n",
        "# Copyright 2017 Google.com\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "# size of the alphabet that we work with\n",
        "ALPHASIZE = 98\n",
        "\n",
        "\n",
        "# Specification of the supported alphabet (subset of ASCII-7)\n",
        "# 10 line feed LF\n",
        "# 32-64 numbers and punctuation\n",
        "# 65-90 upper-case letters\n",
        "# 91-97 more punctuation\n",
        "# 97-122 lower-case letters\n",
        "# 123-126 more punctuation\n",
        "def convert_from_alphabet(a):\n",
        "    \"\"\"Encode a character\n",
        "    :param a: one character\n",
        "    :return: the encoded value\n",
        "    \"\"\"\n",
        "    if a == 9:\n",
        "        return 1\n",
        "    if a == 10:\n",
        "        return 127 - 30  # LF\n",
        "    elif 32 <= a <= 126:\n",
        "        return a - 30\n",
        "    else:\n",
        "        return 0  # unknown\n",
        "\n",
        "\n",
        "# encoded values:\n",
        "# unknown = 0\n",
        "# tab = 1\n",
        "# space = 2\n",
        "# all chars from 32 to 126 = c-30\n",
        "# LF mapped to 127-30\n",
        "def convert_to_alphabet(c, avoid_tab_and_lf=False):\n",
        "    \"\"\"Decode a code point\n",
        "    :param c: code point\n",
        "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
        "    :return: decoded character\n",
        "    \"\"\"\n",
        "    if c == 1:\n",
        "        return 32 if avoid_tab_and_lf else 9  # space instead of TAB\n",
        "    if c == 127 - 30:\n",
        "        return 92 if avoid_tab_and_lf else 10  # \\ instead of LF\n",
        "    if 32 <= c + 30 <= 126:\n",
        "        return c + 30\n",
        "    else:\n",
        "        return 0  # unknown\n",
        "\n",
        "\n",
        "def encode_text(s):\n",
        "    \"\"\"Encode a string.\n",
        "    :param s: a text string\n",
        "    :return: encoded list of code points\n",
        "    \"\"\"\n",
        "    return list(map(lambda a: convert_from_alphabet(ord(a)), s))\n",
        "\n",
        "\n",
        "def decode_to_text(c, avoid_tab_and_lf=False):\n",
        "    \"\"\"Decode an encoded string.\n",
        "    :param c: encoded list of code points\n",
        "    :param avoid_tab_and_lf: if True, tab and line feed characters are replaced by '\\'\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return \"\".join(map(lambda a: chr(convert_to_alphabet(a, avoid_tab_and_lf)), c))\n",
        "\n",
        "\n",
        "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
        "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
        "    according to the provided probabilities. If topn is specified, only the\n",
        "    topn highest probabilities are taken into account.\n",
        "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
        "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
        "    :return: a random integer\n",
        "    \"\"\"\n",
        "    p = np.squeeze(probabilities)\n",
        "    p[np.argsort(p)[:-topn]] = 0\n",
        "    p = p / np.sum(p)\n",
        "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
        "\n",
        "\n",
        "def rnn_minibatch_sequencer(raw_data, batch_size, sequence_size, nb_epochs):\n",
        "    \"\"\"\n",
        "    Divides the data into batches of sequences so that all the sequences in one batch\n",
        "    continue in the next batch. This is a generator that will keep returning batches\n",
        "    until the input data has been seen nb_epochs times. Sequences are continued even\n",
        "    between epochs, apart from one, the one corresponding to the end of raw_data.\n",
        "    The remainder at the end of raw_data that does not fit in an full batch is ignored.\n",
        "    :param raw_data: the training text\n",
        "    :param batch_size: the size of a training minibatch\n",
        "    :param sequence_size: the unroll size of the RNN\n",
        "    :param nb_epochs: number of epochs to train on\n",
        "    :return:\n",
        "        x: one batch of training sequences\n",
        "        y: on batch of target sequences, i.e. training sequences shifted by 1\n",
        "        epoch: the current epoch number (starting at 0)\n",
        "    \"\"\"\n",
        "    data = np.array(raw_data)\n",
        "    data_len = data.shape[0]\n",
        "    # using (data_len-1) because we must provide for the sequence shifted by 1 too\n",
        "    nb_batches = (data_len - 1) // (batch_size * sequence_size)\n",
        "    assert nb_batches > 0, \"Not enough data, even for a single batch. Try using a smaller batch_size.\"\n",
        "    rounded_data_len = nb_batches * batch_size * sequence_size\n",
        "    xdata = np.reshape(data[0:rounded_data_len], [batch_size, nb_batches * sequence_size])\n",
        "    ydata = np.reshape(data[1:rounded_data_len + 1], [batch_size, nb_batches * sequence_size])\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        for batch in range(nb_batches):\n",
        "            x = xdata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
        "            y = ydata[:, batch * sequence_size:(batch + 1) * sequence_size]\n",
        "            x = np.roll(x, -epoch, axis=0)  # to continue the text from epoch to epoch (do not reset rnn state!)\n",
        "            y = np.roll(y, -epoch, axis=0)\n",
        "            yield x, y, epoch\n",
        "\n",
        "\n",
        "def find_book(index, bookranges):\n",
        "    return next(\n",
        "        book[\"name\"] for book in bookranges if (book[\"start\"] <= index < book[\"end\"]))\n",
        "\n",
        "\n",
        "def find_book_index(index, bookranges):\n",
        "    return next(\n",
        "        i for i, book in enumerate(bookranges) if (book[\"start\"] <= index < book[\"end\"]))\n",
        "\n",
        "\n",
        "def print_learning_learned_comparison(X, Y, losses, bookranges, batch_loss, batch_accuracy, epoch_size, index, epoch):\n",
        "    \"\"\"Display utility for printing learning statistics\"\"\"\n",
        "    print()\n",
        "    # epoch_size in number of batches\n",
        "    batch_size = X.shape[0]  # batch_size in number of sequences\n",
        "    sequence_len = X.shape[1]  # sequence_len in number of characters\n",
        "    start_index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
        "    for k in range(batch_size):\n",
        "        index_in_epoch = index % (epoch_size * batch_size * sequence_len)\n",
        "        decx = decode_to_text(X[k], avoid_tab_and_lf=True)\n",
        "        decy = decode_to_text(Y[k], avoid_tab_and_lf=True)\n",
        "        bookname = find_book(index_in_epoch, bookranges)\n",
        "        formatted_bookname = \"{: <10.40}\".format(bookname)  # min 10 and max 40 chars\n",
        "        epoch_string = \"{:4d}\".format(index) + \" (epoch {}) \".format(epoch)\n",
        "        loss_string = \"loss: {:.5f}\".format(losses[k])\n",
        "        print_string = epoch_string + formatted_bookname + \" │ {} │ {} │ {}\"\n",
        "        print(print_string.format(decx, decy, loss_string))\n",
        "        index += sequence_len\n",
        "    # box formatting characters:\n",
        "    # │ \\u2502\n",
        "    # ─ \\u2500\n",
        "    # └ \\u2514\n",
        "    # ┘ \\u2518\n",
        "    # ┴ \\u2534\n",
        "    # ┌ \\u250C\n",
        "    # ┐ \\u2510\n",
        "    format_string = \"└{:─^\" + str(len(epoch_string)) + \"}\"\n",
        "    format_string += \"{:─^\" + str(len(formatted_bookname)) + \"}\"\n",
        "    format_string += \"┴{:─^\" + str(len(decx) + 2) + \"}\"\n",
        "    format_string += \"┴{:─^\" + str(len(decy) + 2) + \"}\"\n",
        "    format_string += \"┴{:─^\" + str(len(loss_string)) + \"}┘\"\n",
        "    footer = format_string.format('INDEX', 'BOOK NAME', 'TRAINING SEQUENCE', 'PREDICTED SEQUENCE', 'LOSS')\n",
        "    print(footer)\n",
        "    # print statistics\n",
        "    batch_index = start_index_in_epoch // (batch_size * sequence_len)\n",
        "    batch_string = \"batch {}/{} in epoch {},\".format(batch_index, epoch_size, epoch)\n",
        "    stats = \"{: <28} batch loss: {:.5f}, batch accuracy: {:.5f}\".format(batch_string, batch_loss, batch_accuracy)\n",
        "    print()\n",
        "    print(\"TRAINING STATS: {}\".format(stats))\n",
        "\n",
        "\n",
        "class Progress:\n",
        "    \"\"\"Text mode progress bar.\n",
        "    Usage:\n",
        "            p = Progress(30)\n",
        "            p.step()\n",
        "            p.step()\n",
        "            p.step(start=True) # to restart form 0%\n",
        "    The progress bar displays a new header at each restart.\"\"\"\n",
        "    def __init__(self, maxi, size=100, msg=\"\"):\n",
        "        \"\"\"\n",
        "        :param maxi: the number of steps required to reach 100%\n",
        "        :param size: the number of characters taken on the screen by the progress bar\n",
        "        :param msg: the message displayed in the header of the progress bat\n",
        "        \"\"\"\n",
        "        self.maxi = maxi\n",
        "        self.p = self.__start_progress(maxi)()  # () to get the iterator from the generator\n",
        "        self.header_printed = False\n",
        "        self.msg = msg\n",
        "        self.size = size\n",
        "\n",
        "    def step(self, reset=False):\n",
        "        if reset:\n",
        "            self.__init__(self.maxi, self.size, self.msg)\n",
        "        if not self.header_printed:\n",
        "            self.__print_header()\n",
        "        next(self.p)\n",
        "\n",
        "    def __print_header(self):\n",
        "        print()\n",
        "        format_string = \"0%{: ^\" + str(self.size - 6) + \"}100%\"\n",
        "        print(format_string.format(self.msg))\n",
        "        self.header_printed = True\n",
        "\n",
        "    def __start_progress(self, maxi):\n",
        "        def print_progress():\n",
        "            # Bresenham's algorithm. Yields the number of dots printed.\n",
        "            # This will always print 100 dots in max invocations.\n",
        "            dx = maxi\n",
        "            dy = self.size\n",
        "            d = dy - dx\n",
        "            for x in range(maxi):\n",
        "                k = 0\n",
        "                while d >= 0:\n",
        "                    print('=', end=\"\", flush=True)\n",
        "                    k += 1\n",
        "                    d -= dx\n",
        "                d += dy\n",
        "                yield k\n",
        "\n",
        "        return print_progress\n",
        "\n",
        "\n",
        "def read_data_files(directory, validation=True):\n",
        "    \"\"\"Read data files according to the specified glob pattern\n",
        "    Optionnaly set aside the last file as validation data.\n",
        "    No validation data is returned if there are 5 files or less.\n",
        "    :param directory: for example \"data/*.txt\"\n",
        "    :param validation: if True (default), sets the last file aside as validation data\n",
        "    :return: training data, validation data, list of loaded file names with ranges\n",
        "     If validation is\n",
        "    \"\"\"\n",
        "    codetext = []\n",
        "    bookranges = []\n",
        "    shakelist = glob.glob(directory, recursive=True)\n",
        "    for shakefile in shakelist:\n",
        "        shaketext = open(shakefile, \"r\")\n",
        "        print(\"Loading file \" + shakefile)\n",
        "        start = len(codetext)\n",
        "        codetext.extend(encode_text(shaketext.read()))\n",
        "        end = len(codetext)\n",
        "        bookranges.append({\"start\": start, \"end\": end, \"name\": shakefile.rsplit(\"/\", 1)[-1]})\n",
        "        shaketext.close()\n",
        "\n",
        "    if len(bookranges) == 0:\n",
        "        sys.exit(\"No training data has been found. Aborting.\")\n",
        "\n",
        "    # For validation, use roughly 90K of text,\n",
        "    # but no more than 10% of the entire text\n",
        "    # and no more than 1 book in 5 => no validation at all for 5 files or fewer.\n",
        "\n",
        "    # 10% of the text is how many files ?\n",
        "    total_len = len(codetext)\n",
        "    validation_len = 0\n",
        "    nb_books1 = 0\n",
        "    for book in reversed(bookranges):\n",
        "        validation_len += book[\"end\"]-book[\"start\"]\n",
        "        nb_books1 += 1\n",
        "        if validation_len > total_len // 10:\n",
        "            break\n",
        "\n",
        "    # 90K of text is how many books ?\n",
        "    validation_len = 0\n",
        "    nb_books2 = 0\n",
        "    for book in reversed(bookranges):\n",
        "        validation_len += book[\"end\"]-book[\"start\"]\n",
        "        nb_books2 += 1\n",
        "        if validation_len > 90*1024:\n",
        "            break\n",
        "\n",
        "    # 20% of the books is how many books ?\n",
        "    nb_books3 = len(bookranges) // 5\n",
        "\n",
        "    # pick the smallest\n",
        "    nb_books = min(nb_books1, nb_books2, nb_books3)\n",
        "\n",
        "    if nb_books == 0 or not validation:\n",
        "        cutoff = len(codetext)\n",
        "    else:\n",
        "        cutoff = bookranges[-nb_books][\"start\"]\n",
        "    valitext = codetext[cutoff:]\n",
        "    codetext = codetext[:cutoff]\n",
        "    return codetext, valitext, bookranges\n",
        "\n",
        "\n",
        "def print_data_stats(datalen, valilen, epoch_size):\n",
        "    datalen_mb = datalen/1024.0/1024.0\n",
        "    valilen_kb = valilen/1024.0\n",
        "    print(\"Training text size is {:.2f}MB with {:.2f}KB set aside for validation.\".format(datalen_mb, valilen_kb)\n",
        "          + \" There will be {} batches per epoch\".format(epoch_size))\n",
        "\n",
        "\n",
        "def print_validation_header(validation_start, bookranges):\n",
        "    bookindex = find_book_index(validation_start, bookranges)\n",
        "    books = ''\n",
        "    for i in range(bookindex, len(bookranges)):\n",
        "        books += bookranges[i][\"name\"]\n",
        "        if i < len(bookranges)-1:\n",
        "            books += \", \"\n",
        "    print(\"{: <60}\".format(\"Validating on \" + books), flush=True)\n",
        "\n",
        "\n",
        "def print_validation_stats(loss, accuracy):\n",
        "    print(\"VALIDATION STATS:                                  loss: {:.5f},       accuracy: {:.5f}\".format(loss,\n",
        "                                                                                                           accuracy))\n",
        "\n",
        "\n",
        "def print_text_generation_header():\n",
        "    print()\n",
        "    print(\"┌{:─^111}┐\".format('Generating random text from learned state'))\n",
        "\n",
        "\n",
        "def print_text_generation_footer():\n",
        "    print()\n",
        "    print(\"└{:─^111}┘\".format('End of generation'))\n",
        "\n",
        "\n",
        "def frequency_limiter(n, multiple=1, modulo=0):\n",
        "    def limit(i):\n",
        "        return i % (multiple * n) == modulo*multiple\n",
        "    return limit\n"
      ],
      "execution_count": 5,
      "outputs": []
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "outputId": "54c54d3e-5e11-4d7e-c888-19218a52cdea"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text size is 2.83MB with 283.09KB set aside for validation. There will be 493 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "# display some stats on the data\n",
    "epoch_size = len(codetext) // (BATCHSIZE * SEQLEN)\n",
    "txt.print_data_stats(len(codetext), len(valitext), epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTbnELiONMJl",
        "outputId": "2cba01e0-b427-4401-c564-cecd9bd67384"
      },
      "source": [
        "# load data, either shakespeare, or the Python source of Tensorflow itself\n",
        "shakedir = \"txts/*.txt\"\n",
        "#shakedir = \"../tensorflow/**/*.py\"\n",
        "codetext, valitext, bookranges = txt.read_data_files(shakedir, validation=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading file txts/matt_new.txt\n",
            "Loading file txts/heb_new.txt\n",
            "Loading file txts/mark01_new.txt\n",
            "Loading file txts/john_new.txt\n",
            "Loading file txts/tit_phl_new.txt\n",
            "Loading file txts/gal_eph_new.txt\n",
            "Loading file txts/jam_jud_new.txt\n",
            "Loading file txts/luke_8_john_new.txt\n",
            "Loading file txts/thes_tim_new.txt\n",
            "Loading file txts/acts_new.txt\n",
            "Loading file txts/phil_col_new.txt\n",
            "Loading file txts/jud_rev_new.txt\n",
            "Loading file txts/matt02_new.txt\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "id": "XfHf56rYNMJr",
    "outputId": "394de08f-72d9-4796-d394-f12f58340af0"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (i2h): GRUCell(98, 512)\n",
       "  (i2o): Linear(in_features=610, out_features=98, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
=======
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnQShJG7NMJq",
        "outputId": "77bbb717-10fc-4abf-a2a0-fa694ccfd307"
      },
      "source": [
        "# display some stats on the data\n",
        "epoch_size = len(codetext) // (BATCHSIZE * SEQLEN)\n",
        "txt.print_data_stats(len(codetext), len(valitext), epoch_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training text size is 2.89MB with 215.29KB set aside for validation. There will be 505 batches per epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHf56rYNMJr",
        "outputId": "62302714-e938-4237-e01b-1a8e422b2b6a"
      },
      "source": [
        "# model\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.GRUCell(input_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(input,hidden)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(BATCHSIZE, self.hidden_size, device=device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('using gpu..' if torch.cuda.is_available() else 'using cpu..')\n",
        "rnn = RNN(ALPHASIZE, INTERNALSIZE, ALPHASIZE)\n",
        "rnn.to(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using gpu..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (i2h): GRUCell(98, 512)\n",
              "  (i2o): Linear(in_features=610, out_features=98, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.GRUCell(input_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input,hidden)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(BATCHSIZE, self.hidden_size, device=device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using gpu..' if torch.cuda.is_available() else 'using cpu..')\n",
    "rnn = RNN(ALPHASIZE, INTERNALSIZE, ALPHASIZE)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "P79-gHUTNMJr",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# loss fn\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#from ok_seq2seq import EncoderRNN \\\n",
    "#                        ,DecoderRNN \\\n",
    "#                        ,AttnDecoderRNN \\\n",
    "#                        ,evaluateRandomly \\\n",
    "#                        ,teacher_forcing_ratio \n",
    "\n",
    "#torch.nn.GRUCell(input_size: int, hidden_size: int, bias: bool = True)\n",
    "# Parameters\n",
    "# input_size – The number of expected features in the input x\n",
    "\n",
    "# hidden_size – The number of features in the hidden state h\n",
    "\n",
    "# bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "\n",
    "# Inputs: input, hidden\n",
    "# input of shape (batch, input_size): tensor containing input features\n",
    "\n",
    "# hidden of shape (batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided.\n",
    "\n",
    "# Outputs: h’\n",
    "# h’ of shape (batch, hidden_size): tensor containing the next hidden state for each element in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5FKhhWDNMJs"
   },
   "outputs": [],
   "source": [
    "# training fn\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    lint = []\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        lint.append(output)\n",
    "    input = torch.stack(lint).transpose(0,1).transpose(1,2)\n",
    "#     print(f'is={input.size()}, cs={category_tensor.size()}')\n",
    "#     print(f'is[1:]={input.size()[1:]}, cs[1:]={category_tensor.size()[1:]}')\n",
    "#     print(f'is[2:]={input.size()[2:]}, cs[2:]={category_tensor.size()[2:]}')\n",
    "    loss = criterion(input, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return torch.stack(lint).transpose(0,1), loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM4NTqI5NMJu"
   },
   "outputs": [],
   "source": [
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def one_hot(chcode):\n",
    "    tensor = torch.zeros(1, ALPHASIZE)\n",
    "    tensor[0][chcode] = 1\n",
    "    return tensor\n",
    "\n",
    "def mb2t(rows):\n",
    "    rows=rows.transpose()\n",
    "    tensor = torch.zeros(rows.shape[0], rows.shape[1], ALPHASIZE, device=device)\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, letter_code in enumerate(row):\n",
    "            tensor[i][j][letter_code] = 1\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ngo8CDGYNMJv"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def lin2txt(lt):\n",
    "    return ''.join([chr(txt.convert_to_alphabet(c))  if c != 0 else '' for c in lt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XSdtXUCNMJv",
    "outputId": "9ba61bfa-036d-43fa-bda9-95d83391d156"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 of  60 (0m 2s) 4.5849 jems jems be barabo firifirima / Ws(S,W,(S,(,((,,,([,Wm,(c1,((, ✗ ems jems be barabo firifirimad\n",
      "epoch 0 of  60 (0m 2s) 4.5849 o yekarifi ma o ye bereni ari  / Ws(S,W,(S,(,((,,,([,Wm,(c1,((, ✗  yekarifi ma o ye bereni ari s\n",
      "epoch 0 of  60 (1m 33s) 4.3815 e miebo bara nwose ori okime.  /                                ✗  miebo bara nwose ori okime. a\n",
      "epoch 0 of  60 (1m 33s) 4.3815 egoye inibo bietonye inibo gba /                                ✗ goye inibo bietonye inibo gbar\n",
      "epoch 1 of  60 (3m 4s) 4.1073  sime i piri eke.    ominea bi /                                ✗ sime i piri eke.    ominea bie\n",
      "epoch 1 of  60 (3m 4s) 4.1073 mi konka siki. anierechi ini d /                                ✗ i konka siki. anierechi ini du\n",
      "epoch 1 of  60 (4m 36s) 3.6348    se fiafiadiri mi jin anga b /                                ✗   se fiafiadiri mi jin anga bu\n",
      "epoch 1 of  60 (4m 36s) 3.6348 am nwo be ye mi.  min bara mi  /                                ✗ m nwo be ye mi.  min bara mi b\n",
      "epoch 2 of  60 (6m 7s) 3.1587 oni  piriye-e ani inia ojumini /                                ✗ ni  piriye-e ani inia ojumini \n",
      "epoch 2 of  60 (6m 7s) 3.1587 amuno be ene mi koruari siki o /                                ✗ muno be ene mi koruari siki o \n",
      "epoch 2 of  60 (7m 38s) 3.0083  se ominea bie korombia, omine /                                ✗ se ominea bie korombia, omine \n",
      "epoch 2 of  60 (7m 38s) 3.0083  kokomaye mi bie iruoye ofori- /                                ✗ kokomaye mi bie iruoye ofori-e\n",
      "epoch 3 of  60 (9m 9s) 2.9195  ani wa sime kuroari ye-e iwo  /                                ✗ ani wa sime kuroari ye-e iwo s\n",
      "epoch 3 of  60 (9m 9s) 2.9195 iatibi tamuno be tatari wa bel /                                ✗ atibi tamuno be tatari wa bele\n",
      "epoch 3 of  60 (10m 40s) 2.8556 o goyegoye piki dabo be sikime /                                ✗  goyegoye piki dabo be sikime \n",
      "epoch 3 of  60 (10m 40s) 2.8556  kraist be bereni minapu ma bo /                                ✗ kraist be bereni minapu ma bo \n",
      "epoch 4 of  60 (12m 12s) 2.8327 ase ori orisa bo be o nwo bele /                                ✗ se ori orisa bo be o nwo belem\n",
      "epoch 4 of  60 (12m 12s) 2.8327  minapu tamuno be min tomoniki /                                ✗ minapu tamuno be min tomonikir\n",
      "epoch 4 of  60 (13m 43s) 2.8042 nwo da. ibiye mie bo goyegoye  /                                ✗ wo da. ibiye mie bo goyegoye s\n",
      "epoch 4 of  60 (13m 43s) 2.8042 e, boka siki nwose sime se was /                                ✗ , boka siki nwose sime se wasa\n",
      "epoch 5 of  60 (15m 14s) 2.8336  osike tapu o punuma se o fono /                                ✗ osike tapu o punuma se o fono \n",
      "epoch 5 of  60 (15m 14s) 2.8336 yebusoka papa dumo mi bie o pe /                                ✗ ebusoka papa dumo mi bie o pek\n",
      "epoch 5 of  60 (16m 46s) 2.7917  bara mi kurake.  aniokuma, nw / b                              ✗ bara mi kurake.  aniokuma, nwo\n",
      "epoch 5 of  60 (16m 46s) 2.7917 ma o nwo mie fiafiama, miese i / b                              ✗ a o nwo mie fiafiama, miese in\n",
      "epoch 6 of  60 (18m 17s) 2.7558 u sime bo be. tomonikiri m ma  /                                ✗  sime bo be. tomonikiri m ma t\n",
      "epoch 6 of  60 (18m 17s) 2.7558 iruo ye dieapu ma . kraist be  /                                ✗ ruo ye dieapu ma . kraist be k\n",
      "epoch 6 of  60 (19m 49s) 2.7680 , ibi ye mie gose torusiori mi /                                ✗  ibi ye mie gose torusiori mi \n",
      "epoch 6 of  60 (19m 49s) 2.7680 iki ngisi, tonbu sime ikiankor /                                ✗ ki ngisi, tonbu sime ikiankoro\n",
      "epoch 7 of  60 (21m 20s) 2.7667 jizos kraist be karakara mi bu /                                ✗ izos kraist be karakara mi bu \n",
      "epoch 7 of  60 (21m 20s) 2.7667 omine o nemime. a diri gien om /                                ✗ mine o nemime. a diri gien omi\n",
      "epoch 7 of  60 (22m 52s) 2.7079 e, ojumini mi dikipukosolia ye /                                ✗ , ojumini mi dikipukosolia ye \n",
      "epoch 7 of  60 (22m 52s) 2.7079 be wa no belemame now se yeke, /                                ✗ e wa no belemame now se yeke, \n",
      "epoch 8 of  60 (24m 23s) 2.7286 aki siki ngisni sime bo be omi /                                ✗ ki siki ngisni sime bo be omin\n",
      "epoch 8 of  60 (24m 23s) 2.7286  mi i piki oju bu so oko kuro. /                                ✗ mi i piki oju bu so oko kuro. \n",
      "epoch 8 of  60 (25m 55s) 2.7040 jinbojinbo belemame nwo bebe,  /                         i      ✗ inbojinbo belemame nwo bebe, t\n",
      "epoch 8 of  60 (25m 55s) 2.7040 omaka bo beke, okuma ani se mi /                         i      ✗ maka bo beke, okuma ani se mie\n",
      "epoch 9 of  60 (27m 26s) 2.6898  oforie bo naa na iya awo ma k / b          i   i          i    ✗ oforie bo naa na iya awo ma ko\n",
      "epoch 9 of  60 (27m 26s) 2.6898 na tuburu, anisiki ori o diki  / b          i   i          i    ✗ a tuburu, anisiki ori o diki m\n",
      "epoch 9 of  60 (28m 57s) 2.6891 obori se obu chinabe  fiafia p /                      i      i  ✗ bori se obu chinabe  fiafia pi\n",
      "epoch 9 of  60 (28m 57s) 2.6891 ni weri bobia bara na nwo doki /                      i      i  ✗ i weri bobia bara na nwo dokim\n",
      "epoch 10 of  60 (30m 27s) 2.6720 ku owu omine ominea deri mi pi /         i     i       i  i     ✗ u owu omine ominea deri mi pik\n",
      "epoch 10 of  60 (30m 27s) 2.6720 jinbo belema, se o piki ibiye  /         i     i       i  i     ✗ inbo belema, se o piki ibiye m\n",
      "epoch 10 of  60 (31m 58s) 2.6723 maa ikiankoroapu ma dieme na i / a          i     i     i  i i  ✗ aa ikiankoroapu ma dieme na in\n",
      "epoch 10 of  60 (31m 58s) 2.6723 ma aniabie chie   babilon mi b / a          i     i     i  i i  ✗ a aniabie chie   babilon mi bi\n",
      "epoch 11 of  60 (33m 29s) 2.6741 ai tamuno be bereni o piriye m /      i    i  i i   i ii i   ii ✗ i tamuno be bereni o piriye mi\n",
      "epoch 11 of  60 (33m 29s) 2.6741 amuno be ani gbuntein kanakana /      i    i  i i   i ii i   ii ✗ muno be ani gbuntein kanakana \n",
      "epoch 11 of  60 (34m 59s) 2.6610 i  ye deinma sime omine kraist /   i      ii    i   i i  ii     ✗   ye deinma sime omine kraist \n",
      "epoch 11 of  60 (34m 59s) 2.6610  wa se ibiokuma nimibia yee na /   i      ii    i   i i  ii     ✗ wa se ibiokuma nimibia yee na \n",
      "epoch 12 of  60 (36m 30s) 2.6651 apu ma pirime  ini bu nyana be /     i    i i  i i ii ii  i ii  ✗ pu ma pirime  ini bu nyana ber\n",
      "epoch 12 of  60 (36m 30s) 2.6651 yana teme be ani kraist be na  /     i    i i  i i ii ii  i ii  ✗ ana teme be ani kraist be na t\n",
      "epoch 12 of  60 (38m 1s) 2.6327  iwo yeke, okuma oloko mi anie / b           i i     i ii i i   ✗ iwo yeke, okuma oloko mi anie,\n",
      "epoch 12 of  60 (38m 1s) 2.6327  soni se o piri ma  aniatibi d / b           i i     i ii i i   ✗ soni se o piri ma  aniatibi de\n",
      "epoch 13 of  60 (39m 31s) 2.6316 atibi o bie sime tamuno be kur /        ii  ii i i  i i ii ii i ✗ tibi o bie sime tamuno be kuro\n",
      "epoch 13 of  60 (39m 31s) 2.6316 zos be na kobirima sime siki i /        ii  ii i i  i i ii ii i ✗ os be na kobirima sime siki in\n",
      "epoch 13 of  60 (41m 2s) 2.6280 omine na iria se toru se omine /  i    i i i  ii i  i i  i i i  ✗ mine na iria se toru se omine \n",
      "epoch 13 of  60 (41m 2s) 2.6280 muno be fi bu be gbori jizos b /  i    i i i  ii i  i i  i i i  ✗ uno be fi bu be gbori jizos be\n",
      "epoch 14 of  60 (42m 32s) 2.6088 ime o pirike omine ari miebia  /  i   ii i i i i i i i ii  i  i ✗ me o pirike omine ari miebia s\n",
      "epoch 14 of  60 (42m 32s) 2.6088 ka se be ikelibo be bu mimgba  /  i   ii i i i i i i i ii  i  i ✗ a se be ikelibo be bu mimgba n\n",
      "epoch 14 of  60 (44m 3s) 2.6042  mi o mioku ori, piki naa ye m / bi   ii  i i i  ii i ii  i  ii ✗ mi o mioku ori, piki naa ye mi\n",
      "epoch 14 of  60 (44m 3s) 2.6042 gasiki koruabe okuma wa bko ma / bi   ii  i i i  ii i ii  i  ii ✗ asiki koruabe okuma wa bko ma \n",
      "epoch 15 of  60 (45m 33s) 2.6011  ominea toroko gwosa bara bu c / b i i  i  i i i     ii i ii i  ✗ ominea toroko gwosa bara bu ch\n",
      "epoch 15 of  60 (45m 33s) 2.6011 un mi bu josef be mie se oria  / b i i  i  i i i     ii i ii i  ✗ n mi bu josef be mie se oria m\n",
      "epoch 15 of  60 (47m 5s) 2.5988 bori owubo so bome now sei ini / e i i   i ii ii i ii  ii  i i  ✗ ori owubo so bome now sei ini \n",
      "epoch 15 of  60 (47m 5s) 2.5988 sameria mi bie. ori obu se opu / e i i   i ii ii i ii  ii  i i  ✗ ameria mi bie. ori obu se opub\n",
      "epoch 16 of  60 (48m 35s) 2.5841  kienbipi laye sonofa kini ine / bi  i    ii   ii i   bi i i i  ✗ kienbipi laye sonofa kini inei\n",
      "epoch 16 of  60 (48m 35s) 2.5841  sol be babia oku now baime ok / bi  i    ii   ii i   bi i i i  ✗ sol be babia oku now baime oku\n",
      "epoch 16 of  60 (50m 6s) 2.5827 u irimame ani miese ini toru s /  b i i i i i ii    i i ii i bi ✗  irimame ani miese ini toru se\n",
      "epoch 16 of  60 (50m 6s) 2.5827 diki balafa se karakaraye mie  /  b i i i i i ii    i i ii i bi ✗ iki balafa se karakaraye mie b\n",
      "epoch 17 of  60 (51m 37s) 2.5755 ma mi be onu mi bu finji sime  / a bi ii i i bi ii bi i  ii i b ✗ a mi be onu mi bu finji sime n\n",
      "epoch 17 of  60 (51m 37s) 2.5755 pita be nungo da book mi nwo g / a bi ii i i bi ii bi i  ii i b ✗ ita be nungo da book mi nwo gb\n",
      "epoch 17 of  60 (53m 8s) 2.5600 mabe, tomoni mamgba nyanabo be / a    i  i i ii i i bi  i i bi  ✗ abe, tomoni mamgba nyanabo be.\n",
      "epoch 17 of  60 (53m 8s) 2.5600 obi, miese ikiankoroapu ma duk / a    i  i i ii i i bi  i i bi  ✗ bi, miese ikiankoroapu ma duko\n",
      "epoch 18 of  60 (54m 39s) 2.5694 na pita be o nungo chie sime w / i bi   ii i ii i  b    bi i b  ✗ a pita be o nungo chie sime wa\n",
      "epoch 18 of  60 (54m 39s) 2.5694 bugerere bu duaboroma nyana ok / i bi   ii i ii i  b    bi i b  ✗ ugerere bu duaboroma nyana oku\n",
      "epoch 18 of  60 (56m 11s) 2.5528  nwo duko belema o piri so pol / bi  ii i bi   i b bi i ii bi   ✗ nwo duko belema o piri so pol \n",
      "epoch 18 of  60 (56m 11s) 2.5528 bini ma pol be na sailas be na / bi  ii i bi   i b bi i ii bi   ✗ ini ma pol be na sailas be na \n",
      "epoch 19 of  60 (57m 41s) 2.5373 buamaye ma na nwo naa siki ini / e  i   ii bi bi  bi  bi i b i  ✗ uamaye ma na nwo naa siki ini \n",
      "epoch 19 of  60 (57m 41s) 2.5373 moni ma o nemi ka sikima o nwo / e  i   ii bi bi  bi  bi i b i  ✗ oni ma o nemi ka sikima o nwo \n",
      "epoch 19 of  60 (59m 13s) 2.5525  bu ikoliwari dikidikibo be in / bi i i     i bi i   i i bi b i ✗ bu ikoliwari dikidikibo be ini\n",
      "epoch 19 of  60 (59m 13s) 2.5525 unbia.  mun ani la so siki, o / bi i i     i bi i   i i bi b i ✗ nbia.  mun ani la so siki, o \n",
      "epoch 20 of  60 (60m 44s) 2.5690 erisam, ani o selepakuma bosa  /  i   i b i i bi   i i a be   b ✗ risam, ani o selepakuma bosa b\n",
      "epoch 20 of  60 (60m 44s) 2.5690 tibi gose.  se moku ari o se t /  i   i b i i bi   i i a be   b ✗ ibi gose.  se moku ari o se ta\n",
      "epoch 20 of  60 (62m 16s) 2.5292 ki mi bu mi opu bufuka efisos  / i bi ii bi b i bi   i b i i ib ✗ i mi bu mi opu bufuka efisos b\n",
      "epoch 20 of  60 (62m 16s) 2.5292 e ini se ikoli seinme. gele ag / i bi ii bi b i bi   i b i i ib ✗  ini se ikoli seinme. gele agb\n",
      "epoch 21 of  60 (63m 48s) 2.5506 ikanika goli, anikanika buchua /  i i i ii    b i i i i bi      ✗ kanika goli, anikanika buchuay\n",
      "epoch 21 of  60 (63m 48s) 2.5506  piri anisiki owuniberetonbo b /  i i i ii    b i i i i bi      ✗ piri anisiki owuniberetonbo be\n",
      "epoch 21 of  60 (65m 19s) 2.5434 ikasi se ini kun bo bufuka se  /  i   ii i i bi ibi bi   i bi b ✗ kasi se ini kun bo bufuka se i\n",
      "epoch 21 of  60 (65m 19s) 2.5434 i pirime na romapu ma ini tomo /  i   ii i i bi ibi bi   i bi b ✗  pirime na romapu ma ini tomon\n",
      "epoch 22 of  60 (66m 50s) 2.5714 ku-e, se ari iya owuni ma na m / i    bi b i b i b   i bi bi bi ✗ u-e, se ari iya owuni ma na mu\n",
      "epoch 22 of  60 (66m 50s) 2.5714 ima borome, se opu bufuka bub  / i    bi b i b i b   i bi bi bi ✗ ma borome, se opu bufuka bub o\n",
      "epoch 22 of  60 (68m 22s) 2.5392 numaye ma bie. ini minyo bo si / i i   bi bi   b i bi i  bi bi  ✗ umaye ma bie. ini minyo bo sik\n",
      "epoch 22 of  60 (68m 22s) 2.5392 in boro siki pol be juapu ma b / i i   bi bi   b i bi i  bi bi  ✗ n boro siki pol be juapu ma be\n",
      "epoch 23 of  60 (69m 53s) 2.5245 sebubama ene miemieye mi boros /   e i a b i bi  i    bi bi i   ✗ ebubama ene miemieye mi borosa\n",
      "epoch 23 of  60 (69m 53s) 2.5245 i basabas nwose chin bo be, in /   e i a b i bi  i    bi bi i   ✗  basabas nwose chin bo be, ini\n",
      "epoch 23 of  60 (71m 24s) 2.5001 juadapu ma bara wa daoki amami /      i bi bi i bi bi  i b i a  ✗ uadapu ma bara wa daoki amamie\n",
      "epoch 23 of  60 (71m 24s) 2.5001  oku nwo ori siki, ori ini tek /      i bi bi i bi bi  i b i a  ✗ oku nwo ori siki, ori ini teke\n",
      "epoch 24 of  60 (72m 55s) 2.5005 mi nwo okibia bo, okunwengibo  / a bi  b i i  bi  b i i  i  i b ✗ i nwo okibia bo, okunwengibo b\n",
      "epoch 24 of  60 (72m 55s) 2.5005 jizos be na tuburubia erechi,  / a bi  b i i  bi  b i i  i  i b ✗ izos be na tuburubia erechi, i\n",
      "epoch 24 of  60 (74m 26s) 2.5257 gisi oforie, okuma a nyana ye  /   i i i i   b i a b bi  i be b ✗ isi oforie, okuma a nyana ye a\n",
      "epoch 24 of  60 (74m 26s) 2.5257 i mi bie na tomonia wari ma bi /   i i i i   b i a b bi  i be b ✗  mi bie na tomonia wari ma bie\n",
      "epoch 25 of  60 (75m 57s) 2.4944 u elekima chua, se bereni mine /  b i i i bii   bi be i i bi i  ✗  elekima chua, se bereni mine \n",
      "epoch 25 of  60 (75m 57s) 2.4944 ni oki pakumabo yee, bugbiripu /  b i i i bii   bi be i i bi i  ✗ i oki pakumabo yee, bugbiripum\n",
      "epoch 25 of  60 (77m 28s) 2.5089 orome, grik okwein konari juap /  i i  bii ib i   ibi i i bi  i ✗ rome, grik okwein konari juapu\n",
      "epoch 25 of  60 (77m 28s) 2.5089 ku, jinbo ani duko belema i pi /  i i  bii ib i   ibi i i bi  i ✗ u, jinbo ani duko belema i pir\n",
      "epoch 26 of  60 (78m 58s) 2.5081  se o firimbia, ani o nwo i fi / bi b ii i ie   b i b bi  b bi  ✗ se o firimbia, ani o nwo i fir\n",
      "epoch 26 of  60 (78m 58s) 2.5081 nilios be na gbori owubo sizar / bi b ii i ie   b i b bi  b bi  ✗ ilios be na gbori owubo sizari\n",
      "epoch 26 of  60 (80m 29s) 2.4966 huka ma kirisinari siki gboinm /   i bi bi i i i i bi i bie  ia ✗ uka ma kirisinari siki gboinma\n",
      "epoch 26 of  60 (80m 29s) 2.4966 hiesime enjelb be nwo ori oku  /   i bi bi i i i i bi i bie  ia ✗ iesime enjelb be nwo ori oku n\n",
      "epoch 27 of  60 (82m 1s) 2.4949 muno piripirime. o bakama bara / a i bi i i i i  b be i a be i  ✗ uno piripirime. o bakama barac\n",
      "epoch 27 of  60 (82m 1s) 2.4949 u ani o gamunuma majik bo be d / a i bi i i i i  b be i a be i  ✗  ani o gamunuma majik bo be di\n",
      "epoch 27 of  60 (83m 32s) 2.4788  okwein siki, fiafia teme be k / b i   ibi i  bi  i  bi i be bi ✗ okwein siki, fiafia teme be ko\n",
      "epoch 27 of  60 (83m 32s) 2.4788  tomoni toru nwose koro wa dam / b i   ibi i  bi  i  bi i be bi ✗ tomoni toru nwose koro wa dama\n",
      "epoch 28 of  60 (85m 3s) 2.4673 ku nyanabo be bara mi korobo i / i bi  i e be be i bi bi i e b  ✗ u nyanabo be bara mi korobo iy\n",
      "epoch 28 of  60 (85m 3s) 2.4673 o ini se firima apu ma damamum / i bi  i e be be i bi bi i e b  ✗  ini se firima apu ma damamume\n",
      "epoch 28 of  60 (86m 35s) 2.4826  na ngwengwe na nwose ama mi b / bi bii  i   bi bi  i b a bi be ✗ na ngwengwe na nwose ama mi be\n",
      "epoch 28 of  60 (86m 35s) 2.4826  oforifori bara se ateliogbo n / bi bii  i   bi bi  i b a bi be ✗ oforifori bara se ateliogbo nw\n",
      "epoch 29 of  60 (88m 6s) 2.4785 iki ani dukome. pol be na bana /  i b i bi i a  bi  be bi be i  ✗ ki ani dukome. pol be na banab\n",
      "epoch 29 of  60 (88m 6s) 2.4785 i mi bie so se juapu ma na jua /  i b i bi i a  bi  be bi be i  ✗  mi bie so se juapu ma na juap\n",
      "epoch 29 of  60 (89m 37s) 2.4647 ma piribia oku. okuma ini ini  / a bi i i  b i  b i a b i b i b ✗ a piribia oku. okuma ini ini d\n",
      "epoch 29 of  60 (89m 37s) 2.4647 ri irima tolu boro se tomoni m / a bi i i  b i  b i a b i b i b ✗ i irima tolu boro se tomoni ma\n",
      "epoch 30 of  60 (91m 8s) 2.4637 iki o damabobia. ani ori efiso /  i b ii a e e   b i b i b i i  ✗ ki o damabobia. ani ori efisos\n",
      "epoch 30 of  60 (91m 8s) 2.4637 i nwo oribia, minea bie juapu  /  i b ii a e e   b i b i b i i  ✗  nwo oribia, minea bie juapu b\n",
      "epoch 30 of  60 (92m 39s) 2.4695 obia. biria bie bo pairos ya,  /  e   bi i  be  be bi  i ibe  b ✗ bia. biria bie bo pairos ya, s\n",
      "epoch 30 of  60 (92m 39s) 2.4695 kuma o nwo doki nemi, ani anib /  e   bi i  be  be bi  i ibe  b ✗ uma o nwo doki nemi, ani anibe\n",
      "epoch 31 of  60 (94m 10s) 2.4686 uapu ma dieabe na ini mozizi o /   i bi bi   e bi b i bi     b  ✗ apu ma dieabe na ini mozizi ol\n",
      "epoch 31 of  60 (94m 10s) 2.4686 oni na toroko anga okue. a to /   i bi bi   e bi b i bi     b  ✗ ni na toroko anga okue. a ton\n",
      "epoch 31 of  60 (95m 41s) 2.4618 ukukuma berechiri mi diki se n /  i i a be i    i bi bi i bi bi ✗ kukuma berechiri mi diki se nw\n",
      "epoch 31 of  60 (95m 41s) 2.4618 oku now dukome okunwengiapu mi /  i i a be i    i bi bi i bi bi ✗ ku now dukome okunwengiapu mie\n",
      "epoch 32 of  60 (97m 12s) 2.4576 ee, a bumiefiafiafiama miemiey /    b be a     i  i  a bi  a  e ✗ e, a bumiefiafiafiama miemieye\n",
      "epoch 32 of  60 (97m 12s) 2.4576  kala aru mi kpo diki ma peles /    b be a     i  i  a bi  a  e ✗ kala aru mi kpo diki ma pelesi\n",
      "epoch 32 of  60 (98m 42s) 2.4547 u, a nwo orime, sobie korobo b /   b bi  b i i  bi e  bi i e be ✗ , a nwo orime, sobie korobo bi\n",
      "epoch 32 of  60 (98m 42s) 2.4547  be oria tamuno firinwengi mi  /   b bi  b i i  bi e  bi i e be ✗ be oria tamuno firinwengi mi  \n",
      "epoch 33 of  60 (100m 13s) 2.4379 efi miese omine inyo nyanabia  /    bi  e b i i b i  bie i e  b ✗ fi miese omine inyo nyanabia o\n",
      "epoch 33 of  60 (100m 13s) 2.4379 a siki mamgba nyanabo be nwo o /    bi  e b i i b i  bie i e  b ✗  siki mamgba nyanabo be nwo or\n",
      "epoch 33 of  60 (101m 44s) 2.4311 e ikoliboe jerusalem bie, siza /  b i i e  bi i     abe   bi i  ✗  ikoliboe jerusalem bie, sizar\n",
      "epoch 33 of  60 (101m 44s) 2.4311 bamieapu ma na, oputekewari mi /  b i i e  bi i     abe   bi i  ✗ amieapu ma na, oputekewari mi \n",
      "epoch 34 of  60 (103m 15s) 2.4215 be soni, torusedikibiaye a nwo / e bi i  bi i     i e  e b bi   ✗ e soni, torusedikibiaye a nwo \n",
      "epoch 34 of  60 (103m 15s) 2.4215 ma na, gbotubara okunwengiapu  / e bi i  bi i     i e  e b bi   ✗ a na, gbotubara okunwengiapu m\n",
      "epoch 34 of  60 (104m 46s) 2.4326 e na fiapu fibusise dumobia  a /  bi bi  i bi e   i bi a e  bb  ✗  na fiapu fibusise dumobia  an\n",
      "epoch 34 of  60 (104m 46s) 2.4326 se mianga i tekebia  anisiki t /  bi bi  i bi e   i bi a e  bb  ✗ e mianga i tekebia  anisiki ta\n",
      "epoch 35 of  60 (106m 17s) 2.4206 oliwari onobu book ma finji ok /      i b i e be  ibi bi i  b i ✗ liwari onobu book ma finji oku\n",
      "epoch 35 of  60 (106m 17s) 2.4206 ba galagala judia na sameria n /      i b i e be  ibi bi i  b i ✗ a galagala judia na sameria na\n",
      "epoch 36 of  60 (107m 48s) 2.4381 se jekob be minea oyima dapu f / e bi i ebe bi i  b e i bi i bi ✗ e jekob be minea oyima dapu fi\n",
      "epoch 36 of  60 (107m 48s) 2.4381 okoro korome se ori ineda piki / e bi i ebe bi i  b e i bi i bi ✗ koro korome se ori ineda piki \n",
      "epoch 36 of  60 (109m 19s) 2.4121 se bereniapu ma fonofono pakum / e be i i  i bi bi i i i bi i a ✗ e bereniapu ma fonofono pakuma\n",
      "epoch 36 of  60 (109m 19s) 2.4121 i iya wari bie sime teke simem / e be i i  i bi bi i i i bi i a ✗  iya wari bie sime teke simeme\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 250\n",
    "plot_every = 100\n",
    "\n",
    "vloss = []\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "iter=0\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for x, y_, epoch in txt.rnn_minibatch_sequencer(codetext, BATCHSIZE, SEQLEN, nb_epochs=nb_epoch):\n",
    "    #category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    category =  [lin2txt(l) for l in y_]\n",
    "    lines = [lin2txt(l) for l in x]\n",
    "    category_tensor=mb2t(y_)\n",
    "    line_tensor=mb2t(x)\n",
    "    output, loss = train(torch.tensor(y_, device=device, dtype=torch.long), line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess = [lin2txt([ch.argmax(dim=0) for ch in line]) for line in output]\n",
    "        for i in range(2):\n",
    "            correct = '✓' if guess[i] == category[i] else '✗ %s' % category[i] \n",
    "            print('epoch %d of  %d (%s) %.4f %s / %s %s' % (epoch, nb_epoch, timeSince(start), loss, lines[i], guess[0], correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0 and len(valitext) > 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "        vali_x, vali_y, _ = next(txt.rnn_minibatch_sequencer(valitext, BATCHSIZE, VALI_SEQLEN, 1))  # all data in 1 batch\n",
    "        line_tensor = mb2t(vali_x)\n",
    "        output, loss = train(torch.tensor(vali_y, device=device, dtype=torch.long), line_tensor)\n",
    "        vloss.append(loss)\n",
    "        with open('vloss.json', 'w') as f:\n",
    "          json.dump(vloss,f)\n",
    "    iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
=======
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "P79-gHUTNMJr"
      },
      "source": [
        "# loss fn\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#from ok_seq2seq import EncoderRNN \\\n",
        "#                        ,DecoderRNN \\\n",
        "#                        ,AttnDecoderRNN \\\n",
        "#                        ,evaluateRandomly \\\n",
        "#                        ,teacher_forcing_ratio \n",
        "\n",
        "#torch.nn.GRUCell(input_size: int, hidden_size: int, bias: bool = True)\n",
        "# Parameters\n",
        "# input_size – The number of expected features in the input x\n",
        "\n",
        "# hidden_size – The number of features in the hidden state h\n",
        "\n",
        "# bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
        "\n",
        "# Inputs: input, hidden\n",
        "# input of shape (batch, input_size): tensor containing input features\n",
        "\n",
        "# hidden of shape (batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided.\n",
        "\n",
        "# Outputs: h’\n",
        "# h’ of shape (batch, hidden_size): tensor containing the next hidden state for each element in the batch"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5FKhhWDNMJs"
      },
      "source": [
        "# training fn\n",
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "    \n",
        "    lint = []\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "        lint.append(output)\n",
        "    input = torch.stack(lint).transpose(0,1).transpose(1,2)\n",
        "#     print(f'is={input.size()}, cs={category_tensor.size()}')\n",
        "#     print(f'is[1:]={input.size()[1:]}, cs[1:]={category_tensor.size()[1:]}')\n",
        "#     print(f'is[2:]={input.size()[2:]}, cs[2:]={category_tensor.size()[2:]}')\n",
        "    loss = criterion(input, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return torch.stack(lint).transpose(0,1), loss.item()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM4NTqI5NMJu"
      },
      "source": [
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def one_hot(chcode):\n",
        "    tensor = torch.zeros(1, ALPHASIZE)\n",
        "    tensor[0][chcode] = 1\n",
        "    return tensor\n",
        "\n",
        "def mb2t(rows):\n",
        "    rows=rows.transpose()\n",
        "    tensor = torch.zeros(rows.shape[0], rows.shape[1], ALPHASIZE, device=device)\n",
        "    for i, row in enumerate(rows):\n",
        "        for j, letter_code in enumerate(row):\n",
        "            tensor[i][j][letter_code] = 1\n",
        "    return tensor\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngo8CDGYNMJv"
      },
      "source": [
        "# \n",
        "def lin2txt(lt):\n",
        "    return ''.join([chr(txt.convert_to_alphabet(c))  if c != 0 else '' for c in lt])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XSdtXUCNMJv",
        "outputId": "9b22f8a9-4d40-4a86-d392-94f1c56ee2d5"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 250\n",
        "plot_every = 100\n",
        "\n",
        "vloss = []\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "iter=0\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for x, y_, epoch in txt.rnn_minibatch_sequencer(codetext, BATCHSIZE, SEQLEN, nb_epochs=nb_epoch):\n",
        "    #category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    category =  [lin2txt(l) for l in y_]\n",
        "    lines = [lin2txt(l) for l in x]\n",
        "    category_tensor=mb2t(y_)\n",
        "    line_tensor=mb2t(x)\n",
        "    output, loss = train(torch.tensor(y_, device=device, dtype=torch.long), line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print iter number, loss, name and guess\n",
        "    if iter % print_every == 0:\n",
        "        guess = [lin2txt([ch.argmax(dim=0) for ch in line]) for line in output]\n",
        "        for i in range(2):\n",
        "            elapsed_time = time.time() - start\n",
        "            tss = str(datetime.timedelta(seconds=elapsed_time)) # time since start string\n",
        "            if epoch > 0:\n",
        "                speed = epoch/elapsed_time\n",
        "                eta = (nb_epoch-epoch)/speed\n",
        "                sspeed = speed*60*60\n",
        "                seta = str(datetime.timedelta(seconds=int(eta)))\n",
        "                stats = f'average epoch rate per hr = %3.2f,  eta = {seta}'%(sspeed)\n",
        "            else:\n",
        "                stats ='initialising stats..'\n",
        "            correct = '✓' if guess[i] == category[i] else '✗ %s' % stats \n",
        "            print('epoch %d of %d (%s) %.4f %s / %s %s' % (epoch+1, nb_epoch, tss, loss, lines[i], guess[0], correct))\n",
        "        PATH = './slgru_epoch120.model'\n",
        "        torch.save(rnn.state_dict(), PATH)\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0 and len(valitext) > 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "        vali_x, vali_y, _ = next(txt.rnn_minibatch_sequencer(valitext, BATCHSIZE, VALI_SEQLEN, 1))  # all data in 1 batch\n",
        "        line_tensor = mb2t(vali_x)\n",
        "        output, loss = train(torch.tensor(vali_y, device=device, dtype=torch.long), line_tensor)\n",
        "        vloss.append(loss)\n",
        "        with open('vloss.json', 'w') as f:\n",
        "          json.dump(str({\"vloss\":vloss,\"tloss\":all_losses}),f)\n",
        "    iter += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 of 125 (0:00:02.304477) 4.5810 matio matio be ibiokwein mi gi / ],\\bB\\B,\\bB\\!Bbb!bBB\tB\t\t\\B\t\\[b ✗ calculating stats..\n",
            "epoch 0 of 125 (0:00:02.304628) 4.5810  berekonwari muabe bebe, ori n / ],\\bB\\B,\\bB\\!Bbb!bBB\tB\t\t\\B\t\\[b ✗ calculating stats..\n",
            "epoch 0 of 125 (0:01:41.103200) 4.3725 kama opuso i nengime, oria akp /                                ✗ calculating stats..\n",
            "epoch 0 of 125 (0:01:41.103346) 4.3725 a mina bun a ori ngo nyana la  /                                ✗ calculating stats..\n",
            "epoch 0 of 125 (0:03:20.302228) 4.0972 riye mi se koroma, se so mun k /                                ✗ calculating stats..\n",
            "epoch 0 of 125 (0:03:20.302419) 4.0972 o pekereme, i duko se ye fiapu /                                ✗ calculating stats..\n",
            "epoch 1 of 125 (0:04:59.899734) 3.6075 alabalari ye piri bie si osoin /                                ✗ average epoch rate per hr = 12.00,  eta = 10:19:47\n",
            "epoch 1 of 125 (0:04:59.899908) 3.6075 apu finji ma inia firi (mak .- /                                ✗ average epoch rate per hr = 12.00,  eta = 10:19:47\n",
            "epoch 1 of 125 (0:06:37.103088) 3.1638 n nyo soni o nyanake. jinbo, a /                                ✗ average epoch rate per hr = 9.07,  eta = 13:40:40\n",
            "epoch 1 of 125 (0:06:37.103283) 3.1638 bo siki, o yefime, piki bubuay /                                ✗ average epoch rate per hr = 9.07,  eta = 13:40:40\n",
            "epoch 2 of 125 (0:08:18.245576) 2.9747 mas be na matio amaochobo be n /                                ✗ average epoch rate per hr = 14.45,  eta = 8:30:42\n",
            "epoch 2 of 125 (0:08:18.245748) 2.9747 uamaye, nwo bi ene-en se o pir /                                ✗ average epoch rate per hr = 14.45,  eta = 8:30:42\n",
            "epoch 2 of 125 (0:09:55.681759) 2.8988  nwo fari o pirime okuma omine /                                ✗ average epoch rate per hr = 12.09,  eta = 10:10:34\n",
            "epoch 2 of 125 (0:09:55.682044) 2.8988 u ma ani sime sobie amanyanaki /                                ✗ average epoch rate per hr = 12.09,  eta = 10:10:34\n",
            "epoch 3 of 125 (0:11:34.719482) 2.8518 me, wa bime i gbori bubuamaye  / i                              ✗ average epoch rate per hr = 15.55,  eta = 7:50:51\n",
            "epoch 3 of 125 (0:11:34.719640) 2.8518  ini ani, torumgbollupun se at / i                              ✗ average epoch rate per hr = 15.55,  eta = 7:50:51\n",
            "epoch 3 of 125 (0:13:15.004210) 2.8506 in kabo mi fie ye nwo duko wa  /                                ✗ average epoch rate per hr = 13.58,  eta = 8:58:50\n",
            "epoch 3 of 125 (0:13:15.004530) 2.8506 i fieke okimun ini tombo toku  /                                ✗ average epoch rate per hr = 13.58,  eta = 8:58:50\n",
            "epoch 4 of 125 (0:14:52.493692) 2.8243 pu ma buosome    i da sobie si /                                ✗ average epoch rate per hr = 16.13,  eta = 7:29:57\n",
            "epoch 4 of 125 (0:14:52.493852) 2.8243 ia firinwengiapu ma ini opoli  /                                ✗ average epoch rate per hr = 16.13,  eta = 7:29:57\n",
            "epoch 4 of 125 (0:16:31.305911) 2.7921 boma na bobia anisiki ani o to /                                ✗ average epoch rate per hr = 14.53,  eta = 8:19:47\n",
            "epoch 4 of 125 (0:16:31.306216) 2.7921 nwose ofiri irua mi bie firinw /                                ✗ average epoch rate per hr = 14.53,  eta = 8:19:47\n",
            "epoch 5 of 125 (0:18:11.310902) 2.7835 se o pekereme, okuma sonome-a  /                                ✗ average epoch rate per hr = 16.49,  eta = 7:16:31\n",
            "epoch 5 of 125 (0:18:11.311082) 2.7835  nwose o pekereme, okuma obuko /                                ✗ average epoch rate per hr = 16.49,  eta = 7:16:31\n",
            "epoch 5 of 125 (0:19:51.416546) 2.7356  ini ok obo be se mukumukuma o / b                              ✗ average epoch rate per hr = 15.11,  eta = 7:56:33\n",
            "epoch 5 of 125 (0:19:51.416696) 2.7356  na tarakapu ma se i buo gbana / b                              ✗ average epoch rate per hr = 15.11,  eta = 7:56:34\n",
            "epoch 6 of 125 (0:21:28.962006) 2.7377 nde o koroma oku gboribo, mama /                           i    ✗ average epoch rate per hr = 16.76,  eta = 7:06:04\n",
            "epoch 6 of 125 (0:21:28.962189) 2.7377 reni bu barasinbia, ini jinbo- /                           i    ✗ average epoch rate per hr = 16.76,  eta = 7:06:04\n",
            "epoch 6 of 125 (0:23:08.390885) 2.7583 ama se ori nyanabo nwose o c /  i                             ✗ average epoch rate per hr = 15.56,  eta = 7:38:56\n",
            "epoch 6 of 125 (0:23:08.391039) 2.7583 la igbiki se kubie se bugbane  /  i                             ✗ average epoch rate per hr = 15.56,  eta = 7:38:56\n",
            "epoch 7 of 125 (0:24:48.814228) 2.7404 ki ini o kun se o boroma bufuk /                       i        ✗ average epoch rate per hr = 16.93,  eta = 6:58:17\n",
            "epoch 7 of 125 (0:24:48.814634) 2.7404 oboko ma painka simeogbo, i te /                       i        ✗ average epoch rate per hr = 16.93,  eta = 6:58:17\n",
            "epoch 7 of 125 (0:26:26.590109) 2.7240 o oyima-ende finji na oyiasi n /      i                         ✗ average epoch rate per hr = 15.88,  eta = 7:25:45\n",
            "epoch 7 of 125 (0:26:26.590281) 2.7240 bo simeme, barabas nwo chin bo /      i                         ✗ average epoch rate per hr = 15.88,  eta = 7:25:45\n",
            "epoch 8 of 125 (0:28:07.418295) 2.6983 izos be beme, ari ngisi i weri /           i    i  i            ✗ average epoch rate per hr = 17.07,  eta = 6:51:18\n",
            "epoch 8 of 125 (0:28:07.418530) 2.6983 uko ini piri oku mi nwo mieme. /           i    i  i            ✗ average epoch rate per hr = 17.07,  eta = 6:51:18\n",
            "epoch 8 of 125 (0:29:45.463181) 2.6798  lasiki-lasiki, romapu govina  / b               i i            ✗ average epoch rate per hr = 16.13,  eta = 7:15:12\n",
            "epoch 8 of 125 (0:29:45.463336) 2.6798  omine oruwu ogbo tobo duko o  / b               i i            ✗ average epoch rate per hr = 16.13,  eta = 7:15:12\n",
            "epoch 9 of 125 (0:31:26.023064) 2.6753 some. se govina be nemikase mi /   i          i  i  i i      i  ✗ average epoch rate per hr = 17.18,  eta = 6:45:08\n",
            "epoch 9 of 125 (0:31:26.023208) 2.6753 o naasam na ini nwo duko tomon /   i          i  i  i i      i  ✗ average epoch rate per hr = 17.18,  eta = 6:45:08\n",
            "epoch 9 of 125 (0:33:04.796480) 2.6484 pakumame, se o jodan mi bie me /     i i       i    i i  i   i  ✗ average epoch rate per hr = 16.32,  eta = 7:06:21\n",
            "epoch 9 of 125 (0:33:04.796628) 2.6484  se dumobia fiye na bubuye na  /     i i       i    i i  i   i  ✗ average epoch rate per hr = 16.32,  eta = 7:06:21\n",
            "epoch 10 of 125 (0:34:43.791550) 2.6543 ko dieapu ma na farisiapu ma n / i         i  i i  i       i  i ✗ average epoch rate per hr = 17.28,  eta = 6:39:23\n",
            "epoch 10 of 125 (0:34:43.791696) 2.6543 bia apu ma luk . jizos be o ke / i         i  i i  i       i  i ✗ average epoch rate per hr = 17.28,  eta = 6:39:23\n",
            "epoch 10 of 125 (0:36:24.761992) 2.6647 be belemabia o buiderina gbori / e      i      ii    i i     i  ✗ average epoch rate per hr = 16.48,  eta = 6:58:44\n",
            "epoch 10 of 125 (0:36:24.762233) 2.6647 ak . luk . jizos be oria oyima / e      i      ii    i i     i  ✗ average epoch rate per hr = 16.48,  eta = 6:58:44\n",
            "epoch 11 of 125 (0:38:04.423082) 2.6574 koro aizaya be duko ye mi bo k / i i        ii    i i  ii ii ii ✗ average epoch rate per hr = 17.33,  eta = 6:34:34\n",
            "epoch 11 of 125 (0:38:04.423254) 2.6574 i ilaija bee, ori ani bobia in / i i        ii    i i  ii ii ii ✗ average epoch rate per hr = 17.33,  eta = 6:34:34\n",
            "epoch 11 of 125 (0:39:43.225347) 2.6592 a firinwengiapu ma boke. sokub /  b  i i  i      i ii i   i i   ✗ average epoch rate per hr = 16.62,  eta = 6:51:38\n",
            "epoch 11 of 125 (0:39:43.225669) 2.6592 i mieye oforie, anikanika bere /  b  i i  i      i ii i   i i   ✗ average epoch rate per hr = 16.62,  eta = 6:51:38\n",
            "epoch 12 of 125 (0:41:23.207035) 2.6178 koroapu mamgba na mozzi oloko  / i i     i i   ii ii    i   i i ✗ average epoch rate per hr = 17.40,  eta = 6:29:43\n",
            "epoch 12 of 125 (0:41:23.207206) 2.6178 o duko wa piri.  jizos be ini  / i i     i i   ii ii    i   i i ✗ average epoch rate per hr = 17.40,  eta = 6:29:43\n",
            "epoch 12 of 125 (0:43:02.121866) 2.6527 bia na berekon ene mi bie tomo / e   i ii i i i  i ii ii  i  i  ✗ average epoch rate per hr = 16.73,  eta = 6:45:14\n",
            "epoch 12 of 125 (0:43:02.122010) 2.6527 a ini ani, torumgbollupun se a / e   i ii i i i  i ii ii  i  i  ✗ average epoch rate per hr = 16.73,  eta = 6:45:14\n",
            "epoch 13 of 125 (0:44:42.063616) 2.6261 ome, oria obudukoapu ma o dama /  i    i  i i   i    ii i i  i  ✗ average epoch rate per hr = 17.45,  eta = 6:25:07\n",
            "epoch 13 of 125 (0:44:42.063778) 2.6261 a jems be na jon be na nwo oki /  i    i  i i   i    ii i i  i  ✗ average epoch rate per hr = 17.45,  eta = 6:25:07\n",
            "epoch 13 of 125 (0:46:20.012558) 2.6229 siapu ma buosome  i da sobie s /       i ii    i  i ii ii i  ii ✗ average epoch rate per hr = 16.83,  eta = 6:39:10\n",
            "epoch 13 of 125 (0:46:20.012710) 2.6229 na, piki o nyana ye goyegoye m /       i ii    i  i ii ii i  ii ✗ average epoch rate per hr = 16.83,  eta = 6:39:10\n",
            "epoch 14 of 125 (0:47:58.091597) 2.6271  ini fieke okimun ini tombo to / b i i   i i i i i  i i  i  i   ✗ average epoch rate per hr = 17.51,  eta = 6:20:19\n",
            "epoch 14 of 125 (0:47:58.091876) 2.6271 e bara nwo mie anikanika a mie / b i i   i i i i i  i i  i  i   ✗ average epoch rate per hr = 17.51,  eta = 6:20:19\n",
            "epoch 14 of 125 (0:49:36.101179) 2.6159 u sa nwo fib o. firinwengibo b /  bi ii  i  i   ii i i  i  i ii ✗ average epoch rate per hr = 16.93,  eta = 6:33:16\n",
            "epoch 14 of 125 (0:49:36.101324) 2.6159 ikiochoapu ma na ama nwengi er /  bi ii  i  i   ii i i  i  i ii ✗ average epoch rate per hr = 16.93,  eta = 6:33:16\n",
            "epoch 15 of 125 (0:51:15.742093) 2.5969  mioku, iya gbeinye oki, se so / bi  i  i   iii  i  i i  ii ii  ✗ average epoch rate per hr = 17.56,  eta = 6:15:55\n",
            "epoch 15 of 125 (0:51:15.742818) 2.5969 iki ari duko nwengi,k okuma om / bi  i  i   iii  i  i i  ii ii  ✗ average epoch rate per hr = 17.56,  eta = 6:15:55\n",
            "epoch 15 of 125 (0:52:53.096799) 2.5833 o amanyannakiri mi bie sobia.  /  b i i  ii i i ii ii  ii e   b ✗ average epoch rate per hr = 17.02,  eta = 6:27:49\n",
            "epoch 15 of 125 (0:52:53.096991) 2.5833 a. ye min diri mi kienbia bo a /  b i i  ii i i ii ii  ii e   b ✗ average epoch rate per hr = 17.02,  eta = 6:27:49\n",
            "epoch 16 of 125 (0:54:33.195520) 2.5796 apu ma na beme. oloko dieapu m /    ii ii ii i  b   i bi     bi ✗ average epoch rate per hr = 17.60,  eta = 6:11:38\n",
            "epoch 16 of 125 (0:54:33.195674) 2.5796 ni soye mie i pirisam, a vinpi /    ii ii ii i  b   i bi     bi ✗ average epoch rate per hr = 17.60,  eta = 6:11:38\n",
            "epoch 16 of 125 (0:56:11.441220) 2.5778 kabia ye mi mak . luk . \t opu  / i i  i  ii ii ib bi ib b b i b ✗ average epoch rate per hr = 17.08,  eta = 6:22:47\n",
            "epoch 16 of 125 (0:56:11.441393) 2.5778 npiki terea obudukoapu ma dama / i i  i  ii ii ib bi ib b b i b ✗ average epoch rate per hr = 17.08,  eta = 6:22:47\n",
            "epoch 17 of 125 (0:57:50.693978) 2.5889 fiiye sokusokume, piki ye kobi /      ii i   i i  bi i i  bi e  ✗ average epoch rate per hr = 17.63,  eta = 6:07:29\n",
            "epoch 17 of 125 (0:57:50.694221) 2.5889 ni pa gele puko se olokuabe mg /      ii i   i i  bi i i  bi e  ✗ average epoch rate per hr = 17.63,  eta = 6:07:29\n",
            "epoch 17 of 125 (0:59:28.571542) 2.5634 bin, toru se kiri ibo se tekem / e i ii i bi bi i b i bi bi i i ✗ average epoch rate per hr = 17.15,  eta = 6:17:50\n",
            "epoch 17 of 125 (0:59:28.571690) 2.5634 e juapu ma kenge pirike, ani i / e i ii i bi bi i b i bi bi i i ✗ average epoch rate per hr = 17.15,  eta = 6:17:50\n",
            "epoch 18 of 125 (1:01:07.605782) 2.5647 bas bee  nde, anisiki jizos in / e  bi  iii   b i i i bi   ib i ✗ average epoch rate per hr = 17.67,  eta = 6:03:21\n",
            "epoch 18 of 125 (1:01:07.605952) 2.5647 ili bie so jodan mi nwo mume,  / e  bi  iii   b i i i bi   ib i ✗ average epoch rate per hr = 17.67,  eta = 6:03:21\n",
            "epoch 18 of 125 (1:02:47.111064) 2.5677  bereni wa piri diaboromabo be / be i i ii bi i bi  i i i e be  ✗ average epoch rate per hr = 17.20,  eta = 6:13:13\n",
            "epoch 18 of 125 (1:02:47.111321) 2.5677  mi i simebia yee, a duko i pi / be i i ii bi i bi  i i i e be  ✗ average epoch rate per hr = 17.20,  eta = 6:13:13\n",
            "epoch 19 of 125 (1:04:25.072094) 2.5683 iye koko nyo mi bies chuabia,  /    ii i bi  bi bi   b    e   b ✗ average epoch rate per hr = 17.70,  eta = 5:59:23\n",
            "epoch 19 of 125 (1:04:25.072237) 2.5683 gose bubalabala se ibu piri ma /    ii i bi  bi bi   b    e   b ✗ average epoch rate per hr = 17.70,  eta = 5:59:23\n",
            "epoch 19 of 125 (1:06:02.673700) 2.5514 ofori,s i nwo ani nyo la kirik /    i  ib ii  b i bi  bi bi i i ✗ average epoch rate per hr = 17.26,  eta = 6:08:27\n",
            "epoch 19 of 125 (1:06:02.673903) 2.5514 me baramgba nwosebalafa ye omi /    i  ib ii  b i bi  bi bi i i ✗ average epoch rate per hr = 17.26,  eta = 6:08:27\n",
            "epoch 20 of 125 (1:07:40.536274) 2.5360 mgba mianga sime se ba bari or / i e bi  i  bi i bi be be i b i ✗ average epoch rate per hr = 17.73,  eta = 5:55:17\n",
            "epoch 20 of 125 (1:07:40.536489) 2.5360 piki gbeinye okika bara bu pir / i e bi  i  bi i bi be be i b i ✗ average epoch rate per hr = 17.73,  eta = 5:55:17\n",
            "epoch 20 of 125 (1:09:19.126925) 2.5327 jizos be o monoabe  obudukoapu /     ibi b bi i  e bi e   i  i  ✗ average epoch rate per hr = 17.31,  eta = 6:03:55\n",
            "epoch 20 of 125 (1:09:19.127198) 2.5327 a bie mie bugbiripumaye ma nem /     ibi b bi i  e bi e   i  i  ✗ average epoch rate per hr = 17.31,  eta = 6:03:55\n",
            "epoch 21 of 125 (1:10:58.472246) 2.5160 kisamu omine obiapu ma gwo, fi / i   i b i i b e  i bi bi   bi  ✗ average epoch rate per hr = 17.75,  eta = 5:51:29\n",
            "epoch 21 of 125 (1:10:58.472411) 2.5160 ko o piriabe na, solomon be ne / i   i b i i b e  i bi bi   bi  ✗ average epoch rate per hr = 17.75,  eta = 5:51:29\n",
            "epoch 21 of 125 (1:12:36.420591) 2.5200  tomoni ma pa inia si ma bie v / bi i i ii bi b i  bi bi be  bi ✗ average epoch rate per hr = 17.35,  eta = 5:59:34\n",
            "epoch 21 of 125 (1:12:36.420877) 2.5200 me ngo nwo orime  o piki ani g / bi i i ii bi b i  bi bi be  bi ✗ average epoch rate per hr = 17.35,  eta = 5:59:34\n",
            "epoch 22 of 125 (1:14:14.689983) 2.5138 aeremenibo ma sise bere kon om /   i i i i bi bi i be i bi ib i ✗ average epoch rate per hr = 17.78,  eta = 5:47:36\n",
            "epoch 22 of 125 (1:14:14.690189) 2.5138 ere anga bo o damabome  ari ow /   i i i i bi bi i be i bi ib i ✗ average epoch rate per hr = 17.78,  eta = 5:47:36\n",
            "epoch 22 of 125 (1:15:54.387008) 2.5228  da be amanyanakiri mi bie  be / bi bi b i i  i i i bi be  bie  ✗ average epoch rate per hr = 17.39,  eta = 5:55:22\n",
            "epoch 22 of 125 (1:15:54.387173) 2.5228 iki, jizos be inia beri jineme / bi bi b i i  i i i bi be  bie  ✗ average epoch rate per hr = 17.39,  eta = 5:55:22\n",
            "epoch 23 of 125 (1:17:34.616148) 2.5118 a bo so eke   gbori eremenibo  /  bi bi b i boiie i b i i i e b ✗ average epoch rate per hr = 17.79,  eta = 5:44:02\n",
            "epoch 23 of 125 (1:17:34.616305) 2.5118  i olo igbiki ma mgba a barasi /  bi bi b i boiie i b i i i e b ✗ average epoch rate per hr = 17.79,  eta = 5:44:02\n",
            "epoch 23 of 125 (1:19:12.197862) 2.5218 se ini lama, se nwo beme, o si /   b i ii i  bi bi  be i  b bi  ✗ average epoch rate per hr = 17.42,  eta = 5:51:14\n",
            "epoch 23 of 125 (1:19:12.198027) 2.5218 nakiri bie   okuma jizos be pe /   b i ii i  bi bi  be i  b bi  ✗ average epoch rate per hr = 17.42,  eta = 5:51:14\n",
            "epoch 24 of 125 (1:20:51.603172) 2.5168 ni pirike, ani ini so mun paka / i bi i i  b i b i bi bi ibi i  ✗ average epoch rate per hr = 17.81,  eta = 5:40:17\n",
            "epoch 24 of 125 (1:20:51.603436) 2.5168 uma, se o ba yee  \t mioku iru  / i bi i i  b i b i bi bi ibi i  ✗ average epoch rate per hr = 17.81,  eta = 5:40:17\n",
            "epoch 24 of 125 (1:22:28.854597) 2.4923  nwo bi  a nwose o beme, beren / bi  be bi bi  i b be i  be i i ✗ average epoch rate per hr = 17.46,  eta = 5:47:06\n",
            "epoch 24 of 125 (1:22:28.854746) 2.4923 aist bee  ominea bie opuso tei / bi  be bi bi  i b be i  be i i ✗ average epoch rate per hr = 17.46,  eta = 5:47:06\n",
            "epoch 25 of 125 (1:24:07.639541) 2.4993 i siki, ini nwose inia bu ma b /  bi i  b i bi  i b i  be bi be ✗ average epoch rate per hr = 17.83,  eta = 5:36:30\n",
            "epoch 25 of 125 (1:24:07.639842) 2.4993  elekima na bugbiripumaye na n /  bi i  b i bi  i b i  be bi be ✗ average epoch rate per hr = 17.83,  eta = 5:36:30\n",
            "epoch 25 of 125 (1:25:46.273490) 2.4941 oribo so chin ma, aniatibi gbo /  i i bi bii ibi  b i    e bie  ✗ average epoch rate per hr = 17.49,  eta = 5:43:05\n",
            "epoch 25 of 125 (1:25:46.273626) 2.4941 i bie so ani tomonikiri mi tem /  i i bi bii ibi  b i    e bie  ✗ average epoch rate per hr = 17.49,  eta = 5:43:05\n",
            "epoch 26 of 125 (1:27:24.094354) 2.4967 diki, kraist be o miannga omi /    i  bii  i be b bi  ii  b i  ✗ average epoch rate per hr = 17.85,  eta = 5:32:47\n",
            "epoch 26 of 125 (1:27:24.094652) 2.4967  ma bie gboribo bo la yee baka /    i  bii  i be b bi  ii  b i  ✗ average epoch rate per hr = 17.85,  eta = 5:32:47\n",
            "epoch 26 of 125 (1:29:03.001286) 2.4641 ia erebaraanga bu simebia  ani /   b i e i  i  be bi i e  bb i  ✗ average epoch rate per hr = 17.52,  eta = 5:39:04\n",
            "epoch 26 of 125 (1:29:03.001923) 2.4641 in se oria ye ma nwose o chuam /   b i e i  i  be bi i e  bb i  ✗ average epoch rate per hr = 17.52,  eta = 5:39:04\n",
            "epoch 27 of 125 (1:30:41.579926) 2.4965 sise, o ye wa so  diki be ani  /   i  b be bi bi bbi i be b i b ✗ average epoch rate per hr = 17.86,  eta = 5:29:10\n",
            "epoch 27 of 125 (1:30:41.580233) 2.4965 e gose (beretibi ), diri mi gi /   i  b be bi bi bbi i be b i b ✗ average epoch rate per hr = 17.86,  eta = 5:29:10\n",
            "epoch 27 of 125 (1:32:20.928339) 2.4638 ri o kombo se nwo beme, gele j / i b ii ie bi bi  be i  bi   bi ✗ average epoch rate per hr = 17.54,  eta = 5:35:11\n",
            "epoch 27 of 125 (1:32:20.928582) 2.4638 mesi bu a nwengi firima ini    / i b ii ie bi bi  be i  bi   bi ✗ average epoch rate per hr = 17.54,  eta = 5:35:11\n",
            "epoch 28 of 125 (1:33:59.504231) 2.4651  be miemieay ma na nama agbama / be bi  i   ebi bi bi a b ie a  ✗ average epoch rate per hr = 17.87,  eta = 5:25:36\n",
            "epoch 28 of 125 (1:33:59.504514) 2.4651 boro min bara mi se okwein-abi / be bi  i   ebi bi bi a b ie a  ✗ average epoch rate per hr = 17.87,  eta = 5:25:36\n",
            "epoch 28 of 125 (1:35:38.728784) 2.4480 ninachin ma, ani ominea biejua / i i    ibi  b i b i i  be      ✗ average epoch rate per hr = 17.56,  eta = 5:31:20\n",
            "epoch 28 of 125 (1:35:38.728956) 2.4480 mi, o nwengi tamubo be na oria / i i    ibi  b i b i i  be      ✗ average epoch rate per hr = 17.56,  eta = 5:31:20\n",
            "epoch 29 of 125 (1:37:16.961962) 2.4707 na kenge pakumame bebe, oko si / i bi i  bi i a a be e  b i bi  ✗ average epoch rate per hr = 17.89,  eta = 5:22:02\n",
            "epoch 29 of 125 (1:37:16.962219) 2.4707 bike,      okuma oju i nwo kar / i bi i  bi i a a be e  b i bi  ✗ average epoch rate per hr = 17.89,  eta = 5:22:02\n",
            "epoch 29 of 125 (1:38:55.670461) 2.4520 , toru kweinma tundu mi ogono  /  bi i bi   ia bi i  bi b i i b ✗ average epoch rate per hr = 17.59,  eta = 5:27:29\n",
            "epoch 29 of 125 (1:38:55.670609) 2.4520 o nwose o chin mi, aniatibi o  /  bi i bi   ia bi i  bi b i i b ✗ average epoch rate per hr = 17.59,  eta = 5:27:29\n",
            "epoch 30 of 125 (1:40:34.733303) 2.4587 na obori na pulo ineda sima de / i b e i bi bi   b i   bi i bi  ✗ average epoch rate per hr = 17.90,  eta = 5:18:29\n",
            "epoch 30 of 125 (1:40:34.733445) 2.4587 nyana ebel pulo mi nengi ye mi / i b e i bi bi   b i   bi i bi  ✗ average epoch rate per hr = 17.90,  eta = 5:18:29\n",
            "epoch 30 of 125 (1:42:16.205844) 2.4774  mgboku ini acho doki se vinpi / bi e i b i b ii bi i bi bi i   ✗ average epoch rate per hr = 17.60,  eta = 5:23:51\n",
            "epoch 30 of 125 (1:42:16.205993) 2.4774  tamuno be oria enjelapu ma nw / bi e i b i b ii bi i bi bi i   ✗ average epoch rate per hr = 17.60,  eta = 5:23:51\n",
            "epoch 31 of 125 (1:43:54.408681) 2.4622 ie karamasa ibi apu ma temema  /   bi i a i b e b i bi bi i a b ✗ average epoch rate per hr = 17.90,  eta = 5:15:04\n",
            "epoch 31 of 125 (1:43:54.408996) 2.4622 i fiafiadiri mi be gbori anga  /   bi i a i b e b i bi bi i a b ✗ average epoch rate per hr = 17.90,  eta = 5:15:04\n",
            "epoch 31 of 125 (1:45:33.280920) 2.4428 se tomonikiri mi firimae ton s / e bi i i i i bi bi i i  bi ibi ✗ average epoch rate per hr = 17.62,  eta = 5:20:04\n",
            "epoch 31 of 125 (1:45:33.281126) 2.4428 angba nwose oyia kiri die se g / e bi i i i i bi bi i i  bi ibi ✗ average epoch rate per hr = 17.62,  eta = 5:20:04\n",
            "epoch 32 of 125 (1:47:14.944565) 2.4545 yosara se ini piribia ton ama  /   i i bi b i bi i e  bi ib i b ✗ average epoch rate per hr = 17.90,  eta = 5:11:41\n",
            "epoch 32 of 125 (1:47:14.944767) 2.4545 maa ye ma nwo duko eke.  ye to /   i i bi b i bi i e  bi ib i b ✗ average epoch rate per hr = 17.90,  eta = 5:11:41\n",
            "epoch 32 of 125 (1:48:54.385920) 2.4704  mun se tona amanyanaapu nwo b / bi ibi bi i b a i  i  i bi  be ✗ average epoch rate per hr = 17.63,  eta = 5:16:30\n",
            "epoch 32 of 125 (1:48:54.386081) 2.4704 gboloma miemieye mi bu o barai / bi ibi bi i b a i  i  i bi  be ✗ average epoch rate per hr = 17.63,  eta = 5:16:30\n",
            "epoch 33 of 125 (1:50:35.763480) 2.4193 muno be anianga ori omie, aria / a i be b i  i  b i b i   b i   ✗ average epoch rate per hr = 17.90,  eta = 5:08:19\n",
            "epoch 33 of 125 (1:50:35.763645) 2.4193 owunima nengimame. bereni mi b / a i be b i  i  b i b i   b i   ✗ average epoch rate per hr = 17.90,  eta = 5:08:19\n",
            "epoch 33 of 125 (1:52:15.981900) 2.4393 nabia na ori ineda o bereniye  / i e  bi b i b i   b be i i   b ✗ average epoch rate per hr = 17.64,  eta = 5:12:59\n",
            "epoch 33 of 125 (1:52:15.982061) 2.4393  jizos be bu wa boro mieari ag / i e  bi b i b i   b be i i   b ✗ average epoch rate per hr = 17.64,  eta = 5:12:59\n",
            "epoch 34 of 125 (1:53:54.569494) 2.4303 um chiribama bipi nwo gbeinme. /  abii i e a be i bi  bie  ia   ✗ average epoch rate per hr = 17.91,  eta = 5:04:52\n",
            "epoch 34 of 125 (1:53:54.569660) 2.4303 izos be miese o kara ani torus /  abii i e a be i bi  bie  ia   ✗ average epoch rate per hr = 17.91,  eta = 5:04:52\n",
            "epoch 34 of 125 (1:55:31.890325) 2.4467 i mianga wa anaga gbasobia ama /  bi  i  bi b i i bie e e  b i  ✗ average epoch rate per hr = 17.66,  eta = 5:09:13\n",
            "epoch 34 of 125 (1:55:31.890554) 2.4467 i eron be chin oku mi   ani kr /  bi  i  bi b i i bie e e  b i  ✗ average epoch rate per hr = 17.66,  eta = 5:09:13\n",
            "epoch 35 of 125 (1:57:10.586519) 2.4349 a osi na ini nwose amanyanachu /  b i bi b i bi  e b a i  i     ✗ average epoch rate per hr = 17.92,  eta = 5:01:18\n",
            "epoch 35 of 125 (1:57:10.586764) 2.4349 ania bu mi wa boro bo tamuno b /  b i bi b i bi  e b a i  i     ✗ average epoch rate per hr = 17.92,  eta = 5:01:18\n",
            "epoch 35 of 125 (1:58:50.006624) 2.4320  ye sonie  gboribo soni gele a / be bi i  boie i e bi i bi   b  ✗ average epoch rate per hr = 17.67,  eta = 5:05:34\n",
            "epoch 35 of 125 (1:58:50.006879) 2.4320 mbulo ma pulo mi nwo oki mengi / be bi i  boie i e bi i bi   b  ✗ average epoch rate per hr = 17.67,  eta = 5:05:34\n",
            "epoch 36 of 125 (2:00:29.545104) 2.4398 pirisam, aniatibi ani kuroke p / i i i a b i  i e b i bi i i bi ✗ average epoch rate per hr = 17.93,  eta = 4:57:53\n",
            "epoch 36 of 125 (2:00:29.545283) 2.4398 obe soni   bereni mi miese eno / i i i a b i  i e b i bi i i bi ✗ average epoch rate per hr = 17.93,  eta = 4:57:53\n",
            "epoch 36 of 125 (2:02:07.696307) 2.4202 ebuso eka yee, pulo osunka sim /  e   b i be   bi   b i ii bi i ✗ average epoch rate per hr = 17.69,  eta = 5:01:55\n",
            "epoch 36 of 125 (2:02:07.696456) 2.4202 ni bufuka se wa piri siki, ani /  e   b i be   bi   b i ii bi i ✗ average epoch rate per hr = 17.69,  eta = 5:01:55\n",
            "epoch 37 of 125 (2:03:47.216901) 2.4123 e se karakara tomonibo nwose o /  bi bi i i i bi i i e bi  e b  ✗ average epoch rate per hr = 17.93,  eta = 4:54:24\n",
            "epoch 37 of 125 (2:03:47.217035) 2.4123 koro koro bia, sobie sime kuro /  bi bi i i i bi i i e bi  e b  ✗ average epoch rate per hr = 17.93,  eta = 4:54:24\n",
            "epoch 37 of 125 (2:05:24.866283) 2.4036 i nwose bufuka se wa pirime, a /  bi  e be   i bi bi bi i i  b  ✗ average epoch rate per hr = 17.70,  eta = 4:58:16\n",
            "epoch 37 of 125 (2:05:24.866426) 2.4036 o be bo la ye-e. tomonikpo o b /  bi  e be   i bi bi bi i i  b  ✗ average epoch rate per hr = 17.70,  eta = 4:58:16\n",
            "epoch 38 of 125 (2:07:05.633292) 2.4112 . tombo toku be oria bo mi (ma /  bi ie bi i be b i  be bi bia  ✗ average epoch rate per hr = 17.94,  eta = 4:50:58\n",
            "epoch 38 of 125 (2:07:05.633543) 2.4112  obu duabororma ke ye wa mesay /  bi ie bi i be b i  be bi bia  ✗ average epoch rate per hr = 17.94,  eta = 4:50:58\n",
            "epoch 38 of 125 (2:08:43.094878) 2.4064 bafiari bo be o mio omi-e jizo / e    i be be b bi  b i   bi i  ✗ average epoch rate per hr = 17.71,  eta = 4:54:41\n",
            "epoch 38 of 125 (2:08:43.095178) 2.4064 gsi, a koromame na ani ibibia  / e    i be be b bi  b i   bi i  ✗ average epoch rate per hr = 17.71,  eta = 4:54:41\n",
            "epoch 39 of 125 (2:10:22.030217) 2.4076 ori bara mi bu tibini agbamiea /  i be i bi be bi e i b ie a    ✗ average epoch rate per hr = 17.95,  eta = 4:47:28\n",
            "epoch 39 of 125 (2:10:22.030451) 2.4076  bolosa siki ngisi ori oria fi /  i be i bi be bi e i b ie a    ✗ average epoch rate per hr = 17.95,  eta = 4:47:28\n",
            "epoch 39 of 125 (2:11:59.733506) 2.4096  ma duko ini piri ye ma ini nw / bi bi i b i bi i be bi b i bi  ✗ average epoch rate per hr = 17.73,  eta = 4:51:04\n",
            "epoch 39 of 125 (2:11:59.733659) 2.4096 lo taibirios be bereton jie-a  / bi bi i b i bi i be bi b i bi  ✗ average epoch rate per hr = 17.73,  eta = 4:51:04\n",
            "epoch 40 of 125 (2:13:39.071610) 2.3964 oria tomoni ma piri-e bome,    /  i  bi i i bi bi i   be a  bbi ✗ average epoch rate per hr = 17.96,  eta = 4:44:00\n",
            "epoch 40 of 125 (2:13:39.071760) 2.3964 ime ama mi bie sime debo fisa  /  i  bi i i bi bi i   be a  bbi ✗ average epoch rate per hr = 17.96,  eta = 4:44:00\n",
            "epoch 40 of 125 (2:15:16.938705) 2.4140 s be senime, oju bun a piki ne / ebe be i i  b i be ib bi i bi  ✗ average epoch rate per hr = 17.74,  eta = 4:47:28\n",
            "epoch 40 of 125 (2:15:16.938852) 2.4140 os be piki min kabo mi kon ini / ebe be i i  b i be ib bi i bi  ✗ average epoch rate per hr = 17.74,  eta = 4:47:28\n",
            "epoch 41 of 125 (2:16:56.022714) 2.3837 oroka siki, opu buruba sime be /  i i bi i  b i be i e bi i be  ✗ average epoch rate per hr = 17.96,  eta = 4:40:32\n",
            "epoch 41 of 125 (2:16:56.022857) 2.3837 nwose o diebia. wari nama-a si /  i i bi i  b i be i e bi i be  ✗ average epoch rate per hr = 17.96,  eta = 4:40:32\n",
            "epoch 41 of 125 (2:18:35.463896) 2.3824 na simeari ogbo ye miemie bara / i bi i  i b ie be bi  a  be i  ✗ average epoch rate per hr = 17.75,  eta = 4:43:56\n",
            "epoch 41 of 125 (2:18:35.464145) 2.3824 sam deinma bu so. jizos be duk / i bi i  i b ie be bi  a  be i  ✗ average epoch rate per hr = 17.75,  eta = 4:43:56\n",
            "epoch 42 of 125 (2:20:15.404191) 2.4073 ) nde o gose, nyanabo, nyanab /  bi  b bi e  bii  i e  bie i e ✗ average epoch rate per hr = 17.97,  eta = 4:37:10\n",
            "epoch 42 of 125 (2:20:15.404488) 2.4073 a now duko nweni mgba piriabe  /  bi  b bi e  bii  i e  bie i e ✗ average epoch rate per hr = 17.97,  eta = 4:37:10\n",
            "epoch 42 of 125 (2:21:52.940108) 2.3882  isiapu ma saki nwose inia bu  / b i  i bi bi i bi  e b i  be b ✗ average epoch rate per hr = 17.76,  eta = 4:40:23\n",
            "epoch 42 of 125 (2:21:52.940334) 2.3882 ia bipiogboso ke ini dukoari b / b i  i bi bi i bi  e b i  be b ✗ average epoch rate per hr = 17.76,  eta = 4:40:23\n",
            "epoch 43 of 125 (2:23:32.609532) 2.3801 anikanika ene ma baka sime ogb /  i i i i b i bi be i bi i b ie ✗ average epoch rate per hr = 17.97,  eta = 4:33:44\n",
            "epoch 43 of 125 (2:23:32.609997) 2.3801 ma pailet be toroko mun se jiz /  i i i i b i bi be i bi i b ie ✗ average epoch rate per hr = 17.97,  eta = 4:33:44\n",
            "epoch 43 of 125 (2:25:12.353461) 2.3508  bere se jizos be punuma bia a / be i be bi i ebe bi i a be  b  ✗ average epoch rate per hr = 17.77,  eta = 4:36:54\n",
            "epoch 43 of 125 (2:25:12.353605) 2.3508 ipipokika apu ma nwo piki bo k / be i be bi i ebe bi i a be  b  ✗ average epoch rate per hr = 17.77,  eta = 4:36:54\n",
            "epoch 44 of 125 (2:26:51.936816) 2.3490 amuno amanyanakiri mi bo bia s /  a i b a i  i i i bi be be  bi ✗ average epoch rate per hr = 17.98,  eta = 4:30:21\n",
            "epoch 44 of 125 (2:26:51.936959) 2.3490 aria siki mi bo lame. se ari a /  a i b a i  i i i bi be be  bi ✗ average epoch rate per hr = 17.98,  eta = 4:30:21\n",
            "epoch 44 of 125 (2:28:31.165627) 2.3677 iribia. o nyanabo be toroko is /  i e   b bie i e be bi i i b i ✗ average epoch rate per hr = 17.78,  eta = 4:33:24\n",
            "epoch 44 of 125 (2:28:31.165774) 2.3677  bara se gboribo so bara igbik /  i e   b bie i e be bi i i b i ✗ average epoch rate per hr = 17.78,  eta = 4:33:24\n",
            "epoch 45 of 125 (2:30:10.308953) 2.3698  boe. o meri ma na mune inia e / be   b bi i bi bi bi i b i  b  ✗ average epoch rate per hr = 17.98,  eta = 4:26:58\n",
            "epoch 45 of 125 (2:30:10.309229) 2.3698 bee. jizos be tekewari ma bie  / be   b bi i bi bi bi i b i  b  ✗ average epoch rate per hr = 17.98,  eta = 4:26:58\n",
            "epoch 45 of 125 (2:31:48.241666) 2.3570 mie be o nwose ini beme, oloko / a  be b bio e b i be a  b i i  ✗ average epoch rate per hr = 17.79,  eta = 4:29:52\n",
            "epoch 45 of 125 (2:31:48.241870) 2.3570 a. ori oko mieme, se o bara mi / a  be b bio e b i be a  b i i  ✗ average epoch rate per hr = 17.79,  eta = 4:29:52\n",
            "epoch 46 of 125 (2:33:27.448109) 2.3649  bie pakasome, oloku se nwo be / be  bi i e a  b i i be bio be  ✗ average epoch rate per hr = 17.99,  eta = 4:23:32\n",
            "epoch 46 of 125 (2:33:27.448309) 2.3649 ikpo piki ari na omie. nyanabo / be  bi i e a  b i i be bio be  ✗ average epoch rate per hr = 17.99,  eta = 4:23:32\n",
            "epoch 46 of 125 (2:35:05.406146) 2.3600  piri barachua muno se ye se n / bi i be i     bi i bi be be bi ✗ average epoch rate per hr = 17.80,  eta = 4:26:21\n",
            "epoch 46 of 125 (2:35:05.406301) 2.3600  naa se mi dumo mi be bubalaba / bi i be i     bi i bi be be bi ✗ average epoch rate per hr = 17.80,  eta = 4:26:21\n",
            "epoch 47 of 125 (2:36:44.436903) 2.3509  kirikiri, duein igbe pura apu / bi i i i  bi   ib ie bi i b i  ✗ average epoch rate per hr = 17.99,  eta = 4:20:07\n",
            "epoch 47 of 125 (2:36:44.437048) 2.3509 i na sababoror fiya mi fi bia  / bi i i i  bi   ib ie bi i b i  ✗ average epoch rate per hr = 17.99,  eta = 4:20:07\n",
            "epoch 47 of 125 (2:38:23.803402) 2.3711 ia bie so mum kuno chuake kala /   be  be bi abi i bii  i bi a  ✗ average epoch rate per hr = 17.80,  eta = 4:22:52\n",
            "epoch 47 of 125 (2:38:23.803555) 2.3711 se owume  ini jizos be se pail /   be  be bi abi i bii  i bi a  ✗ average epoch rate per hr = 17.80,  eta = 4:22:52\n",
            "epoch 48 of 125 (2:40:03.737017) 2.3675 ubo omine na iria bia  omine o /  e b i i bi b i  be  biii i b  ✗ average epoch rate per hr = 17.99,  eta = 4:16:45\n",
            "epoch 48 of 125 (2:40:03.737236) 2.3675 i boro siki jizos be obu seni  /  e b i i bi b i  be  biii i b  ✗ average epoch rate per hr = 17.99,  eta = 4:16:45\n",
            "epoch 48 of 125 (2:41:41.559388) 2.3681 okwein o pirime nwo be oku mi  /  i   ib bi i i bio be b i bi b ✗ average epoch rate per hr = 17.81,  eta = 4:19:22\n",
            "epoch 48 of 125 (2:41:41.559624) 2.3681 gbanabia, tamuno be kuro mi pi /  i   ib bi i i bio be b i bi b ✗ average epoch rate per hr = 17.81,  eta = 4:19:22\n",
            "epoch 49 of 125 (2:43:21.728512) 2.3320 a a nwo beme, na jizos be o du /  b bio be a  bi bi i ebe b bi  ✗ average epoch rate per hr = 18.00,  eta = 4:13:22\n",
            "epoch 49 of 125 (2:43:21.728732) 2.3320 ko mi bi bara bu  anisiki mi b /  b bio be a  bi bi i ebe b bi  ✗ average epoch rate per hr = 18.00,  eta = 4:13:22\n",
            "epoch 49 of 125 (2:45:00.155741) 2.3591 ri ma nwose enjelbo be beme, i / i bi bio e b i   e be be a  b  ✗ average epoch rate per hr = 17.82,  eta = 4:15:55\n",
            "epoch 49 of 125 (2:45:00.155939) 2.3591 halalie ya be, kenan ya be, en / i bi bio e b i   e be be a  b  ✗ average epoch rate per hr = 17.82,  eta = 4:15:55\n",
            "epoch 50 of 125 (2:46:39.904811) 2.3622 ye ini nwose ton bu weri nyana / e b i bio e bi ibe bo i bie i  ✗ average epoch rate per hr = 18.00,  eta = 4:09:59\n",
            "epoch 50 of 125 (2:46:39.904972) 2.3622  a kokoma bime, ye i fiafia an / e b i bio e bi ibe bo i bie i  ✗ average epoch rate per hr = 18.00,  eta = 4:09:59\n",
            "epoch 50 of 125 (2:48:18.380345) 2.3311  ya be, peleg ya be, eba ya be / be be  bi    be be  b e be be  ✗ average epoch rate per hr = 17.82,  eta = 4:12:27\n",
            "epoch 50 of 125 (2:48:18.380490) 2.3311 a bu ari gbori aye ma nwo duko / be be  bi    be be  b e be be  ✗ average epoch rate per hr = 17.82,  eta = 4:12:27\n",
            "epoch 50 of 125 (2:49:56.126948) 2.3504 iki, ori o buo chuku biki koro /  i  b i b be  bii i be i bi i  ✗ average epoch rate per hr = 17.65,  eta = 4:14:54\n",
            "epoch 50 of 125 (2:49:56.127180) 2.3504 i yisa bo goyegoye nengime  ok /  i  b i b be  bii i be i bi i  ✗ average epoch rate per hr = 17.65,  eta = 4:14:54\n",
            "epoch 51 of 125 (2:51:33.694173) 2.3676   apu ma  o kururu pikis owubi / bb i bi boibi i i bi i ib o e  ✗ average epoch rate per hr = 17.84,  eta = 4:08:55\n",
            "epoch 51 of 125 (2:51:33.694330) 2.3676 mame  o papabu sin nwengi bolo / bb i bi boibi i i bi i ib o e  ✗ average epoch rate per hr = 17.84,  eta = 4:08:55\n",
            "epoch 51 of 125 (2:53:11.292997) 2.3641 iya okunwengibo be se i toroko /  e b i i  i  e be be bnbi i i  ✗ average epoch rate per hr = 17.67,  eta = 4:11:17\n",
            "epoch 51 of 125 (2:53:11.293310) 2.3641 a be ereya mi     mama din kar /  e b i i  i  e be be bnbi i i  ✗ average epoch rate per hr = 17.67,  eta = 4:11:17\n",
            "epoch 52 of 125 (2:54:47.961770) 2.3443 ma nwo mume, galili bu weri`bo / a bio bi a  bi a i be bo i  e  ✗ average epoch rate per hr = 17.85,  eta = 4:05:23\n",
            "epoch 52 of 125 (2:54:47.961997) 2.3443 i karam-e. gbori dukoye o nwo  / a bio bi a  bi a i be bo i  e  ✗ average epoch rate per hr = 17.85,  eta = 4:05:23\n",
            "epoch 52 of 125 (2:56:23.607807) 2.3157  oribia se o nwose ini beme, a / b i e  bi b bio e b i be a  b  ✗ average epoch rate per hr = 17.69,  eta = 4:07:37\n",
            "epoch 52 of 125 (2:56:23.608007) 2.3157 obudukoapu ma na soke, okuma i / b i e  bi b bio e b i be a  b  ✗ average epoch rate per hr = 17.69,  eta = 4:07:37\n",
            "epoch 53 of 125 (2:58:01.338360) 2.3115 , nweni boro fiye okibo o piri /  bio i be i bi e b i e b bi i  ✗ average epoch rate per hr = 17.86,  eta = 4:01:50\n",
            "epoch 53 of 125 (2:58:01.338528) 2.3115 o soni bara se o lamake, aniat /  bio i be i bi e b i e b bi i  ✗ average epoch rate per hr = 17.86,  eta = 4:01:50\n",
            "epoch 53 of 125 (2:59:36.928722) 2.3479  anibe ene ba, dapa mi bu isi  / b i e b i be  bi i bi be b i b ✗ average epoch rate per hr = 17.70,  eta = 4:04:00\n",
            "epoch 53 of 125 (2:59:36.928858) 2.3479 e-e  o be na ominea tamuno-e  / b i e b i be  bi i bi be b i b ✗ average epoch rate per hr = 17.70,  eta = 4:04:00\n",
            "epoch 54 of 125 (3:01:12.551914) 2.3456 yemiebo-e, omine o nemike,  ok / e a  e    b i i b bi a i  boii ✗ average epoch rate per hr = 17.88,  eta = 3:58:15\n",
            "epoch 54 of 125 (3:01:12.552075) 2.3456 e mgbele se i gbin-e ton-au \t  / e a  e    b i i b bi a i  boii ✗ average epoch rate per hr = 17.88,  eta = 3:58:15\n",
            "epoch 54 of 125 (3:02:49.433071) 2.3274 oma bara iri tubo \t jizos be p /  i be i bni bi e bibi i ebe bi ✗ average epoch rate per hr = 17.72,  eta = 4:00:22\n",
            "epoch 54 of 125 (3:02:49.433223) 2.3274  nwo beabe, o tamuno be tokoni /  i be i bni bi e bibi i ebe bi ✗ average epoch rate per hr = 17.72,  eta = 4:00:22\n",
            "epoch 55 of 125 (3:04:25.591869) 2.3397 nbia erechi dokim. jizos be nw / ie  b i    bi i i bi i ebe bio ✗ average epoch rate per hr = 17.89,  eta = 3:54:43\n",
            "epoch 55 of 125 (3:04:25.592117) 2.3397 u be o bie some. jizos be nwos / ie  b i    bi i i bi i ebe bio ✗ average epoch rate per hr = 17.89,  eta = 3:54:43\n",
            "epoch 55 of 125 (3:06:02.471890) 2.3094 boro alali mi gose bo opu tomo / e i b i a bi bi e be b i bi a  ✗ average epoch rate per hr = 17.74,  eta = 3:56:46\n",
            "epoch 55 of 125 (3:06:02.472119) 2.3094 leke iri mi o sele ye-e, se o  / e i b i a bi bi e be b i bi a  ✗ average epoch rate per hr = 17.74,  eta = 3:56:46\n",
            "epoch 56 of 125 (3:07:40.378699) 2.3237 bo be-e. ani o fituru pekere m / e be    b i b bi i i bi i i bi ✗ average epoch rate per hr = 17.90,  eta = 3:51:14\n",
            "epoch 56 of 125 (3:07:40.378880) 2.3237  iri na gboribu simeoku mi. ar / e be    b i b bi i i bi i i bi ✗ average epoch rate per hr = 17.90,  eta = 3:51:14\n",
            "epoch 56 of 125 (3:09:18.873094) 2.3498 engibo be o nyanabo be mieari  /  i  e be b bie i e be bi   i b ✗ average epoch rate per hr = 17.75,  eta = 3:53:15\n",
            "epoch 56 of 125 (3:09:18.873297) 2.3498 komaye mi gbolomaye nwo dukobi /  i  e be b bie i e be bi   i b ✗ average epoch rate per hr = 17.75,  eta = 3:53:15\n",
            "epoch 57 of 125 (3:10:56.246424) 2.3436 ri-e, okuma ini tomonikiri mi  / i    b i a bni bi i i i i bi b ✗ average epoch rate per hr = 17.91,  eta = 3:47:47\n",
            "epoch 57 of 125 (3:10:56.246683) 2.3436 ma apu ma mangi ma mume, okuma / i    b i a bni bi i i i i bi b ✗ average epoch rate per hr = 17.91,  eta = 3:47:47\n",
            "epoch 57 of 125 (3:12:32.611907) 2.3359 e-e, iri amanyanabo ani okuma  /     bni b a i  i e b i b i a b ✗ average epoch rate per hr = 17.76,  eta = 3:49:42\n",
            "epoch 57 of 125 (3:12:32.612063) 2.3359 budukobo be-e, piki ari giein  /     bni b a i  i e b i b i a b ✗ average epoch rate per hr = 17.76,  eta = 3:49:42\n",
            "epoch 58 of 125 (3:14:09.630107) 2.3181  idupu mi bie nyanabo be dekis / b i i ba be  bie i e be bi i i ✗ average epoch rate per hr = 17.92,  eta = 3:44:17\n",
            "epoch 58 of 125 (3:14:09.630284) 2.3181  ye nwo duko i piri ma, jizos  / b i i ba be  bie i e be bi i i ✗ average epoch rate per hr = 17.92,  eta = 3:44:17\n",
            "epoch 58 of 125 (3:15:47.365775) 2.2933 zos be o beke na o fi eke, o b /   ebe b be i bi b bi b i  b be ✗ average epoch rate per hr = 17.77,  eta = 3:46:10\n",
            "epoch 58 of 125 (3:15:47.366049) 2.2933 ribo dipime, jinbo sokumeu. ar /   ebe b be i bi b bi b i  b be ✗ average epoch rate per hr = 17.77,  eta = 3:46:10\n",
            "epoch 59 of 125 (3:17:24.409839) 2.3070 jizos be na oria obudukoapu ma /   i ebe bi b i  b e   i  i ba  ✗ average epoch rate per hr = 17.93,  eta = 3:40:49\n",
            "epoch 59 of 125 (3:17:24.410107) 2.3070 e mi duko o piriabe omine i do /   i ebe bi b i  b e   i  i ba  ✗ average epoch rate per hr = 17.93,  eta = 3:40:49\n",
            "epoch 59 of 125 (3:19:01.162212) 2.2790  seni o fiaye ma nwo kobirima  / be i b bi  e bi bio bi e i i b ✗ average epoch rate per hr = 17.79,  eta = 3:42:37\n",
            "epoch 59 of 125 (3:19:01.162438) 2.2790 tibi omine ineda a simebia nyo / be i b bi  e bi bio bi e i i b ✗ average epoch rate per hr = 17.79,  eta = 3:42:37\n",
            "epoch 60 of 125 (3:20:36.299468) 2.3059 uru be \t tomoni ma dapa mi be  /  i be bibi i i bi bi i bi be b ✗ average epoch rate per hr = 17.95,  eta = 3:37:19\n",
            "epoch 60 of 125 (3:20:36.299618) 2.3059  ma o gbelame, yediebo, tubo m /  i be bibi i i bi bi i bi be b ✗ average epoch rate per hr = 17.95,  eta = 3:37:19\n",
            "epoch 60 of 125 (3:22:14.145434) 2.3087 echi. jizos be nwose ini beme, /      bi i ebe bio e bni be a   ✗ average epoch rate per hr = 17.80,  eta = 3:39:05\n",
            "epoch 60 of 125 (3:22:14.145590) 2.3087  ori i bie omie, iri so piki d /      bi i ebe bio e bni be a   ✗ average epoch rate per hr = 17.80,  eta = 3:39:05\n",
            "epoch 61 of 125 (3:23:49.660187) 2.3128 i omieu. jon   jizos be ini to /  b i    bi iboii i ebe bni bi  ✗ average epoch rate per hr = 17.96,  eta = 3:33:51\n",
            "epoch 61 of 125 (3:23:49.660330) 2.3128  bie tamunro tekee mun apu ma  /  b i    bi iboii i ebe bni bi  ✗ average epoch rate per hr = 17.96,  eta = 3:33:51\n",
            "epoch 61 of 125 (3:25:26.001443) 2.3150 i bereni ma, a nemikase i da b /  be i i bi  b bi a i e bnbi be ✗ average epoch rate per hr = 17.82,  eta = 3:35:32\n",
            "epoch 61 of 125 (3:25:26.001592) 2.3150 i nyo mi nwo mun eke.u iwo olo /  be i i bi  b bi a i e bnbi be ✗ average epoch rate per hr = 17.82,  eta = 3:35:32\n",
            "epoch 62 of 125 (3:27:02.074743) 2.2883  orisam na ngisi minea bara so / b i i abi bi  i bi i  be i be  ✗ average epoch rate per hr = 17.97,  eta = 3:30:22\n",
            "epoch 62 of 125 (3:27:02.075013) 2.2883 ein ini pirika okuma mioku ani / b i i abi bi  i bi i  be i be  ✗ average epoch rate per hr = 17.97,  eta = 3:30:22\n",
            "epoch 62 of 125 (3:28:38.867785) 2.3225  iya awo, ari omine na bari si / b e b o  b i b i i bi be i bi  ✗ average epoch rate per hr = 17.83,  eta = 3:32:00\n",
            "epoch 62 of 125 (3:28:38.868008) 2.3225 ma  pirime, miese ini soni ko / b e b o  b i b i i bi be i bi  ✗ average epoch rate per hr = 17.83,  eta = 3:32:00\n",
            "epoch 63 of 125 (3:30:15.760170) 2.3014 ebia, aniatibi omine iya tomon /  e   b i  a e b i i bne bi a i ✗ average epoch rate per hr = 17.98,  eta = 3:26:55\n",
            "epoch 63 of 125 (3:30:15.760417) 2.3014 e \t tibini agbamieapu ma na op /  e   b i  a e b i i bne bi a i ✗ average epoch rate per hr = 17.98,  eta = 3:26:55\n",
            "epoch 63 of 125 (3:31:51.576304) 2.3163 ama ibu piri iya okwein mi ani /  a bne bi i bne b io  ibi b i  ✗ average epoch rate per hr = 17.84,  eta = 3:28:29\n",
            "epoch 63 of 125 (3:31:51.576442) 2.3163 ame, eremenibo, nde i gose owu /  a bne bi i bne b io  ibi b i  ✗ average epoch rate per hr = 17.84,  eta = 3:28:29\n",
            "epoch 64 of 125 (3:33:26.965573) 2.3190 ike. ani jizos be nungo paka y /  i  b i bi i ebe bi a  bi i be ✗ average epoch rate per hr = 17.99,  eta = 3:23:26\n",
            "epoch 64 of 125 (3:33:26.965730) 2.3190  kuroma okwein ma na nwo orime /  i  b i bi i ebe bi a  bi i be ✗ average epoch rate per hr = 17.99,  eta = 3:23:26\n",
            "epoch 64 of 125 (3:35:03.654255) 2.3044 i o se koromaye nyo a nemike \t /  b be bi i a e bie b bi a i bi ✗ average epoch rate per hr = 17.86,  eta = 3:24:58\n",
            "epoch 64 of 125 (3:35:03.654562) 2.3044 ia ere an nikodimos,ori farisi /  b be bi i a e bie b bi a i bi ✗ average epoch rate per hr = 17.86,  eta = 3:24:58\n",
            "epoch 65 of 125 (3:36:42.340002) 2.2809  kuromame jizos be na oria obu / bi i a a bi i ebe bi b i  b e  ✗ average epoch rate per hr = 18.00,  eta = 3:20:02\n",
            "epoch 65 of 125 (3:36:42.340173) 2.2809 bugbiripuma firie o judia so b / bi i a a bi i ebe bi b i  b e  ✗ average epoch rate per hr = 18.00,  eta = 3:20:02\n",
            "epoch 65 of 125 (3:38:19.577695) 2.2753 o duko borosam, se ini fiafiad /  bi i be i e a be bni bi  i  i ✗ average epoch rate per hr = 17.86,  eta = 3:21:31\n",
            "epoch 65 of 125 (3:38:19.577971) 2.2753 sam, okuma o bereni dukuke  i  /  bi i be i e a be bni bi  i  i ✗ average epoch rate per hr = 17.86,  eta = 3:21:31\n",
            "epoch 66 of 125 (3:39:54.256653) 2.2799 iekoromame, ani siki mi bu mi  /   i i a a  b i bi i bi be ba b ✗ average epoch rate per hr = 18.01,  eta = 3:16:34\n",
            "epoch 66 of 125 (3:39:54.256882) 2.2799 un bo be  nwose isiapu ma beme /   i i a a  b i bi i bi be ba b ✗ average epoch rate per hr = 18.01,  eta = 3:16:34\n",
            "epoch 66 of 125 (3:41:31.602202) 2.2940 umo fituru bee, i damabo bo go /  a bi i i be   bnii a e be bi  ✗ average epoch rate per hr = 17.88,  eta = 3:18:01\n",
            "epoch 66 of 125 (3:41:31.602403) 2.2940 wo oki mun farisiapu ma pirime /  a bi i i be   bnii a e be bi  ✗ average epoch rate per hr = 17.88,  eta = 3:18:01\n",
            "epoch 67 of 125 (3:43:08.499242) 2.3023 ina tomoni ma mozizi oloko mi  /  i bi a i bi bi   i b i i bi b ✗ average epoch rate per hr = 18.02,  eta = 3:13:10\n",
            "epoch 67 of 125 (3:43:08.499445) 2.3023 mgbele se i gbine tonme i piki /  i bi a i bi bi   i b i i bi b ✗ average epoch rate per hr = 18.02,  eta = 3:13:10\n",
            "epoch 67 of 125 (3:44:44.682392) 2.2794  ini nwo gbelame, nde ori \to n / b i bio bie   a  bi  b i bi bi ✗ average epoch rate per hr = 17.89,  eta = 3:14:33\n",
            "epoch 67 of 125 (3:44:44.682542) 2.2794 i ani kele ominea ogboku simeb / b i bio bie   a  bi  b i bi bi ✗ average epoch rate per hr = 17.89,  eta = 3:14:33\n",
            "epoch 68 of 125 (3:46:21.676796) 2.2766  o now gbnama simeme  mi anisi / b bi obie  a be i a bni b i i  ✗ average epoch rate per hr = 18.02,  eta = 3:09:44\n",
            "epoch 68 of 125 (3:46:21.676976) 2.2766  wa nemike nde wa ineda mun an / b bi obie  a be i a bni b i i  ✗ average epoch rate per hr = 18.02,  eta = 3:09:44\n",
            "epoch 68 of 125 (3:47:59.376281) 2.2842 e o dumo gbamasobia  nde ani o /  b bi a bie a e e  boia b i b  ✗ average epoch rate per hr = 17.90,  eta = 3:11:06\n",
            "epoch 68 of 125 (3:47:59.376448) 2.2842  o piri borosam  fiafia teme b /  b bi a bie a e e  boia b i b  ✗ average epoch rate per hr = 17.90,  eta = 3:11:06\n",
            "epoch 69 of 125 (3:49:35.450068) 2.2941 npikibo omine oki ibu piribia, / i  i e b i i b i bni bi i e    ✗ average epoch rate per hr = 18.03,  eta = 3:06:20\n",
            "epoch 69 of 125 (3:49:35.450327) 2.2941  gbori ogbokiaye omie  jizos b / i  i e b i i b i bni bi i e    ✗ average epoch rate per hr = 18.03,  eta = 3:06:20\n",
            "epoch 69 of 125 (3:51:12.312555) 2.2741 aniatibi ma ini dabo be na iri /  i  a e bi bni bi e be bi bni  ✗ average epoch rate per hr = 17.91,  eta = 3:07:38\n",
            "epoch 69 of 125 (3:51:12.312836) 2.2741   hibru okwein bu ini nwose an /  i  a e bi bni bi e be bi bni  ✗ average epoch rate per hr = 17.91,  eta = 3:07:38\n",
            "epoch 70 of 125 (3:52:47.289108) 2.2607  bie simebia oku, jizos be kun / be  be i e  b i  bi i ebe bi a ✗ average epoch rate per hr = 18.04,  eta = 3:02:54\n",
            "epoch 70 of 125 (3:52:47.289338) 2.2607  ori owu se inia ogono sara se / be  be i e  b i  bi i ebe bi a ✗ average epoch rate per hr = 18.04,  eta = 3:02:54\n",
            "epoch 70 of 125 (3:54:23.065229) 2.2581 be maa okwein ma naa siki, o j / e bi  b io  iba bi  be i  b bi ✗ average epoch rate per hr = 17.92,  eta = 3:04:09\n",
            "epoch 70 of 125 (3:54:23.065453) 2.2581 inibo dukosimabia ye nwo nyana / e bi  b io  iba bi  be i  b bi ✗ average epoch rate per hr = 17.92,  eta = 3:04:09\n",
            "epoch 71 of 125 (3:55:58.222728) 2.2558 a bie beinme nyanabo be nwo or /  be  be  ia bie i e be bio b i ✗ average epoch rate per hr = 18.05,  eta = 2:59:28\n",
            "epoch 71 of 125 (3:55:58.222890) 2.2558 ma mi a now naame, piki nyanab /  be  be  ia bie i e be bio b i ✗ average epoch rate per hr = 18.05,  eta = 2:59:28\n",
            "epoch 71 of 125 (3:57:34.686964) 2.2560 ie bupalima yema nwose orutonb /   be i a i be a bio e b i o io ✗ average epoch rate per hr = 17.93,  eta = 3:00:41\n",
            "epoch 71 of 125 (3:57:34.687100) 2.2560 ye nwo furu ma. aninakaraka, y /   be i a i be a bio e b i o io ✗ average epoch rate per hr = 17.93,  eta = 3:00:41\n",
            "epoch 72 of 125 (3:59:09.791793) 2.2605 ni mi na  a teke siki goyegoye / i bi bi bonbi i be i bi e   e  ✗ average epoch rate per hr = 18.06,  eta = 2:56:03\n",
            "epoch 72 of 125 (3:59:09.791954) 2.2605  ye ani dada ani dukoariyee  t / i bi bi bonbi i be i bi e   e  ✗ average epoch rate per hr = 18.06,  eta = 2:56:03\n",
            "epoch 72 of 125 (4:00:46.410346) 2.2705 e dukobia siye ofori bara bu.  /  bi i e  be e b i i be i be  b ✗ average epoch rate per hr = 17.94,  eta = 2:57:14\n",
            "epoch 72 of 125 (4:00:46.410605) 2.2705 a ini inia bupalimaye goyegoye /  bi i e  be e b i i be i be  b ✗ average epoch rate per hr = 17.94,  eta = 2:57:14\n",
            "epoch 73 of 125 (4:02:22.195908) 2.2690 irimadiri mi ori ani seni bara /  i i a i bi b i b i bi i be i  ✗ average epoch rate per hr = 18.07,  eta = 2:52:38\n",
            "epoch 73 of 125 (4:02:22.196137) 2.2690 irime. a bike a nwengisa firim /  i i a i bi b i b i bi i be i  ✗ average epoch rate per hr = 18.07,  eta = 2:52:38\n",
            "epoch 73 of 125 (4:03:58.802516) 2.2717 iki mi bie anio simebia  pa bu /  i bi be  b i  be i e  boi be  ✗ average epoch rate per hr = 17.95,  eta = 2:53:47\n",
            "epoch 73 of 125 (4:03:58.802723) 2.2717 e jozos be bu bereni nyana apu /  i bi be  b i  be i e  boi be  ✗ average epoch rate per hr = 17.95,  eta = 2:53:47\n",
            "epoch 74 of 125 (4:05:34.634815) 2.2817 muno be ani se belema i dieme  / a   be bni bi be e a bnii  i b ✗ average epoch rate per hr = 18.08,  eta = 2:49:14\n",
            "epoch 74 of 125 (4:05:34.634953) 2.2817 . teme na ojumini na    min a  / a   be bni bi be e a bnii  i b ✗ average epoch rate per hr = 18.08,  eta = 2:49:14\n",
            "epoch 74 of 125 (4:07:10.966752) 2.2558 neda tamuno be na karakarabia  / i   bi a a be bi bi i i i e  b ✗ average epoch rate per hr = 17.96,  eta = 2:50:21\n",
            "epoch 74 of 125 (4:07:10.967017) 2.2558 tamuno be boma mi tokoni    om / i   bi a a be bi bi i i i e  b ✗ average epoch rate per hr = 17.96,  eta = 2:50:21\n",
            "epoch 75 of 125 (4:08:47.309407) 2.2554 u tomonibo belema. okuma o nem /  bi i i e be e a  b i a b bi a ✗ average epoch rate per hr = 18.09,  eta = 2:45:51\n",
            "epoch 75 of 125 (4:08:47.309562) 2.2554 u inyo nyanabia bara, se a pik /  bi i i e be e a  b i a b bi a ✗ average epoch rate per hr = 18.09,  eta = 2:45:51\n",
            "epoch 75 of 125 (4:10:24.038155) 2.2575 e na gboriye mie bu, ori ani b /  bi bie i e bi  be  b i b i be ✗ average epoch rate per hr = 17.97,  eta = 2:46:56\n",
            "epoch 75 of 125 (4:10:24.038329) 2.2575 kraist be ere bu, o siki mamgb /  bi bie i e bi  be  b i b i be ✗ average epoch rate per hr = 17.97,  eta = 2:46:56\n",
            "epoch 76 of 125 (4:12:01.179620) 2.2616 e boro mina ere nwo nyana bo y /  be i bi i b i bio bie a be be ✗ average epoch rate per hr = 18.09,  eta = 2:42:29\n",
            "epoch 76 of 125 (4:12:01.179878) 2.2616 oro siki remi a so jereusalem  /  be i bi i b i bio bie a be be ✗ average epoch rate per hr = 18.09,  eta = 2:42:29\n",
            "epoch 76 of 125 (4:13:38.760483) 2.2288 a nime ma na be okwein ma nwo  /  bi i ba bi be b io  iba bio b ✗ average epoch rate per hr = 17.98,  eta = 2:43:32\n",
            "epoch 76 of 125 (4:13:38.760696) 2.2288 i gose min ori ani diepiriye m /  bi i ba bi be b io  iba bio b ✗ average epoch rate per hr = 17.98,  eta = 2:43:32\n",
            "epoch 77 of 125 (4:15:15.086164) 2.2669 tari okunwengi sa apu ma so da /   i b i ao i  be bni ba be bi  ✗ average epoch rate per hr = 18.10,  eta = 2:39:07\n",
            "epoch 77 of 125 (4:15:15.086407) 2.2669 upele mi bupalimame nwo be.oku /   i b i ao i  be bni ba be bi  ✗ average epoch rate per hr = 18.10,  eta = 2:39:07\n",
            "epoch 77 of 125 (4:16:51.260667) 2.2352  mi sin eke. aniatibi tamuno b / bi be ib i  b i  a e bi a a be ✗ average epoch rate per hr = 17.99,  eta = 2:40:07\n",
            "epoch 77 of 125 (4:16:51.260812) 2.2352 re mi duba la oku diki. ani o  / bi be ib i  b i  a e bi a a be ✗ average epoch rate per hr = 17.99,  eta = 2:40:07\n",
            "epoch 78 of 125 (4:18:26.582072) 2.2400  toru nwo chua eke, na ominea  / bi i bio bii  b i  bi b i i  b ✗ average epoch rate per hr = 18.11,  eta = 2:35:43\n",
            "epoch 78 of 125 (4:18:26.582338) 2.2400  miesa yemi. wa ori na gboriye / bi i bio bii  b i  bi b i i  b ✗ average epoch rate per hr = 18.11,  eta = 2:35:43\n",
            "epoch 78 of 125 (4:20:03.116295) 2.2252 u se wa piriye mi gose aniatib /  be bo bi i e bi bi e bni  a e ✗ average epoch rate per hr = 18.00,  eta = 2:36:41\n",
            "epoch 78 of 125 (4:20:03.116451) 2.2252  nyana siki mimgba nwose ibi f /  be bo bi i e bi bi e bni  a e ✗ average epoch rate per hr = 18.00,  eta = 2:36:41\n",
            "epoch 79 of 125 (4:21:41.555386) 2.2500 hochi mi bu boro, nwo nemibia  /    i bi be be i  bio bi a e  b ✗ average epoch rate per hr = 18.11,  eta = 2:32:22\n",
            "epoch 79 of 125 (4:21:41.555525) 2.2500 inme firinewngi o piribia erec /    i bi be be i  bio bi a e  b ✗ average epoch rate per hr = 18.11,  eta = 2:32:22\n",
            "epoch 79 of 125 (4:23:19.132323) 2.2351  se kraist be ori iya ogono bi / be bii  i be b i bne b i i be  ✗ average epoch rate per hr = 18.00,  eta = 2:33:19\n",
            "epoch 79 of 125 (4:23:19.132599) 2.2351  ani fieabe ere go okuma ani k / be bii  i be b i bne b i i be  ✗ average epoch rate per hr = 18.00,  eta = 2:33:19\n",
            "epoch 80 of 125 (4:24:56.401851) 2.2437 ri opuma olomua dapu ma be ama / i b i a b i a  bi i ba be bna  ✗ average epoch rate per hr = 18.12,  eta = 2:29:01\n",
            "epoch 80 of 125 (4:24:56.402085) 2.2437 uno be ani mieke  boka fituru  / i b i a b i a  bi i ba be bna  ✗ average epoch rate per hr = 18.12,  eta = 2:29:01\n",
            "epoch 80 of 125 (4:26:32.861935) 2.2587  seni ania bu chua eke  mioku, / be i b i  be bii  b i bni  i   ✗ average epoch rate per hr = 18.01,  eta = 2:29:55\n",
            "epoch 80 of 125 (4:26:32.862185) 2.2587 ukopelesam na o jizos kraist b / be i b i  be bii  b i bni  i   ✗ average epoch rate per hr = 18.01,  eta = 2:29:55\n",
            "epoch 81 of 125 (4:28:09.162505) 2.2532 ro firinwengiaari bereni mie   / i bi i io i    i be i i bi  bn ✗ average epoch rate per hr = 18.12,  eta = 2:25:39\n",
            "epoch 81 of 125 (4:28:09.162743) 2.2532 o nwo miebia oku se bobo toru  / i bi i io i    i be i i bi  bn ✗ average epoch rate per hr = 18.12,  eta = 2:25:39\n",
            "epoch 81 of 125 (4:29:47.471059) 2.2320 mie bu boro wa sele oki se ori / a  be be i bo be e b i be b i  ✗ average epoch rate per hr = 18.01,  eta = 2:26:33\n",
            "epoch 81 of 125 (4:29:47.471213) 2.2320 akuma mi  se ini ye mamgba nwo / a  be be i bo be e b i be b i  ✗ average epoch rate per hr = 18.01,  eta = 2:26:33\n",
            "epoch 82 of 125 (4:31:23.138888) 2.2441  kiri mi nwose i pirime na iri / bi i bi bio e bnii i i bi bni  ✗ average epoch rate per hr = 18.13,  eta = 2:22:18\n",
            "epoch 82 of 125 (4:31:23.139084) 2.2441 uno be teke, ani se o piribia  / bi i bi bio e bnii i i bi bni  ✗ average epoch rate per hr = 18.13,  eta = 2:22:18\n",
            "epoch 82 of 125 (4:33:01.058036) 2.2650  sime kanakana mi piria ye ma  / be i bi i i a ba bi i  be bi b ✗ average epoch rate per hr = 18.02,  eta = 2:23:10\n",
            "epoch 82 of 125 (4:33:01.058197) 2.2650 emeaye mamgba nwo dikidiki se  / be i bi i i a ba bi i  be bi b ✗ average epoch rate per hr = 18.02,  eta = 2:23:10\n",
            "epoch 83 of 125 (4:34:37.399426) 2.2141 i na ominea yeinema mi, anga n /  bi b i i  be  i a ba  bni  bi ✗ average epoch rate per hr = 18.13,  eta = 2:18:57\n",
            "epoch 83 of 125 (4:34:37.399686) 2.2141 ia diri mi kien apu ma biekoro /  bi b i i  be  i a ba  bni  bi ✗ average epoch rate per hr = 18.13,  eta = 2:18:57\n",
            "epoch 83 of 125 (4:36:15.008041) 2.2384 iri nyaname, se piki miena beb /  i bie a a  be bi i bi  i be e ✗ average epoch rate per hr = 18.03,  eta = 2:19:47\n",
            "epoch 83 of 125 (4:36:15.008670) 2.2384   tomoni goyegoye nwo osi, omi /  i bie a a  be bi i bi  i be e ✗ average epoch rate per hr = 18.03,  eta = 2:19:47\n",
            "epoch 84 of 125 (4:37:50.554358) 2.2298 a erechi-e, ani fomubara na to /  b i  i i  bni bi i o i bi bi  ✗ average epoch rate per hr = 18.14,  eta = 2:15:36\n",
            "epoch 84 of 125 (4:37:50.554559) 2.2298 opu siye mie bo-e, anikanika o /  b i  i i  bni bi i o i bi bi  ✗ average epoch rate per hr = 18.14,  eta = 2:15:36\n",
            "epoch 84 of 125 (4:39:27.149616) 2.2401 mine ngeri mina bu nyana apu b / a i bio i bi i be bie a b i be ✗ average epoch rate per hr = 18.04,  eta = 2:16:23\n",
            "epoch 84 of 125 (4:39:27.149767) 2.2401 ku mi duko pakuma ye-e.   iruo / a i bio i bi i be bie a b i be ✗ average epoch rate per hr = 18.04,  eta = 2:16:23\n",
            "epoch 85 of 125 (4:41:03.767252) 2.2375 minea ogono o gbana warabe.  n / a i  b i i b bie a bo i e  bni ✗ average epoch rate per hr = 18.15,  eta = 2:12:15\n",
            "epoch 85 of 125 (4:41:03.767420) 2.2375 loma bu ani si boroboye-e, ani / a i  b i i b bie a bo i e  bni ✗ average epoch rate per hr = 18.15,  eta = 2:12:15\n",
            "epoch 85 of 125 (4:42:42.190878) 2.2379 kian nwo pu finji.  aniatibi t / i  ibio bi bi i   boni  a i bi ✗ average epoch rate per hr = 18.04,  eta = 2:13:02\n",
            "epoch 85 of 125 (4:42:42.191033) 2.2379 echi kraist be na gboribu sime / i  ibio bi bi i   boni  a i bi ✗ average epoch rate per hr = 18.04,  eta = 2:13:02\n",
            "epoch 86 of 125 (4:44:18.158411) 2.2462 ki se inia berijinebia erechi  / i be bni  be i i i e  b i  i b ✗ average epoch rate per hr = 18.15,  eta = 2:08:55\n",
            "epoch 86 of 125 (4:44:18.158566) 2.2462 muno toku be nyanaka bo goyego / i be bni  be i i i e  b i  i b ✗ average epoch rate per hr = 18.15,  eta = 2:08:55\n",
            "epoch 86 of 125 (4:45:54.968892) 2.2220 o tamuno oloko kan-abe, aniati /  bi a a b i i bi i  e  bni  a  ✗ average epoch rate per hr = 18.05,  eta = 2:09:39\n",
            "epoch 86 of 125 (4:45:54.969148) 2.2220 mame na ani opuma bupalimaye s /  bi a a b i i bi i  e  bni  a  ✗ average epoch rate per hr = 18.05,  eta = 2:09:39\n",
            "epoch 87 of 125 (4:47:32.144933) 2.2170  mi-e na tamuno be bene-bene b / bi i bi bi a a be be i  e a be ✗ average epoch rate per hr = 18.15,  eta = 2:05:35\n",
            "epoch 87 of 125 (4:47:32.145176) 2.2170 i ani mi nwo berenime piki bug / bi i bi bi a a be be i  e a be ✗ average epoch rate per hr = 18.15,  eta = 2:05:35\n",
            "epoch 87 of 125 (4:49:09.407037) 2.2160 nma na piki belema na bakama s / ia bi bi i be e a bi be i a be ✗ average epoch rate per hr = 18.05,  eta = 2:06:17\n",
            "epoch 87 of 125 (4:49:09.407277) 2.2160 ni chinme, aniatibi ini inema  / ia bi bi i be e a bi be i a be ✗ average epoch rate per hr = 18.05,  eta = 2:06:17\n",
            "epoch 88 of 125 (4:50:46.416654) 2.2210  ofori bereni nwo nyanabia oku / b i i be i i bio bie a o  b i  ✗ average epoch rate per hr = 18.16,  eta = 2:02:15\n",
            "epoch 88 of 125 (4:50:46.416807) 2.2210 afiadiri mi now beme, a yela d / b i i be i i bio bie a o  b i  ✗ average epoch rate per hr = 18.16,  eta = 2:02:15\n",
            "epoch 88 of 125 (4:52:23.753114) 2.2231 ikwein kon ikiankoroapu ma o n /  io  ibi ibni  io i  i ba b bi ✗ average epoch rate per hr = 18.06,  eta = 2:02:56\n",
            "epoch 88 of 125 (4:52:23.753289) 2.2231 orifori dumo mi konka siki. an /  io  ibi ibni  io i  i ba b bi ✗ average epoch rate per hr = 18.06,  eta = 2:02:56\n",
            "epoch 89 of 125 (4:54:00.796700) 2.2181 ekewari mi nama, ani tonbu sim /  i o i bi bi a  bni bi io be i ✗ average epoch rate per hr = 18.16,  eta = 1:58:55\n",
            "epoch 89 of 125 (4:54:00.796852) 2.2181 minea duaboromabo jizos kraist /  i o i bi bi a  bni bi io be i ✗ average epoch rate per hr = 18.16,  eta = 1:58:55\n",
            "epoch 89 of 125 (4:55:36.830358) 2.2240 a piki galagalasa oru teke mie /  bi i bi a a a e b i ba i bi   ✗ average epoch rate per hr = 18.06,  eta = 1:59:34\n",
            "epoch 89 of 125 (4:55:36.830494) 2.2240 be berenisa ye mi ani wa sime  /  bi i bi a a a e b i ba i bi   ✗ average epoch rate per hr = 18.06,  eta = 1:59:34\n",
            "epoch 90 of 125 (4:57:12.989328) 2.2136 e ani o buokoro gbaso tamuno b /  b i b be  i i bie e bi a a be ✗ average epoch rate per hr = 18.17,  eta = 1:55:35\n",
            "epoch 90 of 125 (4:57:12.989573) 2.2136 i oku mi o nwo kokome bebe, an /  b i b be  i i bie e bi a a be ✗ average epoch rate per hr = 18.17,  eta = 1:55:35\n",
            "epoch 90 of 125 (4:58:50.999977) 2.2297 inyo la bara mieabe miese ani  /  ie bi be i ba   e ba  e bni b ✗ average epoch rate per hr = 18.07,  eta = 1:56:13\n",
            "epoch 90 of 125 (4:58:51.000251) 2.2297 e goyegoye piki oria toku be s /  ie bi be i ba   e ba  e bni b ✗ average epoch rate per hr = 18.07,  eta = 1:56:13\n",
            "epoch 91 of 125 (5:00:27.521616) 2.2022 bo goyegoye piki dabo be sikim / e bi e e e bi i bi e be be i i ✗ average epoch rate per hr = 18.17,  eta = 1:52:15\n",
            "epoch 91 of 125 (5:00:27.521914) 2.2022  wa toru se iria se okweinbia  / e bi e e e bi i bi e be be i i ✗ average epoch rate per hr = 18.17,  eta = 1:52:15\n",
            "epoch 91 of 125 (5:02:04.247145) 2.2020  nwo belemae.  minea tomonikir / bio be e e   bni i  bi i i i i ✗ average epoch rate per hr = 18.08,  eta = 1:52:51\n",
            "epoch 91 of 125 (5:02:04.247378) 2.2020 egoye, inibo arimgba nwo kansa / bio be e e   bni i  bi i i i i ✗ average epoch rate per hr = 18.08,  eta = 1:52:51\n",
            "epoch 92 of 125 (5:03:40.750704) 2.2299 kokomayee.  kuluma kerenibipi  / i i a e   bni a a bi i i e i b ✗ average epoch rate per hr = 18.18,  eta = 1:48:55\n",
            "epoch 92 of 125 (5:03:40.750846) 2.2299  bie, omine ngo kobirima korom / i i a e   bni a a bi i i e i b ✗ average epoch rate per hr = 18.18,  eta = 1:48:55\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    },
    "id": "1W0YOx5gDPuL",
    "outputId": "862849a3-b8d4-437f-fff2-2951f22885c3"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb8b7248f6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./slgru_epoch36.model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rnn' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "PATH = './slgru_epoch36.model'\r\n",
    "torch.save(rnn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOF1-xK-NMJw",
    "outputId": "c7d7adff-c3c3-4ab8-90a6-e0a2c00a8b97"
   },
   "outputs": [
=======
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "1W0YOx5gDPuL",
        "outputId": "bce52e90-d446-47f7-ce0e-4dfc8743b49c"
      },
      "source": [
        "import torch\r\n",
        "PATH = './slgru_epoch120.model'\r\n",
        "torch.save(rnn.state_dict(), PATH)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd03158f3c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./slgru_epoch120.model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'rnn' is not defined"
          ]
        }
      ]
    },
>>>>>>> 4de12b72940938de9f2ea6823de9a8e42aa6c50a
    {
     "data": {
      "text/plain": [
       "(200, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "# product = reduce((lambda x, y: x * y), [1, 2, 3, 4])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(vloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXwKxI0KNMJx",
    "outputId": "cb7fe06f-082d-4d5f-dd89-14f4d04581dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is=torch.Size([1, 98]), hs=torch.Size([1, 128])\n",
      "torch.Size([1, 98])\n"
     ]
    }
   ],
   "source": [
    "import kenlm\n",
    "with open('rpynotes/ok-rnn/txts/gal_eph_new.txt', encoding='utf-16') as f:\n",
    "  s=f.read()\n",
    "model = kenlm.Model('rpynotes/ok-rnn/txteval/val/text.arpa')\n",
    "print(model.perplexity(s))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_gru.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
